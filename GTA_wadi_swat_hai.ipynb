{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lekiho/NSR_AD/blob/main/GTA_wadi_swat_hai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGqEUA6klNXY",
        "outputId": "7ad68325-5a74-44a5-9269-be191b5afb7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "my_path = '/content/notebooks'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl0AHXcduBwT"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab_Notebooks/GTA/myenv')\n",
        "sys.path.append('/content/drive/MyDrive/Colab_Notebooks/GTA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTaP27HwuV7I",
        "outputId": "055b4cbf-e78b-491e-ea32-76340fa60f95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/MyDrive/Colab_Notebooks/GTA/myenv', '/content/drive/MyDrive/Colab_Notebooks/GTA']\n"
          ]
        }
      ],
      "source": [
        "print(sys.path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYVz02JHuZqu"
      },
      "outputs": [],
      "source": [
        "# !pip install --target=$my_path -r /content/drive/MyDrive/'Colab Notebooks'/GTA/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxphU9a1xGxG"
      },
      "outputs": [],
      "source": [
        "def down_cast(df, columns) :\n",
        "    df_list = []\n",
        "    for column in columns :\n",
        "        try:\n",
        "            df[column] = pd.to_numeric(df[column], downcast='integer')\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            df[column] = pd.to_numeric(df[column], downcast='float')\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            df[column] = pd.to_object(df[column], downcast='object')\n",
        "        except:\n",
        "            pass\n",
        "        df_list.append(df[column])\n",
        "    return pd.concat(df_list, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBEckEMaxDT5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#downsampling\n",
        "from myenv import process_wadi\n",
        "import re\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWLniihgvHlY"
      },
      "outputs": [],
      "source": [
        "dirpath = os.getcwd()\n",
        "x_train = pd.read_csv(os.path.join(dirpath, 'data', '/content/drive/MyDrive/Colab_Notebooks/GTA/data/WADI.A2_19_Nov_2019/WADI_14days_new.csv'), index_col=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_lbxd9IxeeA"
      },
      "outputs": [],
      "source": [
        "x_test = pd.read_csv(os.path.join(dirpath, 'data', '/content/drive/MyDrive/Colab_Notebooks/GTA/data/WADI.A2_19_Nov_2019/WADI_attackdataLABLE.csv'), index_col=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNUkpCH9xvPp"
      },
      "outputs": [],
      "source": [
        "down_cast(x_train, x_train.columns)\n",
        "down_cast(x_test, x_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8qLGRDE3s0t",
        "outputId": "47f4f2a6-7137-4758-f291-602a8d43a90c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "x_test['Attack LABLE (1:No Attack, -1:Attack)'] = (x_test['Attack LABLE (1:No Attack, -1:Attack)'] -1)*((-1)/2)\n",
        "x_test['attack'] = x_test['Attack LABLE (1:No Attack, -1:Attack)'].astype(int)\n",
        "y_test = x_test['attack']\n",
        "x_test.drop('Attack LABLE (1:No Attack, -1:Attack)', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwBRDN-R72Dw"
      },
      "outputs": [],
      "source": [
        "# x_train.to_csv('/content/drive/MyDrive/Colab Notebooks/GTA/data/WADI.A2_19_Nov_2019/WADI_14days_train.csv')\n",
        "# x_test.to_csv('/content/drive/MyDrive/Colab Notebooks/GTA/data/WADI.A2_19_Nov_2019/WADI_attackdata_labelled_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHm5ne5z-wvA"
      },
      "source": [
        "##### process_wadi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANz2_-TJ-uGt"
      },
      "outputs": [],
      "source": [
        "# max min(0-1)\n",
        "def norm(train, test):\n",
        "\n",
        "    normalizer = MinMaxScaler(feature_range=(0, 1)).fit(train) # scale training data to [0,1] range\n",
        "    train_ret = normalizer.transform(train)\n",
        "    test_ret = normalizer.transform(test)\n",
        "\n",
        "    return train_ret, test_ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sidZVQy967_"
      },
      "outputs": [],
      "source": [
        "# downsample by 10\n",
        "def downsample(data, labels, down_len):\n",
        "    np_data = np.array(data)\n",
        "    np_labels = np.array(labels)\n",
        "\n",
        "    orig_len, col_num = np_data.shape\n",
        "\n",
        "    down_time_len = orig_len // down_len\n",
        "\n",
        "    np_data = np_data.transpose()\n",
        "    # print('before downsample', np_data.shape)\n",
        "\n",
        "    d_data = np_data[:, :down_time_len*down_len].reshape(col_num, -1, down_len)\n",
        "    d_data = np.median(d_data, axis=2).reshape(col_num, -1)\n",
        "\n",
        "    d_labels = np_labels[:down_time_len*down_len].reshape(-1, down_len)\n",
        "    # if exist anomalies, then this sample is abnormal\n",
        "    d_labels = np.round(np.max(d_labels, axis=1))\n",
        "\n",
        "    d_data = d_data.transpose()\n",
        "\n",
        "    # print('after downsample', d_data.shape, d_labels.shape)\n",
        "\n",
        "    return d_data.tolist(), d_labels.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPOynY9A-Q5A"
      },
      "outputs": [],
      "source": [
        "train = x_train\n",
        "test = x_test\n",
        "\n",
        "train = train.iloc[:, 2:]\n",
        "test = test.iloc[:, 2:]\n",
        "\n",
        "\n",
        "train = train.fillna(train.mean())\n",
        "test = test.fillna(test.mean())\n",
        "train = train.fillna(0)\n",
        "test = test.fillna(0)\n",
        "\n",
        "# trim column names\n",
        "train = train.rename(columns=lambda x: x.strip())\n",
        "test = test.rename(columns=lambda x: x.strip())\n",
        "\n",
        "\n",
        "train_labels = np.zeros(len(train))\n",
        "test_labels = test.attack\n",
        "\n",
        "# train = train.drop(columns=['attack'])\n",
        "test = test.drop(columns=['attack'])\n",
        "\n",
        "cols = [x[46:] for x in train.columns] # remove column name prefixes\n",
        "train.columns = cols\n",
        "cols = [x[46:] for x in test.columns] # remove column name prefixes\n",
        "test.columns = cols\n",
        "\n",
        "\n",
        "x_train1, x_test1 = norm(train.values, test.values)\n",
        "\n",
        "train = pd.DataFrame(x_train1)\n",
        "test = pd.DataFrame(x_test1)\n",
        "\n",
        "# for i, col in enumerate(train.columns):\n",
        "#     train.loc[:, col] = x_train1[:, i]\n",
        "#     test.loc[:, col] = x_test1[:, i]\n",
        "\n",
        "d_train_x, d_train_labels = downsample(train.values, train_labels, 10)\n",
        "d_test_x, d_test_labels = downsample(test.values, test_labels, 10)\n",
        "\n",
        "train_df = pd.DataFrame(d_train_x, columns = train.columns)\n",
        "test_df = pd.DataFrame(d_test_x, columns = test.columns)\n",
        "\n",
        "\n",
        "test_df['attack'] = d_test_labels\n",
        "train_df['attack'] = d_train_labels\n",
        "\n",
        "# train_df = train_df.iloc[2160:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgnDFnNBeJEi"
      },
      "outputs": [],
      "source": [
        "train_df.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/WADI.A2_19_Nov_2019/WADI_14days_downsampled.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_H4f-VEIFW3"
      },
      "source": [
        "##### GTA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HESBW1yPm1Eo",
        "outputId": "43f42c10-5665-46e8-ae0a-a59fd56b7915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 15.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 14.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.13\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 14.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (750 kB)\n",
            "\u001b[K     |████████████████████████████████| 750 kB 14.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.5.18.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=d6605e0f4bdeafbf060dc8615bc2d154fa4ffb74479f1b5a970d1c2e85de4aa9\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4\n"
          ]
        }
      ],
      "source": [
        "# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4h5MHG-xdFB8",
        "outputId": "47d62967-26bd-461e-9861-9ca67e11748e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "my_path = '/content/notebooks'\n",
        "sys.path.append('/content/drive/MyDrive/Colab_Notebooks/GTA/myenv')\n",
        "sys.path.append('/content/drive/MyDrive/Colab_Notebooks/GTA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OeMe3IRLzxq"
      },
      "outputs": [],
      "source": [
        "# ! pip install --target=$my_path -r /content/drive/MyDrive/Colab_Notebooks/GTA/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4CSZpmvH9GQ",
        "outputId": "6d8bee1a-6c0e-4ee2-cd66-e68af4d46be4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Notebooks/GTA\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab_Notebooks/GTA\n",
        "import myenv\n",
        "# from exp import exp_gta_dad\n",
        "# from models import gta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ65patsMWL0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yth35DeoMfHX"
      },
      "outputs": [],
      "source": [
        "x_train = pd.read_csv(os.path.join('data', '/content/drive/MyDrive/Colab_Notebooks/GTA/data/rename/WADI_14days_colab.csv'), index_col=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WH52CBqKmHZf"
      },
      "outputs": [],
      "source": [
        "# x_train['date'] = pd.to_datetime(x_train[['date','Time']].apply(lambda row:' '.join(row.values.astype(str)), axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mygH80IBTfkt"
      },
      "outputs": [],
      "source": [
        "# x_train['date'] = pd.to_datetime(x_train['date'], format = '%y-%m-%d %H:%M:%S')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fADwldJhK_Bt"
      },
      "outputs": [],
      "source": [
        "# x_train.drop(['2_LS_001_AL','2_LS_002_AL','2_P_001_STATUS','2_P_002_STATUS'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnEOigWuL99C"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(x_train.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cPnB-d3pjIP"
      },
      "outputs": [],
      "source": [
        "# from datetime import datetime\n",
        "# import time\n",
        "# x_train['timestamp'] = x_train['date']\n",
        "# for i in range(len(x_train['date'])):\n",
        "#   x_train['timestamp'].iloc[i] = time.mktime(x_train['date'].iloc[i].timetuple())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKqJoBJ1NhAP"
      },
      "outputs": [],
      "source": [
        "# x_train.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/rename/WADI_14days_colab.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Jh3_8E58QqV"
      },
      "outputs": [],
      "source": [
        "attack_data = pd.read_csv(os.path.join('data', '/content/drive/MyDrive/Colab_Notebooks/GTA/data/rename/WADI_attackdata_colab.csv'), index_col=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe32AcUVMcRB"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(attack_data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jfZCqHmMq7M"
      },
      "outputs": [],
      "source": [
        "attack_data.drop(['2_LS_001_AL','2_LS_002_AL','2_P_001_STATUS','2_P_002_STATUS'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBT4iJn-_31O"
      },
      "outputs": [],
      "source": [
        "attack_data.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPes2pZl3gac"
      },
      "outputs": [],
      "source": [
        "# attack_data['Timestamp'] = pd.to_datetime(attack_data[['Date ', 'Time']].apply(lambda row:' '.join(row.values.astype(str)), axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkZGZE6NCO8L"
      },
      "outputs": [],
      "source": [
        "# attack_data.drop(['Date ','Time'], axis=1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32Zfhc9oAllC"
      },
      "outputs": [],
      "source": [
        "# from datetime import datetime\n",
        "# import time\n",
        "# for i in range(len(attack_data['Timestamp'])):\n",
        "#   attack_data['Timestamp'].iloc[i] = time.mktime(attack_data['Timestamp'].iloc[i].timetuple())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByQZSCX-DQMV"
      },
      "outputs": [],
      "source": [
        "# attack_data['label'] = attack_data['Attack LABLE (1:No Attack, -1:Attack)']\n",
        "# attack_data.drop(['Attack LABLE (1:No Attack, -1:Attack)'], axis=1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gX6YBU74CkxE"
      },
      "outputs": [],
      "source": [
        "# attack_data.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/rename/WADI_attackdata_colab.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "UMCBxSq1KRGK",
        "outputId": "c9621621-d131-46a6-dd65-5b1e4c772f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        1_AIT_001_PV  1_AIT_002_PV  1_AIT_003_PV  1_AIT_004_PV  1_AIT_005_PV  \\\n",
              "0            171.155      0.619473       11.5759       504.645      0.318319   \n",
              "1            171.155      0.619473       11.5759       504.645      0.318319   \n",
              "2            171.155      0.619473       11.5759       504.645      0.318319   \n",
              "3            171.155      0.607477       11.5725       504.673      0.318438   \n",
              "4            171.155      0.607477       11.5725       504.673      0.318438   \n",
              "...              ...           ...           ...           ...           ...   \n",
              "784532       175.855      0.589478       11.8941       479.191      0.331571   \n",
              "784533       175.855      0.589478       11.8941       479.191      0.331571   \n",
              "784534       175.855      0.589478       11.8941       479.191      0.331571   \n",
              "784535       175.896      0.613476       11.8913       479.224      0.331622   \n",
              "784536       175.896      0.613476       11.8913       479.224      0.331622   \n",
              "\n",
              "        1_FIT_001_PV  1_LS_001_AL  1_LS_002_AL  1_LT_001_PV  1_MV_001_STATUS  \\\n",
              "0           0.001157            0            0      47.8911                1   \n",
              "1           0.001157            0            0      47.8911                1   \n",
              "2           0.001157            0            0      47.8911                1   \n",
              "3           0.001207            0            0      47.7503                1   \n",
              "4           0.001207            0            0      47.7503                1   \n",
              "...              ...          ...          ...          ...              ...   \n",
              "784532      0.001128            0            0      48.1129                1   \n",
              "784533      0.001128            0            0      48.1129                1   \n",
              "784534      0.001128            0            0      48.1129                1   \n",
              "784535      0.001173            0            0      48.0348                1   \n",
              "784536      0.001173            0            0      48.0348                1   \n",
              "\n",
              "        ...  3_MV_002_STATUS  3_MV_003_STATUS  3_P_001_STATUS  3_P_002_STATUS  \\\n",
              "0       ...                1                1               1               1   \n",
              "1       ...                1                1               1               1   \n",
              "2       ...                1                1               1               1   \n",
              "3       ...                1                1               1               1   \n",
              "4       ...                1                1               1               1   \n",
              "...     ...              ...              ...             ...             ...   \n",
              "784532  ...                1                1               1               1   \n",
              "784533  ...                1                1               1               1   \n",
              "784534  ...                1                1               1               1   \n",
              "784535  ...                1                1               1               1   \n",
              "784536  ...                1                1               1               1   \n",
              "\n",
              "        3_P_003_STATUS  3_P_004_STATUS  LEAK_DIFF_PRESSURE  \\\n",
              "0                    1               1             67.9651   \n",
              "1                    1               1             67.9651   \n",
              "2                    1               1             67.9651   \n",
              "3                    1               1             67.1948   \n",
              "4                    1               1             67.1948   \n",
              "...                ...             ...                 ...   \n",
              "784532               1               1             60.6305   \n",
              "784533               1               1             60.6305   \n",
              "784534               1               1             60.6305   \n",
              "784535               1               1             60.4477   \n",
              "784536               1               1             60.4477   \n",
              "\n",
              "        PLANT_START_STOP_LOG  TOTAL_CONS_REQUIRED_FLOW     Timestamp  \n",
              "0                          1                      0.68  1.506298e+09  \n",
              "1                          1                      0.68  1.506298e+09  \n",
              "2                          1                      0.68  1.506298e+09  \n",
              "3                          1                      0.68  1.506298e+09  \n",
              "4                          1                      0.68  1.506298e+09  \n",
              "...                      ...                       ...           ...  \n",
              "784532                     1                      0.25  1.279326e+09  \n",
              "784533                     1                      0.25  1.279326e+09  \n",
              "784534                     1                      0.25  1.279326e+09  \n",
              "784535                     1                      0.25  1.279326e+09  \n",
              "784536                     1                      0.25  1.279326e+09  \n",
              "\n",
              "[784537 rows x 124 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c81f2a3-bb3b-44d0-aa22-05838f78e80c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1_AIT_001_PV</th>\n",
              "      <th>1_AIT_002_PV</th>\n",
              "      <th>1_AIT_003_PV</th>\n",
              "      <th>1_AIT_004_PV</th>\n",
              "      <th>1_AIT_005_PV</th>\n",
              "      <th>1_FIT_001_PV</th>\n",
              "      <th>1_LS_001_AL</th>\n",
              "      <th>1_LS_002_AL</th>\n",
              "      <th>1_LT_001_PV</th>\n",
              "      <th>1_MV_001_STATUS</th>\n",
              "      <th>...</th>\n",
              "      <th>3_MV_002_STATUS</th>\n",
              "      <th>3_MV_003_STATUS</th>\n",
              "      <th>3_P_001_STATUS</th>\n",
              "      <th>3_P_002_STATUS</th>\n",
              "      <th>3_P_003_STATUS</th>\n",
              "      <th>3_P_004_STATUS</th>\n",
              "      <th>LEAK_DIFF_PRESSURE</th>\n",
              "      <th>PLANT_START_STOP_LOG</th>\n",
              "      <th>TOTAL_CONS_REQUIRED_FLOW</th>\n",
              "      <th>Timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>171.155</td>\n",
              "      <td>0.619473</td>\n",
              "      <td>11.5759</td>\n",
              "      <td>504.645</td>\n",
              "      <td>0.318319</td>\n",
              "      <td>0.001157</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47.8911</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>67.9651</td>\n",
              "      <td>1</td>\n",
              "      <td>0.68</td>\n",
              "      <td>1.506298e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>171.155</td>\n",
              "      <td>0.619473</td>\n",
              "      <td>11.5759</td>\n",
              "      <td>504.645</td>\n",
              "      <td>0.318319</td>\n",
              "      <td>0.001157</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47.8911</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>67.9651</td>\n",
              "      <td>1</td>\n",
              "      <td>0.68</td>\n",
              "      <td>1.506298e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>171.155</td>\n",
              "      <td>0.619473</td>\n",
              "      <td>11.5759</td>\n",
              "      <td>504.645</td>\n",
              "      <td>0.318319</td>\n",
              "      <td>0.001157</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47.8911</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>67.9651</td>\n",
              "      <td>1</td>\n",
              "      <td>0.68</td>\n",
              "      <td>1.506298e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>171.155</td>\n",
              "      <td>0.607477</td>\n",
              "      <td>11.5725</td>\n",
              "      <td>504.673</td>\n",
              "      <td>0.318438</td>\n",
              "      <td>0.001207</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47.7503</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>67.1948</td>\n",
              "      <td>1</td>\n",
              "      <td>0.68</td>\n",
              "      <td>1.506298e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>171.155</td>\n",
              "      <td>0.607477</td>\n",
              "      <td>11.5725</td>\n",
              "      <td>504.673</td>\n",
              "      <td>0.318438</td>\n",
              "      <td>0.001207</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47.7503</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>67.1948</td>\n",
              "      <td>1</td>\n",
              "      <td>0.68</td>\n",
              "      <td>1.506298e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>784532</th>\n",
              "      <td>175.855</td>\n",
              "      <td>0.589478</td>\n",
              "      <td>11.8941</td>\n",
              "      <td>479.191</td>\n",
              "      <td>0.331571</td>\n",
              "      <td>0.001128</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48.1129</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>60.6305</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.279326e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>784533</th>\n",
              "      <td>175.855</td>\n",
              "      <td>0.589478</td>\n",
              "      <td>11.8941</td>\n",
              "      <td>479.191</td>\n",
              "      <td>0.331571</td>\n",
              "      <td>0.001128</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48.1129</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>60.6305</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.279326e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>784534</th>\n",
              "      <td>175.855</td>\n",
              "      <td>0.589478</td>\n",
              "      <td>11.8941</td>\n",
              "      <td>479.191</td>\n",
              "      <td>0.331571</td>\n",
              "      <td>0.001128</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48.1129</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>60.6305</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.279326e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>784535</th>\n",
              "      <td>175.896</td>\n",
              "      <td>0.613476</td>\n",
              "      <td>11.8913</td>\n",
              "      <td>479.224</td>\n",
              "      <td>0.331622</td>\n",
              "      <td>0.001173</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48.0348</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>60.4477</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.279326e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>784536</th>\n",
              "      <td>175.896</td>\n",
              "      <td>0.613476</td>\n",
              "      <td>11.8913</td>\n",
              "      <td>479.224</td>\n",
              "      <td>0.331622</td>\n",
              "      <td>0.001173</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48.0348</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>60.4477</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.279326e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>784537 rows × 124 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c81f2a3-bb3b-44d0-aa22-05838f78e80c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c81f2a3-bb3b-44d0-aa22-05838f78e80c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c81f2a3-bb3b-44d0-aa22-05838f78e80c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "K = 5\n",
        "kfold = KFold(n_splits= K, shuffle= False, random_state=None)\n",
        "\n",
        "for train, test in kfold.split(x_train):\n",
        "    print('train: %s, test: %s' % (train, test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjS3_bc72rDj",
        "outputId": "5db2c9b7-ccbc-4cf7-ba91-bbfc49f38797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: [156908 156909 156910 ... 784534 784535 784536], test: [     0      1      2 ... 156905 156906 156907]\n",
            "train: [     0      1      2 ... 784534 784535 784536], test: [156908 156909 156910 ... 313813 313814 313815]\n",
            "train: [     0      1      2 ... 784534 784535 784536], test: [313816 313817 313818 ... 470720 470721 470722]\n",
            "train: [     0      1      2 ... 784534 784535 784536], test: [470723 470724 470725 ... 627627 627628 627629]\n",
            "train: [     0      1      2 ... 627627 627628 627629], test: [627630 627631 627632 ... 784534 784535 784536]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K1_train = x_train[156908:784536]\n",
        "K1_test = x_train[0:156907]\n",
        "K1_test['label'] = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOeBqiKHMell",
        "outputId": "144d4ca9-0316-490b-9645-7ec4b3d4d9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K1_train.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/wadi_kfold_train_only/k1/WADI_14days_colab.csv')\n",
        "K1_test.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/wadi_kfold_train_only/k1/WADI_attackdata_colab.csv')"
      ],
      "metadata": {
        "id": "I4R2_tlcRSrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K2_train = pd.concat([x_train[0:156907],x_train[313816:784536]])\n",
        "K2_test = x_train[156908:313815]\n",
        "K2_test['label'] = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFChbwQDM1my",
        "outputId": "0d927c0c-2ed9-40d1-8218-f29eb65ded5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K2_train.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/wadi_kfold_train_only/k2/WADI_14days_colab.csv')\n",
        "K2_test.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/wadi_kfold_train_only/k2/WADI_attackdata_colab.csv')"
      ],
      "metadata": {
        "id": "dl-qabMZR9Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K3_train = pd.concat([x_train[0:313815],x_train[470723:784536]])\n",
        "K3_test = x_train[313816:470722]\n",
        "K3_test['label'] = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T77EUedM1gf",
        "outputId": "15384b3f-ef40-4dbb-b5c7-8b7bce359a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K3_train.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/wadi_kfold_train_only/k3/WADI_14days_colab.csv')\n",
        "K3_test.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/wadi_kfold_train_only/k3/WADI_attackdata_colab.csv')"
      ],
      "metadata": {
        "id": "grU7jItDSAnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K4_train = pd.concat([x_train[0:470722],x_train[627630:784536]])\n",
        "K4_test = x_train[470723:627629]\n",
        "K4_test['label'] = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqTv9bi7M1cP",
        "outputId": "e0618a38-36bb-4005-f775-4355b6e22537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K4_train.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/wadi_kfold_train_only/k4/WADI_14days_colab.csv')\n",
        "K4_test.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/wadi_kfold_train_only/k4/WADI_attackdata_colab.csv')"
      ],
      "metadata": {
        "id": "Wmw7SNj0SDZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K5_train = x_train[0:627629]\n",
        "K5_test = x_train[627630:784536]\n",
        "K5_test['label'] = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiq1C0QFQTTY",
        "outputId": "879e1b1e-2278-4c7f-dd53-7ad0c27c5112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K5_train.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/wadi_kfold_train_only/k5/WADI_14days_colab.csv')\n",
        "K5_test.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/wadi_kfold_train_only/k5/WADI_attackdata_colab.csv')"
      ],
      "metadata": {
        "id": "ZJDPXM97SLdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntj0mPY0EURu",
        "outputId": "76d9594a-1f25-4500-f10d-0cf54549070d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Notebooks/GTA\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab_Notebooks/GTA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -u main_gta_dad.py --model gta --data WADI --root_path '/content/drive/MyDrive/Colab_Notebooks/GTA/data/wadi_kfold_train_only/k1/' --data_path 'WADI_14days_colab.csv'\n",
        "# !python -u main_gta_dad.py --model gta --data WADI --root_path '/content/drive/MyDrive/Colab_Notebooks/GTA/data/wadi_kfold_train_only/k2/' --data_path 'WADI_14days_colab.csv'\n",
        "!python -u main_gta_dad.py --model gta --data WADI --root_path '/content/drive/MyDrive/Colab_Notebooks/GTA/data/wadi_kfold_train_only/k3/' --data_path 'WADI_14days_colab.csv'\n",
        "!python -u main_gta_dad.py --model gta --data WADI --root_path '/content/drive/MyDrive/Colab_Notebooks/GTA/data/wadi_kfold_train_only/k4/' --data_path 'WADI_14days_colab.csv'\n",
        "!python -u main_gta_dad.py --model gta --data WADI --root_path '/content/drive/MyDrive/Colab_Notebooks/GTA/data/wadi_kfold_train_only/k5/' --data_path 'WADI_14days_colab.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bv0QPh_SShO",
        "outputId": "e199ef28-0a36-4100-bbe0-22a0b58bdd42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : gta_WADI_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 627568\n",
            "val 39166\n",
            "test 156847\n",
            "\titers: 100, epoch: 1 | loss: 12148.6160370\n",
            "\tspeed: 0.1879s/iter; left time: 3518.9444s\n",
            "\titers: 200, epoch: 1 | loss: 11994.8458545\n",
            "\tspeed: 0.1894s/iter; left time: 3527.3700s\n",
            "\titers: 300, epoch: 1 | loss: 11841.0800111\n",
            "\tspeed: 0.1896s/iter; left time: 3511.2314s\n",
            "\titers: 400, epoch: 1 | loss: 11687.3179566\n",
            "\tspeed: 0.1882s/iter; left time: 3466.8072s\n",
            "\titers: 500, epoch: 1 | loss: 11533.5546799\n",
            "\tspeed: 0.1897s/iter; left time: 3475.1407s\n",
            "\titers: 600, epoch: 1 | loss: 11379.7929809\n",
            "\tspeed: 0.1892s/iter; left time: 3447.7374s\n",
            "\titers: 700, epoch: 1 | loss: 11226.0311775\n",
            "\tspeed: 0.1888s/iter; left time: 3421.0948s\n",
            "\titers: 800, epoch: 1 | loss: 11072.2697746\n",
            "\tspeed: 0.1888s/iter; left time: 3402.6759s\n",
            "\titers: 900, epoch: 1 | loss: 10918.5079110\n",
            "\tspeed: 0.1891s/iter; left time: 3389.2150s\n",
            "\titers: 1000, epoch: 1 | loss: 10764.7480384\n",
            "\tspeed: 0.1889s/iter; left time: 3366.0937s\n",
            "\titers: 1100, epoch: 1 | loss: 10610.9869329\n",
            "\tspeed: 0.1890s/iter; left time: 3350.1188s\n",
            "\titers: 1200, epoch: 1 | loss: 10457.2259705\n",
            "\tspeed: 0.1889s/iter; left time: 3328.8582s\n",
            "\titers: 1300, epoch: 1 | loss: 10303.4651081\n",
            "\tspeed: 0.1887s/iter; left time: 3307.1158s\n",
            "\titers: 1400, epoch: 1 | loss: 10149.7052955\n",
            "\tspeed: 0.1883s/iter; left time: 3280.8961s\n",
            "\titers: 1500, epoch: 1 | loss: 9995.9444266\n",
            "\tspeed: 0.1884s/iter; left time: 3263.7877s\n",
            "\titers: 1600, epoch: 1 | loss: 9842.1841311\n",
            "\tspeed: 0.1885s/iter; left time: 3246.1616s\n",
            "\titers: 1700, epoch: 1 | loss: 9688.4243008\n",
            "\tspeed: 0.1893s/iter; left time: 3241.1757s\n",
            "\titers: 1800, epoch: 1 | loss: 9534.6636151\n",
            "\tspeed: 0.1894s/iter; left time: 3224.3714s\n",
            "\titers: 1900, epoch: 1 | loss: 9380.9032601\n",
            "\tspeed: 0.1886s/iter; left time: 3192.0721s\n",
            "\titers: 2000, epoch: 1 | loss: 9227.1425877\n",
            "\tspeed: 0.1890s/iter; left time: 3179.4799s\n",
            "\titers: 2100, epoch: 1 | loss: 9073.3827189\n",
            "\tspeed: 0.1892s/iter; left time: 3163.8949s\n",
            "\titers: 2200, epoch: 1 | loss: 8919.6228588\n",
            "\tspeed: 0.1886s/iter; left time: 3135.3393s\n",
            "\titers: 2300, epoch: 1 | loss: 8765.8620330\n",
            "\tspeed: 0.1891s/iter; left time: 3124.2977s\n",
            "\titers: 2400, epoch: 1 | loss: 8612.1019798\n",
            "\tspeed: 0.1894s/iter; left time: 3110.1361s\n",
            "\titers: 2500, epoch: 1 | loss: 8458.3412893\n",
            "\tspeed: 0.1886s/iter; left time: 3078.8891s\n",
            "\titers: 2600, epoch: 1 | loss: 8304.5814441\n",
            "\tspeed: 0.1888s/iter; left time: 3062.6223s\n",
            "\titers: 2700, epoch: 1 | loss: 8150.8214366\n",
            "\tspeed: 0.1887s/iter; left time: 3042.2788s\n",
            "\titers: 2800, epoch: 1 | loss: 7997.0612680\n",
            "\tspeed: 0.1887s/iter; left time: 3023.3722s\n",
            "\titers: 2900, epoch: 1 | loss: 7843.3009876\n",
            "\tspeed: 0.1884s/iter; left time: 2999.5129s\n",
            "\titers: 3000, epoch: 1 | loss: 7689.5409635\n",
            "\tspeed: 0.1898s/iter; left time: 3002.4749s\n",
            "\titers: 3100, epoch: 1 | loss: 7535.7810051\n",
            "\tspeed: 0.1885s/iter; left time: 2963.2992s\n",
            "Epoch: 1, Steps: 3137 | Train Loss: 9889.8553745 Vali Loss: 0.0035724 Test Loss: 0.0053759\n",
            "Validation loss decreased (inf --> 0.003572).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 7325.1292367\n",
            "\tspeed: 0.9421s/iter; left time: 14683.7063s\n",
            "\titers: 200, epoch: 2 | loss: 7171.3691889\n",
            "\tspeed: 0.1905s/iter; left time: 2950.7067s\n",
            "\titers: 300, epoch: 2 | loss: 7017.6093187\n",
            "\tspeed: 0.1890s/iter; left time: 2908.3442s\n",
            "\titers: 400, epoch: 2 | loss: 6863.8489954\n",
            "\tspeed: 0.1888s/iter; left time: 2885.4702s\n",
            "\titers: 500, epoch: 2 | loss: 6710.0891162\n",
            "\tspeed: 0.1897s/iter; left time: 2881.1533s\n",
            "\titers: 600, epoch: 2 | loss: 6556.3288671\n",
            "\tspeed: 0.1886s/iter; left time: 2845.1435s\n",
            "\titers: 700, epoch: 2 | loss: 6402.5686230\n",
            "\tspeed: 0.1889s/iter; left time: 2831.1585s\n",
            "\titers: 800, epoch: 2 | loss: 6248.8087823\n",
            "\tspeed: 0.1894s/iter; left time: 2819.1212s\n",
            "\titers: 900, epoch: 2 | loss: 6095.0484776\n",
            "\tspeed: 0.1891s/iter; left time: 2796.6071s\n",
            "\titers: 1000, epoch: 2 | loss: 5941.2883397\n",
            "\tspeed: 0.1891s/iter; left time: 2776.6462s\n",
            "\titers: 1100, epoch: 2 | loss: 5787.5283229\n",
            "\tspeed: 0.1891s/iter; left time: 2758.6176s\n",
            "\titers: 1200, epoch: 2 | loss: 5633.7683479\n",
            "\tspeed: 0.1892s/iter; left time: 2740.2466s\n",
            "\titers: 1300, epoch: 2 | loss: 5480.0086048\n",
            "\tspeed: 0.1896s/iter; left time: 2727.5178s\n",
            "\titers: 1400, epoch: 2 | loss: 5326.2485865\n",
            "\tspeed: 0.1893s/iter; left time: 2704.7121s\n",
            "\titers: 1500, epoch: 2 | loss: 5172.4883047\n",
            "\tspeed: 0.1899s/iter; left time: 2694.2230s\n",
            "\titers: 1600, epoch: 2 | loss: 5018.7283235\n",
            "\tspeed: 0.1887s/iter; left time: 2658.6507s\n",
            "\titers: 1700, epoch: 2 | loss: 4864.9682143\n",
            "\tspeed: 0.1894s/iter; left time: 2648.2783s\n",
            "\titers: 1800, epoch: 2 | loss: 4711.2083614\n",
            "\tspeed: 0.1895s/iter; left time: 2631.0560s\n",
            "\titers: 1900, epoch: 2 | loss: 4557.4481095\n",
            "\tspeed: 0.1892s/iter; left time: 2607.9835s\n",
            "\titers: 2000, epoch: 2 | loss: 4403.6882492\n",
            "\tspeed: 0.1895s/iter; left time: 2592.9244s\n",
            "\titers: 2100, epoch: 2 | loss: 4249.9281270\n",
            "\tspeed: 0.1896s/iter; left time: 2575.9752s\n",
            "\titers: 2200, epoch: 2 | loss: 4096.1679780\n",
            "\tspeed: 0.1892s/iter; left time: 2551.9914s\n",
            "\titers: 2300, epoch: 2 | loss: 3942.4078449\n",
            "\tspeed: 0.1884s/iter; left time: 2522.3724s\n",
            "\titers: 2400, epoch: 2 | loss: 3788.6479039\n",
            "\tspeed: 0.1899s/iter; left time: 2522.9820s\n",
            "\titers: 2500, epoch: 2 | loss: 3634.8879413\n",
            "\tspeed: 0.1889s/iter; left time: 2490.6225s\n",
            "\titers: 2600, epoch: 2 | loss: 3481.1278990\n",
            "\tspeed: 0.1889s/iter; left time: 2471.5574s\n",
            "\titers: 2700, epoch: 2 | loss: 3327.3678803\n",
            "\tspeed: 0.1897s/iter; left time: 2463.3471s\n",
            "\titers: 2800, epoch: 2 | loss: 3173.6078760\n",
            "\tspeed: 0.1896s/iter; left time: 2443.0037s\n",
            "\titers: 2900, epoch: 2 | loss: 3019.8476179\n",
            "\tspeed: 0.1893s/iter; left time: 2420.0261s\n",
            "\titers: 3000, epoch: 2 | loss: 2866.0882692\n",
            "\tspeed: 0.1894s/iter; left time: 2402.4218s\n",
            "\titers: 3100, epoch: 2 | loss: 2712.3278410\n",
            "\tspeed: 0.1895s/iter; left time: 2385.1426s\n",
            "Epoch: 2, Steps: 3137 | Train Loss: 5066.3940028 Vali Loss: 0.0023550 Test Loss: 0.0040583\n",
            "Validation loss decreased (0.003572 --> 0.002355).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 2577.7877883\n",
            "\tspeed: 0.9376s/iter; left time: 11672.5234s\n",
            "\titers: 200, epoch: 3 | loss: 2500.9079630\n",
            "\tspeed: 0.1886s/iter; left time: 2328.6053s\n",
            "\titers: 300, epoch: 3 | loss: 2424.0278934\n",
            "\tspeed: 0.1896s/iter; left time: 2322.7895s\n",
            "\titers: 400, epoch: 3 | loss: 2347.1479485\n",
            "\tspeed: 0.1883s/iter; left time: 2288.1614s\n",
            "\titers: 500, epoch: 3 | loss: 2270.2679211\n",
            "\tspeed: 0.1895s/iter; left time: 2282.9244s\n",
            "\titers: 600, epoch: 3 | loss: 2193.3879387\n",
            "\tspeed: 0.1890s/iter; left time: 2257.8851s\n",
            "\titers: 700, epoch: 3 | loss: 2116.5078467\n",
            "\tspeed: 0.1887s/iter; left time: 2235.5962s\n",
            "\titers: 800, epoch: 3 | loss: 2039.6278466\n",
            "\tspeed: 0.1895s/iter; left time: 2226.0277s\n",
            "\titers: 900, epoch: 3 | loss: 1962.7476958\n",
            "\tspeed: 0.1892s/iter; left time: 2203.9680s\n",
            "\titers: 1000, epoch: 3 | loss: 1885.8676645\n",
            "\tspeed: 0.1895s/iter; left time: 2188.7537s\n",
            "\titers: 1100, epoch: 3 | loss: 1808.9876518\n",
            "\tspeed: 0.1895s/iter; left time: 2169.2320s\n",
            "\titers: 1200, epoch: 3 | loss: 1732.1079445\n",
            "\tspeed: 0.1893s/iter; left time: 2148.5719s\n",
            "\titers: 1300, epoch: 3 | loss: 1655.2275684\n",
            "\tspeed: 0.1893s/iter; left time: 2129.8696s\n",
            "\titers: 1400, epoch: 3 | loss: 1578.3477443\n",
            "\tspeed: 0.1899s/iter; left time: 2116.8860s\n",
            "\titers: 1500, epoch: 3 | loss: 1501.4676701\n",
            "\tspeed: 0.1891s/iter; left time: 2088.9576s\n",
            "\titers: 1600, epoch: 3 | loss: 1424.5877232\n",
            "\tspeed: 0.1882s/iter; left time: 2060.6490s\n",
            "\titers: 1700, epoch: 3 | loss: 1347.7076605\n",
            "\tspeed: 0.1887s/iter; left time: 2047.5420s\n",
            "\titers: 1800, epoch: 3 | loss: 1270.8278774\n",
            "\tspeed: 0.1893s/iter; left time: 2034.8357s\n",
            "\titers: 1900, epoch: 3 | loss: 1193.9477523\n",
            "\tspeed: 0.1885s/iter; left time: 2006.9715s\n",
            "\titers: 2000, epoch: 3 | loss: 1117.0677279\n",
            "\tspeed: 0.1895s/iter; left time: 1998.5408s\n",
            "\titers: 2100, epoch: 3 | loss: 1040.1875892\n",
            "\tspeed: 0.1882s/iter; left time: 1966.5667s\n",
            "\titers: 2200, epoch: 3 | loss: 963.3078011\n",
            "\tspeed: 0.1887s/iter; left time: 1953.1408s\n",
            "\titers: 2300, epoch: 3 | loss: 886.4277314\n",
            "\tspeed: 0.1891s/iter; left time: 1938.1509s\n",
            "\titers: 2400, epoch: 3 | loss: 809.5476816\n",
            "\tspeed: 0.1898s/iter; left time: 1925.8355s\n",
            "\titers: 2500, epoch: 3 | loss: 732.6676063\n",
            "\tspeed: 0.1892s/iter; left time: 1901.5891s\n",
            "\titers: 2600, epoch: 3 | loss: 655.7875230\n",
            "\tspeed: 0.1891s/iter; left time: 1880.9292s\n",
            "\titers: 2700, epoch: 3 | loss: 578.9075778\n",
            "\tspeed: 0.1897s/iter; left time: 1868.8089s\n",
            "\titers: 2800, epoch: 3 | loss: 502.0276712\n",
            "\tspeed: 0.1893s/iter; left time: 1845.4390s\n",
            "\titers: 2900, epoch: 3 | loss: 425.1479933\n",
            "\tspeed: 0.1897s/iter; left time: 1829.9354s\n",
            "\titers: 3000, epoch: 3 | loss: 348.2676382\n",
            "\tspeed: 0.1891s/iter; left time: 1805.8440s\n",
            "\titers: 3100, epoch: 3 | loss: 271.3875830\n",
            "\tspeed: 0.1901s/iter; left time: 1796.1035s\n",
            "Epoch: 3, Steps: 3137 | Train Loss: 1448.4205282 Vali Loss: 0.0021132 Test Loss: 0.0037861\n",
            "Validation loss decreased (0.002355 --> 0.002113).  Saving model ...\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 204.1176663\n",
            "\tspeed: 0.9383s/iter; left time: 8737.0696s\n",
            "\titers: 200, epoch: 4 | loss: 165.6776519\n",
            "\tspeed: 0.1895s/iter; left time: 1745.4520s\n",
            "\titers: 300, epoch: 4 | loss: 127.2375205\n",
            "\tspeed: 0.1896s/iter; left time: 1727.6524s\n",
            "\titers: 400, epoch: 4 | loss: 88.7976018\n",
            "\tspeed: 0.1895s/iter; left time: 1707.5768s\n",
            "\titers: 500, epoch: 4 | loss: 50.3575642\n",
            "\tspeed: 0.1892s/iter; left time: 1686.3775s\n",
            "\titers: 600, epoch: 4 | loss: 11.9179863\n",
            "\tspeed: 0.1896s/iter; left time: 1670.7036s\n",
            "\titers: 700, epoch: 4 | loss: 0.0244082\n",
            "\tspeed: 0.1890s/iter; left time: 1646.9558s\n",
            "\titers: 800, epoch: 4 | loss: 0.1669220\n",
            "\tspeed: 0.1886s/iter; left time: 1624.2409s\n",
            "\titers: 900, epoch: 4 | loss: 0.1626253\n",
            "\tspeed: 0.1899s/iter; left time: 1616.5217s\n",
            "\titers: 1000, epoch: 4 | loss: 0.0236380\n",
            "\tspeed: 0.1898s/iter; left time: 1596.2853s\n",
            "\titers: 1100, epoch: 4 | loss: 0.1670434\n",
            "\tspeed: 0.1905s/iter; left time: 1583.5843s\n",
            "\titers: 1200, epoch: 4 | loss: 0.1626550\n",
            "\tspeed: 0.1891s/iter; left time: 1553.0594s\n",
            "\titers: 1300, epoch: 4 | loss: 0.0233350\n",
            "\tspeed: 0.1893s/iter; left time: 1535.5782s\n",
            "\titers: 1400, epoch: 4 | loss: 0.1673517\n",
            "\tspeed: 0.1895s/iter; left time: 1518.0576s\n",
            "\titers: 1500, epoch: 4 | loss: 0.1627213\n",
            "\tspeed: 0.1893s/iter; left time: 1497.9312s\n",
            "\titers: 1600, epoch: 4 | loss: 0.0235116\n",
            "\tspeed: 0.1892s/iter; left time: 1477.9049s\n",
            "\titers: 1700, epoch: 4 | loss: 0.1671845\n",
            "\tspeed: 0.1892s/iter; left time: 1459.0434s\n",
            "\titers: 1800, epoch: 4 | loss: 0.1625559\n",
            "\tspeed: 0.1902s/iter; left time: 1447.6984s\n",
            "\titers: 1900, epoch: 4 | loss: 0.0235946\n",
            "\tspeed: 0.1892s/iter; left time: 1421.0410s\n",
            "\titers: 2000, epoch: 4 | loss: 0.1670960\n",
            "\tspeed: 0.1892s/iter; left time: 1402.3945s\n",
            "\titers: 2100, epoch: 4 | loss: 0.1626256\n",
            "\tspeed: 0.1900s/iter; left time: 1389.0965s\n",
            "\titers: 2200, epoch: 4 | loss: 0.0233597\n",
            "\tspeed: 0.1900s/iter; left time: 1370.5843s\n",
            "\titers: 2300, epoch: 4 | loss: 0.1673308\n",
            "\tspeed: 0.1897s/iter; left time: 1349.4632s\n",
            "\titers: 2400, epoch: 4 | loss: 0.1627610\n",
            "\tspeed: 0.1896s/iter; left time: 1329.6911s\n",
            "\titers: 2500, epoch: 4 | loss: 0.0233365\n",
            "\tspeed: 0.1890s/iter; left time: 1306.0718s\n",
            "\titers: 2600, epoch: 4 | loss: 0.1670280\n",
            "\tspeed: 0.1899s/iter; left time: 1293.3588s\n",
            "\titers: 2700, epoch: 4 | loss: 0.1625496\n",
            "\tspeed: 0.1900s/iter; left time: 1275.0571s\n",
            "\titers: 2800, epoch: 4 | loss: 0.0233821\n",
            "\tspeed: 0.1890s/iter; left time: 1249.5147s\n",
            "\titers: 2900, epoch: 4 | loss: 0.1670211\n",
            "\tspeed: 0.1894s/iter; left time: 1233.4006s\n",
            "\titers: 3000, epoch: 4 | loss: 0.1626373\n",
            "\tspeed: 0.1892s/iter; left time: 1213.0079s\n",
            "\titers: 3100, epoch: 4 | loss: 0.0236155\n",
            "\tspeed: 0.1889s/iter; left time: 1192.6331s\n",
            "Epoch: 4, Steps: 3137 | Train Loss: 24.4604669 Vali Loss: 0.0020268 Test Loss: 0.0036250\n",
            "Validation loss decreased (0.002113 --> 0.002027).  Saving model ...\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 5 | loss: 0.0071469\n",
            "\tspeed: 0.9386s/iter; left time: 5795.7642s\n",
            "\titers: 200, epoch: 5 | loss: 0.0362986\n",
            "\tspeed: 0.1887s/iter; left time: 1146.2871s\n",
            "\titers: 300, epoch: 5 | loss: 0.0045756\n",
            "\tspeed: 0.1888s/iter; left time: 1128.3000s\n",
            "\titers: 400, epoch: 5 | loss: 0.0103233\n",
            "\tspeed: 0.1885s/iter; left time: 1107.3711s\n",
            "\titers: 500, epoch: 5 | loss: 0.0318465\n",
            "\tspeed: 0.1897s/iter; left time: 1095.3045s\n",
            "\titers: 600, epoch: 5 | loss: 0.0095990\n",
            "\tspeed: 0.1879s/iter; left time: 1066.4205s\n",
            "\titers: 700, epoch: 5 | loss: 0.0162618\n",
            "\tspeed: 0.1892s/iter; left time: 1054.8270s\n",
            "\titers: 800, epoch: 5 | loss: 0.0243212\n",
            "\tspeed: 0.1901s/iter; left time: 1040.7059s\n",
            "\titers: 900, epoch: 5 | loss: 0.0193022\n",
            "\tspeed: 0.1892s/iter; left time: 1016.8879s\n",
            "\titers: 1000, epoch: 5 | loss: 0.0281008\n",
            "\tspeed: 0.1887s/iter; left time: 995.6082s\n",
            "\titers: 1100, epoch: 5 | loss: 0.0100777\n",
            "\tspeed: 0.1890s/iter; left time: 977.8482s\n",
            "\titers: 1200, epoch: 5 | loss: 0.0077985\n",
            "\tspeed: 0.1894s/iter; left time: 961.3276s\n",
            "\titers: 1300, epoch: 5 | loss: 0.0047651\n",
            "\tspeed: 0.1891s/iter; left time: 940.9753s\n",
            "\titers: 1400, epoch: 5 | loss: 0.0009234\n",
            "\tspeed: 0.1890s/iter; left time: 921.5546s\n",
            "\titers: 1500, epoch: 5 | loss: 0.0053534\n",
            "\tspeed: 0.1890s/iter; left time: 902.6462s\n",
            "\titers: 1600, epoch: 5 | loss: 0.0380340\n",
            "\tspeed: 0.1887s/iter; left time: 882.4040s\n",
            "\titers: 1700, epoch: 5 | loss: 0.0021157\n",
            "\tspeed: 0.1895s/iter; left time: 866.9288s\n",
            "\titers: 1800, epoch: 5 | loss: 0.0069541\n",
            "\tspeed: 0.1890s/iter; left time: 845.6963s\n",
            "\titers: 1900, epoch: 5 | loss: 0.0359018\n",
            "\tspeed: 0.1883s/iter; left time: 823.9900s\n",
            "\titers: 2000, epoch: 5 | loss: 0.0045991\n",
            "\tspeed: 0.1888s/iter; left time: 807.0658s\n",
            "\titers: 2100, epoch: 5 | loss: 0.0101131\n",
            "\tspeed: 0.1884s/iter; left time: 786.6631s\n",
            "\titers: 2200, epoch: 5 | loss: 0.0320117\n",
            "\tspeed: 0.1884s/iter; left time: 767.7469s\n",
            "\titers: 2300, epoch: 5 | loss: 0.0096213\n",
            "\tspeed: 0.1890s/iter; left time: 751.3026s\n",
            "\titers: 2400, epoch: 5 | loss: 0.0165717\n",
            "\tspeed: 0.1902s/iter; left time: 737.1327s\n",
            "\titers: 2500, epoch: 5 | loss: 0.0244793\n",
            "\tspeed: 0.1895s/iter; left time: 715.2701s\n",
            "\titers: 2600, epoch: 5 | loss: 0.0190969\n",
            "\tspeed: 0.1889s/iter; left time: 694.2735s\n",
            "\titers: 2700, epoch: 5 | loss: 0.0278161\n",
            "\tspeed: 0.1890s/iter; left time: 675.4988s\n",
            "\titers: 2800, epoch: 5 | loss: 0.0100750\n",
            "\tspeed: 0.1889s/iter; left time: 656.2565s\n",
            "\titers: 2900, epoch: 5 | loss: 0.0076383\n",
            "\tspeed: 0.1886s/iter; left time: 636.4244s\n",
            "\titers: 3000, epoch: 5 | loss: 0.0047043\n",
            "\tspeed: 0.1891s/iter; left time: 619.1400s\n",
            "\titers: 3100, epoch: 5 | loss: 0.0009025\n",
            "\tspeed: 0.1882s/iter; left time: 597.4669s\n",
            "Epoch: 5, Steps: 3137 | Train Loss: 0.0167038 Vali Loss: 0.0019808 Test Loss: 0.0035549\n",
            "Validation loss decreased (0.002027 --> 0.001981).  Saving model ...\n",
            "Updating learning rate to 6.25e-06\n",
            "\titers: 100, epoch: 6 | loss: 0.0014338\n",
            "\tspeed: 0.9351s/iter; left time: 2840.9274s\n",
            "\titers: 200, epoch: 6 | loss: 0.0014653\n",
            "\tspeed: 0.1893s/iter; left time: 556.0819s\n",
            "\titers: 300, epoch: 6 | loss: 0.0013753\n",
            "\tspeed: 0.1889s/iter; left time: 536.1129s\n",
            "\titers: 400, epoch: 6 | loss: 0.0015349\n",
            "\tspeed: 0.1885s/iter; left time: 516.1570s\n",
            "\titers: 500, epoch: 6 | loss: 0.0013365\n",
            "\tspeed: 0.1893s/iter; left time: 499.4915s\n",
            "\titers: 600, epoch: 6 | loss: 0.0015128\n",
            "\tspeed: 0.1888s/iter; left time: 479.0562s\n",
            "\titers: 700, epoch: 6 | loss: 0.0013264\n",
            "\tspeed: 0.1889s/iter; left time: 460.6141s\n",
            "\titers: 800, epoch: 6 | loss: 0.0014250\n",
            "\tspeed: 0.1898s/iter; left time: 443.6539s\n",
            "\titers: 900, epoch: 6 | loss: 0.0015229\n",
            "\tspeed: 0.1893s/iter; left time: 423.6453s\n",
            "\titers: 1000, epoch: 6 | loss: 0.0013973\n",
            "\tspeed: 0.1889s/iter; left time: 403.8066s\n",
            "\titers: 1100, epoch: 6 | loss: 0.0014695\n",
            "\tspeed: 0.1895s/iter; left time: 386.1204s\n",
            "\titers: 1200, epoch: 6 | loss: 0.0013366\n",
            "\tspeed: 0.1893s/iter; left time: 366.9430s\n",
            "\titers: 1300, epoch: 6 | loss: 0.0014300\n",
            "\tspeed: 0.1883s/iter; left time: 346.0365s\n",
            "\titers: 1400, epoch: 6 | loss: 0.0014215\n",
            "\tspeed: 0.1885s/iter; left time: 327.5407s\n",
            "\titers: 1500, epoch: 6 | loss: 0.0014253\n",
            "\tspeed: 0.1889s/iter; left time: 309.3553s\n",
            "\titers: 1600, epoch: 6 | loss: 0.0017302\n",
            "\tspeed: 0.1877s/iter; left time: 288.7521s\n",
            "\titers: 1700, epoch: 6 | loss: 0.0013033\n",
            "\tspeed: 0.1888s/iter; left time: 271.4993s\n",
            "\titers: 1800, epoch: 6 | loss: 0.0016646\n",
            "\tspeed: 0.1889s/iter; left time: 252.7798s\n",
            "\titers: 1900, epoch: 6 | loss: 0.0014899\n",
            "\tspeed: 0.1881s/iter; left time: 232.8444s\n",
            "\titers: 2000, epoch: 6 | loss: 0.0014923\n",
            "\tspeed: 0.1890s/iter; left time: 215.0345s\n",
            "\titers: 2100, epoch: 6 | loss: 0.0016285\n",
            "\tspeed: 0.1883s/iter; left time: 195.4957s\n",
            "\titers: 2200, epoch: 6 | loss: 0.0013774\n",
            "\tspeed: 0.1892s/iter; left time: 177.4605s\n",
            "\titers: 2300, epoch: 6 | loss: 0.0018544\n",
            "\tspeed: 0.1893s/iter; left time: 158.6742s\n",
            "\titers: 2400, epoch: 6 | loss: 0.0013455\n",
            "\tspeed: 0.1886s/iter; left time: 139.1608s\n",
            "\titers: 2500, epoch: 6 | loss: 0.0016076\n",
            "\tspeed: 0.1884s/iter; left time: 120.1894s\n",
            "\titers: 2600, epoch: 6 | loss: 0.0012971\n",
            "\tspeed: 0.1890s/iter; left time: 101.6874s\n",
            "\titers: 2700, epoch: 6 | loss: 0.0015521\n",
            "\tspeed: 0.1886s/iter; left time: 82.5956s\n",
            "\titers: 2800, epoch: 6 | loss: 0.0015490\n",
            "\tspeed: 0.1886s/iter; left time: 63.7523s\n",
            "\titers: 2900, epoch: 6 | loss: 0.0014575\n",
            "\tspeed: 0.1894s/iter; left time: 45.0702s\n",
            "\titers: 3000, epoch: 6 | loss: 0.0015085\n",
            "\tspeed: 0.1888s/iter; left time: 26.0537s\n",
            "\titers: 3100, epoch: 6 | loss: 0.0013345\n",
            "\tspeed: 0.1897s/iter; left time: 7.2090s\n",
            "Epoch: 6, Steps: 3137 | Train Loss: 0.0082026 Vali Loss: 0.0019607 Test Loss: 0.0035202\n",
            "Validation loss decreased (0.001981 --> 0.001961).  Saving model ...\n",
            "Updating learning rate to 3.125e-06\n",
            ">>>>>>>testing : gta_WADI_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 156847\n",
            "test shape: (784, 200, 1, 124) (784, 200, 1, 124)\n",
            "test shape: (156800, 1, 124) (156800, 1, 124)\n",
            "mse:0.00351998489042323, mae:0.02723090677962733\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : gta_WADI_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 627568\n",
            "val 39166\n",
            "test 156847\n",
            "\titers: 100, epoch: 1 | loss: 12148.6185035\n",
            "\tspeed: 0.1881s/iter; left time: 3521.4364s\n",
            "\titers: 200, epoch: 1 | loss: 11994.8464336\n",
            "\tspeed: 0.1891s/iter; left time: 3522.4666s\n",
            "\titers: 300, epoch: 1 | loss: 11841.0811545\n",
            "\tspeed: 0.1898s/iter; left time: 3515.2112s\n",
            "\titers: 400, epoch: 1 | loss: 11687.3158504\n",
            "\tspeed: 0.1895s/iter; left time: 3491.9946s\n",
            "\titers: 500, epoch: 1 | loss: 11533.5533736\n",
            "\tspeed: 0.1896s/iter; left time: 3473.1448s\n",
            "\titers: 600, epoch: 1 | loss: 11379.7911371\n",
            "\tspeed: 0.1900s/iter; left time: 3462.7044s\n",
            "\titers: 700, epoch: 1 | loss: 11226.0299861\n",
            "\tspeed: 0.1898s/iter; left time: 3440.0783s\n",
            "\titers: 800, epoch: 1 | loss: 11072.2684445\n",
            "\tspeed: 0.1893s/iter; left time: 3410.9430s\n",
            "\titers: 900, epoch: 1 | loss: 10918.5073695\n",
            "\tspeed: 0.1899s/iter; left time: 3403.3294s\n",
            "\titers: 1000, epoch: 1 | loss: 10764.7469886\n",
            "\tspeed: 0.1892s/iter; left time: 3371.4304s\n",
            "\titers: 1100, epoch: 1 | loss: 10610.9857591\n",
            "\tspeed: 0.1888s/iter; left time: 3345.2570s\n",
            "\titers: 1200, epoch: 1 | loss: 10457.2253652\n",
            "\tspeed: 0.1894s/iter; left time: 3337.0195s\n",
            "\titers: 1300, epoch: 1 | loss: 10303.4645389\n",
            "\tspeed: 0.1893s/iter; left time: 3317.3032s\n",
            "\titers: 1400, epoch: 1 | loss: 10149.7043463\n",
            "\tspeed: 0.1897s/iter; left time: 3304.4867s\n",
            "\titers: 1500, epoch: 1 | loss: 9995.9440329\n",
            "\tspeed: 0.1889s/iter; left time: 3273.1691s\n",
            "\titers: 1600, epoch: 1 | loss: 9842.1837866\n",
            "\tspeed: 0.1894s/iter; left time: 3262.4097s\n",
            "\titers: 1700, epoch: 1 | loss: 9688.4232694\n",
            "\tspeed: 0.1895s/iter; left time: 3244.0354s\n",
            "\titers: 1800, epoch: 1 | loss: 9534.6629696\n",
            "\tspeed: 0.1893s/iter; left time: 3222.7290s\n",
            "\titers: 1900, epoch: 1 | loss: 9380.9028634\n",
            "\tspeed: 0.1893s/iter; left time: 3203.0065s\n",
            "\titers: 2000, epoch: 1 | loss: 9227.1424732\n",
            "\tspeed: 0.1893s/iter; left time: 3184.9995s\n",
            "\titers: 2100, epoch: 1 | loss: 9073.3822504\n",
            "\tspeed: 0.1890s/iter; left time: 3160.0692s\n",
            "\titers: 2200, epoch: 1 | loss: 8919.6216846\n",
            "\tspeed: 0.1885s/iter; left time: 3133.5166s\n",
            "\titers: 2300, epoch: 1 | loss: 8765.8614651\n",
            "\tspeed: 0.1897s/iter; left time: 3134.9494s\n",
            "\titers: 2400, epoch: 1 | loss: 8612.1014996\n",
            "\tspeed: 0.1892s/iter; left time: 3106.6754s\n",
            "\titers: 2500, epoch: 1 | loss: 8458.3409708\n",
            "\tspeed: 0.1900s/iter; left time: 3101.9223s\n",
            "\titers: 2600, epoch: 1 | loss: 8304.5812429\n",
            "\tspeed: 0.1891s/iter; left time: 3068.3456s\n",
            "\titers: 2700, epoch: 1 | loss: 8150.8210112\n",
            "\tspeed: 0.1890s/iter; left time: 3047.2423s\n",
            "\titers: 2800, epoch: 1 | loss: 7997.0607073\n",
            "\tspeed: 0.1891s/iter; left time: 3030.0287s\n",
            "\titers: 2900, epoch: 1 | loss: 7843.3006328\n",
            "\tspeed: 0.1886s/iter; left time: 3003.3991s\n",
            "\titers: 3000, epoch: 1 | loss: 7689.5404917\n",
            "\tspeed: 0.1890s/iter; left time: 2989.9877s\n",
            "\titers: 3100, epoch: 1 | loss: 7535.7804013\n",
            "\tspeed: 0.1892s/iter; left time: 2974.1808s\n",
            "Epoch: 1, Steps: 3137 | Train Loss: 9889.8543696 Vali Loss: 0.0036779 Test Loss: 0.0057928\n",
            "Validation loss decreased (inf --> 0.003678).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 7325.1293726\n",
            "\tspeed: 0.9402s/iter; left time: 14654.1708s\n",
            "\titers: 200, epoch: 2 | loss: 7171.3688136\n",
            "\tspeed: 0.1898s/iter; left time: 2939.2932s\n",
            "\titers: 300, epoch: 2 | loss: 7017.6088310\n",
            "\tspeed: 0.1899s/iter; left time: 2922.3673s\n",
            "\titers: 400, epoch: 2 | loss: 6863.8487925\n",
            "\tspeed: 0.1895s/iter; left time: 2896.8150s\n",
            "\titers: 500, epoch: 2 | loss: 6710.0886351\n",
            "\tspeed: 0.1893s/iter; left time: 2875.0192s\n",
            "\titers: 600, epoch: 2 | loss: 6556.3284892\n",
            "\tspeed: 0.1893s/iter; left time: 2855.6363s\n",
            "\titers: 700, epoch: 2 | loss: 6402.5685428\n",
            "\tspeed: 0.1890s/iter; left time: 2832.6560s\n",
            "\titers: 800, epoch: 2 | loss: 6248.8084775\n",
            "\tspeed: 0.1900s/iter; left time: 2828.3123s\n",
            "\titers: 900, epoch: 2 | loss: 6095.0485871\n",
            "\tspeed: 0.1894s/iter; left time: 2800.6706s\n",
            "\titers: 1000, epoch: 2 | loss: 5941.2885851\n",
            "\tspeed: 0.1897s/iter; left time: 2786.3482s\n",
            "\titers: 1100, epoch: 2 | loss: 5787.5281810\n",
            "\tspeed: 0.1887s/iter; left time: 2753.0790s\n",
            "\titers: 1200, epoch: 2 | loss: 5633.7682862\n",
            "\tspeed: 0.1887s/iter; left time: 2733.8489s\n",
            "\titers: 1300, epoch: 2 | loss: 5480.0082598\n",
            "\tspeed: 0.1887s/iter; left time: 2714.5689s\n",
            "\titers: 1400, epoch: 2 | loss: 5326.2481282\n",
            "\tspeed: 0.1888s/iter; left time: 2696.9333s\n",
            "\titers: 1500, epoch: 2 | loss: 5172.4883662\n",
            "\tspeed: 0.1884s/iter; left time: 2673.3456s\n",
            "\titers: 1600, epoch: 2 | loss: 5018.7280948\n",
            "\tspeed: 0.1888s/iter; left time: 2660.0288s\n",
            "\titers: 1700, epoch: 2 | loss: 4864.9681296\n",
            "\tspeed: 0.1889s/iter; left time: 2641.3035s\n",
            "\titers: 1800, epoch: 2 | loss: 4711.2079302\n",
            "\tspeed: 0.1890s/iter; left time: 2625.0187s\n",
            "\titers: 1900, epoch: 2 | loss: 4557.4480378\n",
            "\tspeed: 0.1890s/iter; left time: 2605.3400s\n",
            "\titers: 2000, epoch: 2 | loss: 4403.6880378\n",
            "\tspeed: 0.1887s/iter; left time: 2581.8921s\n",
            "\titers: 2100, epoch: 2 | loss: 4249.9279422\n",
            "\tspeed: 0.1889s/iter; left time: 2566.9460s\n",
            "\titers: 2200, epoch: 2 | loss: 4096.1680022\n",
            "\tspeed: 0.1896s/iter; left time: 2557.2527s\n",
            "\titers: 2300, epoch: 2 | loss: 3942.4081392\n",
            "\tspeed: 0.1889s/iter; left time: 2529.2508s\n",
            "\titers: 2400, epoch: 2 | loss: 3788.6478225\n",
            "\tspeed: 0.1892s/iter; left time: 2513.4670s\n",
            "\titers: 2500, epoch: 2 | loss: 3634.8880476\n",
            "\tspeed: 0.1897s/iter; left time: 2501.4541s\n",
            "\titers: 2600, epoch: 2 | loss: 3481.1279267\n",
            "\tspeed: 0.1901s/iter; left time: 2487.1337s\n",
            "\titers: 2700, epoch: 2 | loss: 3327.3681513\n",
            "\tspeed: 0.1894s/iter; left time: 2459.0204s\n",
            "\titers: 2800, epoch: 2 | loss: 3173.6079162\n",
            "\tspeed: 0.1900s/iter; left time: 2448.4399s\n",
            "\titers: 2900, epoch: 2 | loss: 3019.8480191\n",
            "\tspeed: 0.1892s/iter; left time: 2419.2768s\n",
            "\titers: 3000, epoch: 2 | loss: 2866.0878379\n",
            "\tspeed: 0.1898s/iter; left time: 2407.8634s\n",
            "\titers: 3100, epoch: 2 | loss: 2712.3278797\n",
            "\tspeed: 0.1894s/iter; left time: 2383.6671s\n",
            "Epoch: 2, Steps: 3137 | Train Loss: 5066.3938517 Vali Loss: 0.0024553 Test Loss: 0.0043258\n",
            "Validation loss decreased (0.003678 --> 0.002455).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 2577.7879113\n",
            "\tspeed: 0.9360s/iter; left time: 11652.1511s\n",
            "\titers: 200, epoch: 3 | loss: 2500.9075875\n",
            "\tspeed: 0.1893s/iter; left time: 2337.1091s\n",
            "\titers: 300, epoch: 3 | loss: 2424.0278508\n",
            "\tspeed: 0.1891s/iter; left time: 2316.0167s\n",
            "\titers: 400, epoch: 3 | loss: 2347.1480752\n",
            "\tspeed: 0.1893s/iter; left time: 2299.2531s\n",
            "\titers: 500, epoch: 3 | loss: 2270.2678438\n",
            "\tspeed: 0.1895s/iter; left time: 2283.3177s\n",
            "\titers: 600, epoch: 3 | loss: 2193.3876934\n",
            "\tspeed: 0.1904s/iter; left time: 2274.7203s\n",
            "\titers: 700, epoch: 3 | loss: 2116.5076709\n",
            "\tspeed: 0.1894s/iter; left time: 2243.6918s\n",
            "\titers: 800, epoch: 3 | loss: 2039.6275961\n",
            "\tspeed: 0.1893s/iter; left time: 2224.0820s\n",
            "\titers: 900, epoch: 3 | loss: 1962.7479640\n",
            "\tspeed: 0.1902s/iter; left time: 2215.9487s\n",
            "\titers: 1000, epoch: 3 | loss: 1885.8677232\n",
            "\tspeed: 0.1899s/iter; left time: 2193.4255s\n",
            "\titers: 1100, epoch: 3 | loss: 1808.9879720\n",
            "\tspeed: 0.1893s/iter; left time: 2166.7910s\n",
            "\titers: 1200, epoch: 3 | loss: 1732.1076166\n",
            "\tspeed: 0.1900s/iter; left time: 2156.0636s\n",
            "\titers: 1300, epoch: 3 | loss: 1655.2277119\n",
            "\tspeed: 0.1895s/iter; left time: 2131.3479s\n",
            "\titers: 1400, epoch: 3 | loss: 1578.3475594\n",
            "\tspeed: 0.1893s/iter; left time: 2110.6817s\n",
            "\titers: 1500, epoch: 3 | loss: 1501.4678349\n",
            "\tspeed: 0.1897s/iter; left time: 2096.5196s\n",
            "\titers: 1600, epoch: 3 | loss: 1424.5881288\n",
            "\tspeed: 0.1909s/iter; left time: 2090.2326s\n",
            "\titers: 1700, epoch: 3 | loss: 1347.7075700\n",
            "\tspeed: 0.1897s/iter; left time: 2058.0154s\n",
            "\titers: 1800, epoch: 3 | loss: 1270.8274719\n",
            "\tspeed: 0.1895s/iter; left time: 2037.1131s\n",
            "\titers: 1900, epoch: 3 | loss: 1193.9476871\n",
            "\tspeed: 0.1892s/iter; left time: 2015.1860s\n",
            "\titers: 2000, epoch: 3 | loss: 1117.0674285\n",
            "\tspeed: 0.1893s/iter; left time: 1997.1156s\n",
            "\titers: 2100, epoch: 3 | loss: 1040.1877822\n",
            "\tspeed: 0.1898s/iter; left time: 1983.5738s\n",
            "\titers: 2200, epoch: 3 | loss: 963.3075491\n",
            "\tspeed: 0.1904s/iter; left time: 1970.4498s\n",
            "\titers: 2300, epoch: 3 | loss: 886.4277996\n",
            "\tspeed: 0.1894s/iter; left time: 1941.5772s\n",
            "\titers: 2400, epoch: 3 | loss: 809.5474914\n",
            "\tspeed: 0.1899s/iter; left time: 1926.8733s\n",
            "\titers: 2500, epoch: 3 | loss: 732.6675479\n",
            "\tspeed: 0.1894s/iter; left time: 1903.5367s\n",
            "\titers: 2600, epoch: 3 | loss: 655.7876673\n",
            "\tspeed: 0.1892s/iter; left time: 1882.5178s\n",
            "\titers: 2700, epoch: 3 | loss: 578.9078026\n",
            "\tspeed: 0.1885s/iter; left time: 1856.8839s\n",
            "\titers: 2800, epoch: 3 | loss: 502.0279684\n",
            "\tspeed: 0.1887s/iter; left time: 1839.4464s\n",
            "\titers: 2900, epoch: 3 | loss: 425.1475753\n",
            "\tspeed: 0.1889s/iter; left time: 1823.0317s\n",
            "\titers: 3000, epoch: 3 | loss: 348.2674520\n",
            "\tspeed: 0.1897s/iter; left time: 1811.2705s\n",
            "\titers: 3100, epoch: 3 | loss: 271.3875667\n",
            "\tspeed: 0.1883s/iter; left time: 1779.1487s\n",
            "Epoch: 3, Steps: 3137 | Train Loss: 1448.4204797 Vali Loss: 0.0021417 Test Loss: 0.0037579\n",
            "Validation loss decreased (0.002455 --> 0.002142).  Saving model ...\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 204.1175564\n",
            "\tspeed: 0.9283s/iter; left time: 8643.9607s\n",
            "\titers: 200, epoch: 4 | loss: 165.6775909\n",
            "\tspeed: 0.1883s/iter; left time: 1734.2633s\n",
            "\titers: 300, epoch: 4 | loss: 127.2379062\n",
            "\tspeed: 0.1888s/iter; left time: 1720.2886s\n",
            "\titers: 400, epoch: 4 | loss: 88.7977142\n",
            "\tspeed: 0.1886s/iter; left time: 1699.2546s\n",
            "\titers: 500, epoch: 4 | loss: 50.3574079\n",
            "\tspeed: 0.1883s/iter; left time: 1678.0767s\n",
            "\titers: 600, epoch: 4 | loss: 11.9175032\n",
            "\tspeed: 0.1884s/iter; left time: 1660.0111s\n",
            "\titers: 700, epoch: 4 | loss: 0.0244355\n",
            "\tspeed: 0.1882s/iter; left time: 1639.5723s\n",
            "\titers: 800, epoch: 4 | loss: 0.1670571\n",
            "\tspeed: 0.1889s/iter; left time: 1626.7685s\n",
            "\titers: 900, epoch: 4 | loss: 0.1626485\n",
            "\tspeed: 0.1883s/iter; left time: 1602.3916s\n",
            "\titers: 1000, epoch: 4 | loss: 0.0234788\n",
            "\tspeed: 0.1887s/iter; left time: 1587.4360s\n",
            "\titers: 1100, epoch: 4 | loss: 0.1670463\n",
            "\tspeed: 0.1883s/iter; left time: 1565.0344s\n",
            "\titers: 1200, epoch: 4 | loss: 0.1625437\n",
            "\tspeed: 0.1886s/iter; left time: 1548.6368s\n",
            "\titers: 1300, epoch: 4 | loss: 0.0234779\n",
            "\tspeed: 0.1887s/iter; left time: 1530.4146s\n",
            "\titers: 1400, epoch: 4 | loss: 0.1669207\n",
            "\tspeed: 0.1881s/iter; left time: 1506.8162s\n",
            "\titers: 1500, epoch: 4 | loss: 0.1626272\n",
            "\tspeed: 0.1878s/iter; left time: 1485.7175s\n",
            "\titers: 1600, epoch: 4 | loss: 0.0235706\n",
            "\tspeed: 0.1885s/iter; left time: 1472.4461s\n",
            "\titers: 1700, epoch: 4 | loss: 0.1669454\n",
            "\tspeed: 0.1889s/iter; left time: 1456.4178s\n",
            "\titers: 1800, epoch: 4 | loss: 0.1626270\n",
            "\tspeed: 0.1886s/iter; left time: 1435.8651s\n",
            "\titers: 1900, epoch: 4 | loss: 0.0234544\n",
            "\tspeed: 0.1897s/iter; left time: 1424.9949s\n",
            "\titers: 2000, epoch: 4 | loss: 0.1669356\n",
            "\tspeed: 0.1888s/iter; left time: 1399.4496s\n",
            "\titers: 2100, epoch: 4 | loss: 0.1628056\n",
            "\tspeed: 0.1888s/iter; left time: 1380.3215s\n",
            "\titers: 2200, epoch: 4 | loss: 0.0235539\n",
            "\tspeed: 0.1892s/iter; left time: 1364.5861s\n",
            "\titers: 2300, epoch: 4 | loss: 0.1669771\n",
            "\tspeed: 0.1877s/iter; left time: 1335.1269s\n",
            "\titers: 2400, epoch: 4 | loss: 0.1625098\n",
            "\tspeed: 0.1881s/iter; left time: 1319.1732s\n",
            "\titers: 2500, epoch: 4 | loss: 0.0235744\n",
            "\tspeed: 0.1883s/iter; left time: 1301.5287s\n",
            "\titers: 2600, epoch: 4 | loss: 0.1670330\n",
            "\tspeed: 0.1892s/iter; left time: 1288.5475s\n",
            "\titers: 2700, epoch: 4 | loss: 0.1624764\n",
            "\tspeed: 0.1879s/iter; left time: 1261.5062s\n",
            "\titers: 2800, epoch: 4 | loss: 0.0234254\n",
            "\tspeed: 0.1878s/iter; left time: 1241.6477s\n",
            "\titers: 2900, epoch: 4 | loss: 0.1669499\n",
            "\tspeed: 0.1885s/iter; left time: 1227.5217s\n",
            "\titers: 3000, epoch: 4 | loss: 0.1625060\n",
            "\tspeed: 0.1885s/iter; left time: 1208.4366s\n",
            "\titers: 3100, epoch: 4 | loss: 0.0234476\n",
            "\tspeed: 0.1887s/iter; left time: 1190.9986s\n",
            "Epoch: 4, Steps: 3137 | Train Loss: 24.4604325 Vali Loss: 0.0020182 Test Loss: 0.0035750\n",
            "Validation loss decreased (0.002142 --> 0.002018).  Saving model ...\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 5 | loss: 0.0068929\n",
            "\tspeed: 0.9347s/iter; left time: 5771.7667s\n",
            "\titers: 200, epoch: 5 | loss: 0.0358638\n",
            "\tspeed: 0.1882s/iter; left time: 1143.1854s\n",
            "\titers: 300, epoch: 5 | loss: 0.0045692\n",
            "\tspeed: 0.1888s/iter; left time: 1128.0876s\n",
            "\titers: 400, epoch: 5 | loss: 0.0100669\n",
            "\tspeed: 0.1882s/iter; left time: 1105.9315s\n",
            "\titers: 500, epoch: 5 | loss: 0.0320970\n",
            "\tspeed: 0.1891s/iter; left time: 1091.8388s\n",
            "\titers: 600, epoch: 5 | loss: 0.0096222\n",
            "\tspeed: 0.1886s/iter; left time: 1070.3148s\n",
            "\titers: 700, epoch: 5 | loss: 0.0161970\n",
            "\tspeed: 0.1890s/iter; left time: 1053.6662s\n",
            "\titers: 800, epoch: 5 | loss: 0.0243077\n",
            "\tspeed: 0.1886s/iter; left time: 1032.7954s\n",
            "\titers: 900, epoch: 5 | loss: 0.0189440\n",
            "\tspeed: 0.1891s/iter; left time: 1016.2389s\n",
            "\titers: 1000, epoch: 5 | loss: 0.0279369\n",
            "\tspeed: 0.1885s/iter; left time: 994.6010s\n",
            "\titers: 1100, epoch: 5 | loss: 0.0102508\n",
            "\tspeed: 0.1882s/iter; left time: 973.8009s\n",
            "\titers: 1200, epoch: 5 | loss: 0.0076692\n",
            "\tspeed: 0.1889s/iter; left time: 958.5366s\n",
            "\titers: 1300, epoch: 5 | loss: 0.0047766\n",
            "\tspeed: 0.1879s/iter; left time: 934.7871s\n",
            "\titers: 1400, epoch: 5 | loss: 0.0010017\n",
            "\tspeed: 0.1882s/iter; left time: 917.4130s\n",
            "\titers: 1500, epoch: 5 | loss: 0.0052286\n",
            "\tspeed: 0.1886s/iter; left time: 900.5923s\n",
            "\titers: 1600, epoch: 5 | loss: 0.0382912\n",
            "\tspeed: 0.1904s/iter; left time: 889.9957s\n",
            "\titers: 1700, epoch: 5 | loss: 0.0021630\n",
            "\tspeed: 0.1888s/iter; left time: 863.7404s\n",
            "\titers: 1800, epoch: 5 | loss: 0.0069816\n",
            "\tspeed: 0.1896s/iter; left time: 848.5569s\n",
            "\titers: 1900, epoch: 5 | loss: 0.0359782\n",
            "\tspeed: 0.1891s/iter; left time: 827.4483s\n",
            "\titers: 2000, epoch: 5 | loss: 0.0045186\n",
            "\tspeed: 0.1888s/iter; left time: 807.0868s\n",
            "\titers: 2100, epoch: 5 | loss: 0.0102851\n",
            "\tspeed: 0.1889s/iter; left time: 788.5989s\n",
            "\titers: 2200, epoch: 5 | loss: 0.0319465\n",
            "\tspeed: 0.1883s/iter; left time: 767.1682s\n",
            "\titers: 2300, epoch: 5 | loss: 0.0096240\n",
            "\tspeed: 0.1885s/iter; left time: 749.1228s\n",
            "\titers: 2400, epoch: 5 | loss: 0.0164252\n",
            "\tspeed: 0.1891s/iter; left time: 732.6501s\n",
            "\titers: 2500, epoch: 5 | loss: 0.0243547\n",
            "\tspeed: 0.1889s/iter; left time: 713.0880s\n",
            "\titers: 2600, epoch: 5 | loss: 0.0190052\n",
            "\tspeed: 0.1888s/iter; left time: 693.8616s\n",
            "\titers: 2700, epoch: 5 | loss: 0.0277783\n",
            "\tspeed: 0.1886s/iter; left time: 674.1157s\n",
            "\titers: 2800, epoch: 5 | loss: 0.0100536\n",
            "\tspeed: 0.1889s/iter; left time: 656.5873s\n",
            "\titers: 2900, epoch: 5 | loss: 0.0076263\n",
            "\tspeed: 0.1893s/iter; left time: 638.7802s\n",
            "\titers: 3000, epoch: 5 | loss: 0.0047079\n",
            "\tspeed: 0.1893s/iter; left time: 620.0362s\n",
            "\titers: 3100, epoch: 5 | loss: 0.0009583\n",
            "\tspeed: 0.1886s/iter; left time: 598.9536s\n",
            "Epoch: 5, Steps: 3137 | Train Loss: 0.0166754 Vali Loss: 0.0019821 Test Loss: 0.0034894\n",
            "Validation loss decreased (0.002018 --> 0.001982).  Saving model ...\n",
            "Updating learning rate to 6.25e-06\n",
            "\titers: 100, epoch: 6 | loss: 0.0013354\n",
            "\tspeed: 0.9351s/iter; left time: 2840.7393s\n",
            "\titers: 200, epoch: 6 | loss: 0.0014603\n",
            "\tspeed: 0.1888s/iter; left time: 554.7282s\n",
            "\titers: 300, epoch: 6 | loss: 0.0016100\n",
            "\tspeed: 0.1888s/iter; left time: 535.9547s\n",
            "\titers: 400, epoch: 6 | loss: 0.0015123\n",
            "\tspeed: 0.1886s/iter; left time: 516.3629s\n",
            "\titers: 500, epoch: 6 | loss: 0.0013257\n",
            "\tspeed: 0.1883s/iter; left time: 496.7720s\n",
            "\titers: 600, epoch: 6 | loss: 0.0013739\n",
            "\tspeed: 0.1902s/iter; left time: 482.8369s\n",
            "\titers: 700, epoch: 6 | loss: 0.0014885\n",
            "\tspeed: 0.1890s/iter; left time: 460.6852s\n",
            "\titers: 800, epoch: 6 | loss: 0.0013282\n",
            "\tspeed: 0.1889s/iter; left time: 441.7427s\n",
            "\titers: 900, epoch: 6 | loss: 0.0014631\n",
            "\tspeed: 0.1886s/iter; left time: 421.9882s\n",
            "\titers: 1000, epoch: 6 | loss: 0.0015494\n",
            "\tspeed: 0.1888s/iter; left time: 403.6784s\n",
            "\titers: 1100, epoch: 6 | loss: 0.0013615\n",
            "\tspeed: 0.1896s/iter; left time: 386.4483s\n",
            "\titers: 1200, epoch: 6 | loss: 0.0016549\n",
            "\tspeed: 0.1892s/iter; left time: 366.7150s\n",
            "\titers: 1300, epoch: 6 | loss: 0.0014742\n",
            "\tspeed: 0.1899s/iter; left time: 349.0207s\n",
            "\titers: 1400, epoch: 6 | loss: 0.0015249\n",
            "\tspeed: 0.1887s/iter; left time: 327.9282s\n",
            "\titers: 1500, epoch: 6 | loss: 0.0014335\n",
            "\tspeed: 0.1895s/iter; left time: 310.3373s\n",
            "\titers: 1600, epoch: 6 | loss: 0.0013299\n",
            "\tspeed: 0.1888s/iter; left time: 290.3548s\n",
            "\titers: 1700, epoch: 6 | loss: 0.0016150\n",
            "\tspeed: 0.1887s/iter; left time: 271.3386s\n",
            "\titers: 1800, epoch: 6 | loss: 0.0016254\n",
            "\tspeed: 0.1885s/iter; left time: 252.2569s\n",
            "\titers: 1900, epoch: 6 | loss: 0.0015169\n",
            "\tspeed: 0.1885s/iter; left time: 233.3884s\n",
            "\titers: 2000, epoch: 6 | loss: 0.0014644\n",
            "\tspeed: 0.1894s/iter; left time: 215.4921s\n",
            "\titers: 2100, epoch: 6 | loss: 0.0015120\n",
            "\tspeed: 0.1881s/iter; left time: 195.2586s\n",
            "\titers: 2200, epoch: 6 | loss: 0.0014349\n",
            "\tspeed: 0.1897s/iter; left time: 177.9566s\n",
            "\titers: 2300, epoch: 6 | loss: 0.0014197\n",
            "\tspeed: 0.1883s/iter; left time: 157.7744s\n",
            "\titers: 2400, epoch: 6 | loss: 0.0013882\n",
            "\tspeed: 0.1892s/iter; left time: 139.6626s\n",
            "\titers: 2500, epoch: 6 | loss: 0.0014346\n",
            "\tspeed: 0.1896s/iter; left time: 120.9741s\n",
            "\titers: 2600, epoch: 6 | loss: 0.0013228\n",
            "\tspeed: 0.1888s/iter; left time: 101.5833s\n",
            "\titers: 2700, epoch: 6 | loss: 0.0014173\n",
            "\tspeed: 0.1888s/iter; left time: 82.7035s\n",
            "\titers: 2800, epoch: 6 | loss: 0.0015871\n",
            "\tspeed: 0.1894s/iter; left time: 64.0174s\n",
            "\titers: 2900, epoch: 6 | loss: 0.0015220\n",
            "\tspeed: 0.1897s/iter; left time: 45.1545s\n",
            "\titers: 3000, epoch: 6 | loss: 0.0015600\n",
            "\tspeed: 0.1890s/iter; left time: 26.0778s\n",
            "\titers: 3100, epoch: 6 | loss: 0.0013250\n",
            "\tspeed: 0.1892s/iter; left time: 7.1913s\n",
            "Epoch: 6, Steps: 3137 | Train Loss: 0.0081762 Vali Loss: 0.0019557 Test Loss: 0.0034378\n",
            "Validation loss decreased (0.001982 --> 0.001956).  Saving model ...\n",
            "Updating learning rate to 3.125e-06\n",
            ">>>>>>>testing : gta_WADI_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 156847\n",
            "test shape: (784, 200, 1, 124) (784, 200, 1, 124)\n",
            "test shape: (156800, 1, 124) (156800, 1, 124)\n",
            "mse:0.0034372471033135817, mae:0.027565465665068397\n",
            "True\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : gta_WADI_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 627567\n",
            "val 39166\n",
            "test 156847\n",
            "\titers: 100, epoch: 1 | loss: 12148.6154545\n",
            "\tspeed: 0.1906s/iter; left time: 3568.7881s\n",
            "\titers: 200, epoch: 1 | loss: 11994.8458920\n",
            "\tspeed: 0.1913s/iter; left time: 3561.8872s\n",
            "\titers: 300, epoch: 1 | loss: 11841.0793831\n",
            "\tspeed: 0.1905s/iter; left time: 3527.7598s\n",
            "\titers: 400, epoch: 1 | loss: 11687.3155596\n",
            "\tspeed: 0.1916s/iter; left time: 3529.2658s\n",
            "\titers: 500, epoch: 1 | loss: 11533.5541562\n",
            "\tspeed: 0.1919s/iter; left time: 3516.1996s\n",
            "\titers: 600, epoch: 1 | loss: 11379.7921053\n",
            "\tspeed: 0.1914s/iter; left time: 3487.1731s\n",
            "\titers: 700, epoch: 1 | loss: 11226.0296434\n",
            "\tspeed: 0.1914s/iter; left time: 3468.1664s\n",
            "\titers: 800, epoch: 1 | loss: 11072.2689468\n",
            "\tspeed: 0.1908s/iter; left time: 3439.5355s\n",
            "\titers: 900, epoch: 1 | loss: 10918.5081617\n",
            "\tspeed: 0.1910s/iter; left time: 3423.0104s\n",
            "\titers: 1000, epoch: 1 | loss: 10764.7471332\n",
            "\tspeed: 0.1900s/iter; left time: 3386.4892s\n",
            "\titers: 1100, epoch: 1 | loss: 10610.9862029\n",
            "\tspeed: 0.1907s/iter; left time: 3379.3631s\n",
            "\titers: 1200, epoch: 1 | loss: 10457.2260099\n",
            "\tspeed: 0.1901s/iter; left time: 3350.8934s\n",
            "\titers: 1300, epoch: 1 | loss: 10303.4650773\n",
            "\tspeed: 0.1915s/iter; left time: 3356.3960s\n",
            "\titers: 1400, epoch: 1 | loss: 10149.7044153\n",
            "\tspeed: 0.1919s/iter; left time: 3343.5190s\n",
            "\titers: 1500, epoch: 1 | loss: 9995.9435245\n",
            "\tspeed: 0.1915s/iter; left time: 3316.7739s\n",
            "\titers: 1600, epoch: 1 | loss: 9842.1831689\n",
            "\tspeed: 0.1906s/iter; left time: 3283.5003s\n",
            "\titers: 1700, epoch: 1 | loss: 9688.4231254\n",
            "\tspeed: 0.1913s/iter; left time: 3275.4480s\n",
            "\titers: 1800, epoch: 1 | loss: 9534.6632393\n",
            "\tspeed: 0.1905s/iter; left time: 3243.0139s\n",
            "\titers: 1900, epoch: 1 | loss: 9380.9023801\n",
            "\tspeed: 0.1904s/iter; left time: 3221.8165s\n",
            "\titers: 2000, epoch: 1 | loss: 9227.1424805\n",
            "\tspeed: 0.1915s/iter; left time: 3221.1580s\n",
            "\titers: 2100, epoch: 1 | loss: 9073.3822618\n",
            "\tspeed: 0.1905s/iter; left time: 3185.9232s\n",
            "\titers: 2200, epoch: 1 | loss: 8919.6217591\n",
            "\tspeed: 0.1914s/iter; left time: 3182.2661s\n",
            "\titers: 2300, epoch: 1 | loss: 8765.8615385\n",
            "\tspeed: 0.1908s/iter; left time: 3152.8974s\n",
            "\titers: 2400, epoch: 1 | loss: 8612.1012467\n",
            "\tspeed: 0.1911s/iter; left time: 3138.7240s\n",
            "\titers: 2500, epoch: 1 | loss: 8458.3411541\n",
            "\tspeed: 0.1905s/iter; left time: 3108.8510s\n",
            "\titers: 2600, epoch: 1 | loss: 8304.5809861\n",
            "\tspeed: 0.1914s/iter; left time: 3105.2537s\n",
            "\titers: 2700, epoch: 1 | loss: 8150.8207190\n",
            "\tspeed: 0.1909s/iter; left time: 3077.5355s\n",
            "\titers: 2800, epoch: 1 | loss: 7997.0604051\n",
            "\tspeed: 0.1913s/iter; left time: 3065.5848s\n",
            "\titers: 2900, epoch: 1 | loss: 7843.3005289\n",
            "\tspeed: 0.1918s/iter; left time: 3053.7324s\n",
            "\titers: 3000, epoch: 1 | loss: 7689.5403558\n",
            "\tspeed: 0.1909s/iter; left time: 3020.5165s\n",
            "\titers: 3100, epoch: 1 | loss: 7535.7805111\n",
            "\tspeed: 0.1911s/iter; left time: 3004.1144s\n",
            "Epoch: 1, Steps: 3137 | Train Loss: 9889.8543755 Vali Loss: 0.0081689 Test Loss: 0.0065727\n",
            "Validation loss decreased (inf --> 0.008169).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 7325.1290660\n",
            "\tspeed: 0.9350s/iter; left time: 14573.4290s\n",
            "\titers: 200, epoch: 2 | loss: 7171.3686945\n",
            "\tspeed: 0.1918s/iter; left time: 2969.7690s\n",
            "\titers: 300, epoch: 2 | loss: 7017.6087002\n",
            "\tspeed: 0.1918s/iter; left time: 2950.4440s\n",
            "\titers: 400, epoch: 2 | loss: 6863.8485114\n",
            "\tspeed: 0.1913s/iter; left time: 2924.9724s\n",
            "\titers: 500, epoch: 2 | loss: 6710.0885194\n",
            "\tspeed: 0.1912s/iter; left time: 2903.7689s\n",
            "\titers: 600, epoch: 2 | loss: 6556.3285047\n",
            "\tspeed: 0.1909s/iter; left time: 2879.6591s\n",
            "\titers: 700, epoch: 2 | loss: 6402.5685138\n",
            "\tspeed: 0.1916s/iter; left time: 2871.9488s\n",
            "\titers: 800, epoch: 2 | loss: 6248.8083108\n",
            "\tspeed: 0.1912s/iter; left time: 2846.8164s\n",
            "\titers: 900, epoch: 2 | loss: 6095.0484039\n",
            "\tspeed: 0.1912s/iter; left time: 2827.6220s\n",
            "\titers: 1000, epoch: 2 | loss: 5941.2883176\n",
            "\tspeed: 0.1911s/iter; left time: 2806.0390s\n",
            "\titers: 1100, epoch: 2 | loss: 5787.5282577\n",
            "\tspeed: 0.1909s/iter; left time: 2785.0666s\n",
            "\titers: 1200, epoch: 2 | loss: 5633.7683342\n",
            "\tspeed: 0.1910s/iter; left time: 2766.7019s\n",
            "\titers: 1300, epoch: 2 | loss: 5480.0082583\n",
            "\tspeed: 0.1912s/iter; left time: 2751.1586s\n",
            "\titers: 1400, epoch: 2 | loss: 5326.2479984\n",
            "\tspeed: 0.1913s/iter; left time: 2733.5497s\n",
            "\titers: 1500, epoch: 2 | loss: 5172.4881456\n",
            "\tspeed: 0.1906s/iter; left time: 2704.4625s\n",
            "\titers: 1600, epoch: 2 | loss: 5018.7281085\n",
            "\tspeed: 0.1917s/iter; left time: 2700.8100s\n",
            "\titers: 1700, epoch: 2 | loss: 4864.9681191\n",
            "\tspeed: 0.1916s/iter; left time: 2679.9061s\n",
            "\titers: 1800, epoch: 2 | loss: 4711.2082218\n",
            "\tspeed: 0.1907s/iter; left time: 2648.1107s\n",
            "\titers: 1900, epoch: 2 | loss: 4557.4479392\n",
            "\tspeed: 0.1903s/iter; left time: 2623.2945s\n",
            "\titers: 2000, epoch: 2 | loss: 4403.6879074\n",
            "\tspeed: 0.1913s/iter; left time: 2618.5481s\n",
            "\titers: 2100, epoch: 2 | loss: 4249.9277710\n",
            "\tspeed: 0.1913s/iter; left time: 2598.9322s\n",
            "\titers: 2200, epoch: 2 | loss: 4096.1680065\n",
            "\tspeed: 0.1909s/iter; left time: 2574.5255s\n",
            "\titers: 2300, epoch: 2 | loss: 3942.4082184\n",
            "\tspeed: 0.1917s/iter; left time: 2565.6144s\n",
            "\titers: 2400, epoch: 2 | loss: 3788.6478143\n",
            "\tspeed: 0.1906s/iter; left time: 2532.1613s\n",
            "\titers: 2500, epoch: 2 | loss: 3634.8877965\n",
            "\tspeed: 0.1913s/iter; left time: 2522.6666s\n",
            "\titers: 2600, epoch: 2 | loss: 3481.1277451\n",
            "\tspeed: 0.1916s/iter; left time: 2507.1621s\n",
            "\titers: 2700, epoch: 2 | loss: 3327.3677541\n",
            "\tspeed: 0.1914s/iter; left time: 2485.1648s\n",
            "\titers: 2800, epoch: 2 | loss: 3173.6077719\n",
            "\tspeed: 0.1915s/iter; left time: 2468.2485s\n",
            "\titers: 2900, epoch: 2 | loss: 3019.8477549\n",
            "\tspeed: 0.1910s/iter; left time: 2441.6285s\n",
            "\titers: 3000, epoch: 2 | loss: 2866.0878788\n",
            "\tspeed: 0.1913s/iter; left time: 2427.2092s\n",
            "\titers: 3100, epoch: 2 | loss: 2712.3275475\n",
            "\tspeed: 0.1904s/iter; left time: 2396.6394s\n",
            "Epoch: 2, Steps: 3137 | Train Loss: 5066.3938106 Vali Loss: 0.0067818 Test Loss: 0.0051450\n",
            "Validation loss decreased (0.008169 --> 0.006782).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 2577.7878620\n",
            "\tspeed: 0.9402s/iter; left time: 11703.9975s\n",
            "\titers: 200, epoch: 3 | loss: 2500.9076199\n",
            "\tspeed: 0.1915s/iter; left time: 2364.4050s\n",
            "\titers: 300, epoch: 3 | loss: 2424.0277189\n",
            "\tspeed: 0.1908s/iter; left time: 2336.8305s\n",
            "\titers: 400, epoch: 3 | loss: 2347.1478265\n",
            "\tspeed: 0.1911s/iter; left time: 2321.3353s\n",
            "\titers: 500, epoch: 3 | loss: 2270.2677024\n",
            "\tspeed: 0.1905s/iter; left time: 2295.5987s\n",
            "\titers: 600, epoch: 3 | loss: 2193.3878935\n",
            "\tspeed: 0.1906s/iter; left time: 2277.2524s\n",
            "\titers: 700, epoch: 3 | loss: 2116.5078409\n",
            "\tspeed: 0.1916s/iter; left time: 2269.9590s\n",
            "\titers: 800, epoch: 3 | loss: 2039.6276040\n",
            "\tspeed: 0.1904s/iter; left time: 2236.8939s\n",
            "\titers: 900, epoch: 3 | loss: 1962.7477695\n",
            "\tspeed: 0.1906s/iter; left time: 2219.8999s\n",
            "\titers: 1000, epoch: 3 | loss: 1885.8678129\n",
            "\tspeed: 0.1916s/iter; left time: 2213.3607s\n",
            "\titers: 1100, epoch: 3 | loss: 1808.9876405\n",
            "\tspeed: 0.1912s/iter; left time: 2189.6007s\n",
            "\titers: 1200, epoch: 3 | loss: 1732.1076282\n",
            "\tspeed: 0.1909s/iter; left time: 2166.0139s\n",
            "\titers: 1300, epoch: 3 | loss: 1655.2275908\n",
            "\tspeed: 0.1912s/iter; left time: 2150.6630s\n",
            "\titers: 1400, epoch: 3 | loss: 1578.3477413\n",
            "\tspeed: 0.1910s/iter; left time: 2129.0857s\n",
            "\titers: 1500, epoch: 3 | loss: 1501.4677887\n",
            "\tspeed: 0.1911s/iter; left time: 2111.4591s\n",
            "\titers: 1600, epoch: 3 | loss: 1424.5875805\n",
            "\tspeed: 0.1905s/iter; left time: 2085.8579s\n",
            "\titers: 1700, epoch: 3 | loss: 1347.7076692\n",
            "\tspeed: 0.1905s/iter; left time: 2067.0611s\n",
            "\titers: 1800, epoch: 3 | loss: 1270.8276876\n",
            "\tspeed: 0.1910s/iter; left time: 2053.1936s\n",
            "\titers: 1900, epoch: 3 | loss: 1193.9477380\n",
            "\tspeed: 0.1912s/iter; left time: 2036.4838s\n",
            "\titers: 2000, epoch: 3 | loss: 1117.0676412\n",
            "\tspeed: 0.1906s/iter; left time: 2010.8778s\n",
            "\titers: 2100, epoch: 3 | loss: 1040.1874941\n",
            "\tspeed: 0.1903s/iter; left time: 1988.3872s\n",
            "\titers: 2200, epoch: 3 | loss: 963.3075053\n",
            "\tspeed: 0.1900s/iter; left time: 1966.3351s\n",
            "\titers: 2300, epoch: 3 | loss: 886.4275973\n",
            "\tspeed: 0.1902s/iter; left time: 1949.6814s\n",
            "\titers: 2400, epoch: 3 | loss: 809.5475236\n",
            "\tspeed: 0.1911s/iter; left time: 1939.3427s\n",
            "\titers: 2500, epoch: 3 | loss: 732.6677098\n",
            "\tspeed: 0.1903s/iter; left time: 1912.5250s\n",
            "\titers: 2600, epoch: 3 | loss: 655.7875590\n",
            "\tspeed: 0.1917s/iter; left time: 1907.1768s\n",
            "\titers: 2700, epoch: 3 | loss: 578.9076635\n",
            "\tspeed: 0.1903s/iter; left time: 1874.7168s\n",
            "\titers: 2800, epoch: 3 | loss: 502.0275130\n",
            "\tspeed: 0.1921s/iter; left time: 1872.3327s\n",
            "\titers: 2900, epoch: 3 | loss: 425.1474591\n",
            "\tspeed: 0.1912s/iter; left time: 1845.1775s\n",
            "\titers: 3000, epoch: 3 | loss: 348.2676010\n",
            "\tspeed: 0.1914s/iter; left time: 1827.5366s\n",
            "\titers: 3100, epoch: 3 | loss: 271.3878157\n",
            "\tspeed: 0.1906s/iter; left time: 1800.7885s\n",
            "Epoch: 3, Steps: 3137 | Train Loss: 1448.4204772 Vali Loss: 0.0061955 Test Loss: 0.0046686\n",
            "Validation loss decreased (0.006782 --> 0.006196).  Saving model ...\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 204.1176755\n",
            "\tspeed: 0.9356s/iter; left time: 8712.5812s\n",
            "\titers: 200, epoch: 4 | loss: 165.6775855\n",
            "\tspeed: 0.1920s/iter; left time: 1768.3977s\n",
            "\titers: 300, epoch: 4 | loss: 127.2374652\n",
            "\tspeed: 0.1907s/iter; left time: 1737.9163s\n",
            "\titers: 400, epoch: 4 | loss: 88.7974751\n",
            "\tspeed: 0.1908s/iter; left time: 1719.2600s\n",
            "\titers: 500, epoch: 4 | loss: 50.3574805\n",
            "\tspeed: 0.1911s/iter; left time: 1703.1320s\n",
            "\titers: 600, epoch: 4 | loss: 11.9174816\n",
            "\tspeed: 0.1919s/iter; left time: 1691.2709s\n",
            "\titers: 700, epoch: 4 | loss: 0.0245089\n",
            "\tspeed: 0.1913s/iter; left time: 1666.4777s\n",
            "\titers: 800, epoch: 4 | loss: 0.1669632\n",
            "\tspeed: 0.1910s/iter; left time: 1645.2562s\n",
            "\titers: 900, epoch: 4 | loss: 0.1626927\n",
            "\tspeed: 0.1908s/iter; left time: 1624.0401s\n",
            "\titers: 1000, epoch: 4 | loss: 0.0235801\n",
            "\tspeed: 0.1907s/iter; left time: 1604.5700s\n",
            "\titers: 1100, epoch: 4 | loss: 0.1669266\n",
            "\tspeed: 0.1917s/iter; left time: 1593.8000s\n",
            "\titers: 1200, epoch: 4 | loss: 0.1625060\n",
            "\tspeed: 0.1905s/iter; left time: 1564.2419s\n",
            "\titers: 1300, epoch: 4 | loss: 0.0236076\n",
            "\tspeed: 0.1906s/iter; left time: 1546.3942s\n",
            "\titers: 1400, epoch: 4 | loss: 0.1669962\n",
            "\tspeed: 0.1908s/iter; left time: 1528.8488s\n",
            "\titers: 1500, epoch: 4 | loss: 0.1624626\n",
            "\tspeed: 0.1907s/iter; left time: 1508.7636s\n",
            "\titers: 1600, epoch: 4 | loss: 0.0233619\n",
            "\tspeed: 0.1915s/iter; left time: 1496.1504s\n",
            "\titers: 1700, epoch: 4 | loss: 0.1668548\n",
            "\tspeed: 0.1906s/iter; left time: 1469.5639s\n",
            "\titers: 1800, epoch: 4 | loss: 0.1626584\n",
            "\tspeed: 0.1907s/iter; left time: 1451.8061s\n",
            "\titers: 1900, epoch: 4 | loss: 0.0233962\n",
            "\tspeed: 0.1905s/iter; left time: 1431.0900s\n",
            "\titers: 2000, epoch: 4 | loss: 0.1669499\n",
            "\tspeed: 0.1904s/iter; left time: 1411.3896s\n",
            "\titers: 2100, epoch: 4 | loss: 0.1626598\n",
            "\tspeed: 0.1900s/iter; left time: 1389.2118s\n",
            "\titers: 2200, epoch: 4 | loss: 0.0234228\n",
            "\tspeed: 0.1914s/iter; left time: 1380.0375s\n",
            "\titers: 2300, epoch: 4 | loss: 0.1669241\n",
            "\tspeed: 0.1907s/iter; left time: 1356.0852s\n",
            "\titers: 2400, epoch: 4 | loss: 0.1628838\n",
            "\tspeed: 0.1908s/iter; left time: 1338.1905s\n",
            "\titers: 2500, epoch: 4 | loss: 0.0234255\n",
            "\tspeed: 0.1911s/iter; left time: 1320.9083s\n",
            "\titers: 2600, epoch: 4 | loss: 0.1668670\n",
            "\tspeed: 0.1916s/iter; left time: 1304.8443s\n",
            "\titers: 2700, epoch: 4 | loss: 0.1626404\n",
            "\tspeed: 0.1911s/iter; left time: 1282.5182s\n",
            "\titers: 2800, epoch: 4 | loss: 0.0233657\n",
            "\tspeed: 0.1909s/iter; left time: 1262.1450s\n",
            "\titers: 2900, epoch: 4 | loss: 0.1673302\n",
            "\tspeed: 0.1914s/iter; left time: 1246.1808s\n",
            "\titers: 3000, epoch: 4 | loss: 0.1625742\n",
            "\tspeed: 0.1906s/iter; left time: 1222.3792s\n",
            "\titers: 3100, epoch: 4 | loss: 0.0233326\n",
            "\tspeed: 0.1919s/iter; left time: 1211.4299s\n",
            "Epoch: 4, Steps: 3137 | Train Loss: 24.4604286 Vali Loss: 0.0058668 Test Loss: 0.0044073\n",
            "Validation loss decreased (0.006196 --> 0.005867).  Saving model ...\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 5 | loss: 0.0068057\n",
            "\tspeed: 0.9375s/iter; left time: 5789.3315s\n",
            "\titers: 200, epoch: 5 | loss: 0.0358969\n",
            "\tspeed: 0.1907s/iter; left time: 1158.6599s\n",
            "\titers: 300, epoch: 5 | loss: 0.0046626\n",
            "\tspeed: 0.1909s/iter; left time: 1140.5412s\n",
            "\titers: 400, epoch: 5 | loss: 0.0100450\n",
            "\tspeed: 0.1912s/iter; left time: 1123.4087s\n",
            "\titers: 500, epoch: 5 | loss: 0.0321974\n",
            "\tspeed: 0.1913s/iter; left time: 1104.7746s\n",
            "\titers: 600, epoch: 5 | loss: 0.0095358\n",
            "\tspeed: 0.1925s/iter; left time: 1092.3200s\n",
            "\titers: 700, epoch: 5 | loss: 0.0163859\n",
            "\tspeed: 0.1911s/iter; left time: 1065.4974s\n",
            "\titers: 800, epoch: 5 | loss: 0.0243848\n",
            "\tspeed: 0.1908s/iter; left time: 1044.5032s\n",
            "\titers: 900, epoch: 5 | loss: 0.0189893\n",
            "\tspeed: 0.1910s/iter; left time: 1026.4594s\n",
            "\titers: 1000, epoch: 5 | loss: 0.0277894\n",
            "\tspeed: 0.1913s/iter; left time: 1008.9518s\n",
            "\titers: 1100, epoch: 5 | loss: 0.0103806\n",
            "\tspeed: 0.1907s/iter; left time: 986.6780s\n",
            "\titers: 1200, epoch: 5 | loss: 0.0077182\n",
            "\tspeed: 0.1917s/iter; left time: 972.6681s\n",
            "\titers: 1300, epoch: 5 | loss: 0.0045513\n",
            "\tspeed: 0.1911s/iter; left time: 950.7049s\n",
            "\titers: 1400, epoch: 5 | loss: 0.0010031\n",
            "\tspeed: 0.1908s/iter; left time: 930.2267s\n",
            "\titers: 1500, epoch: 5 | loss: 0.0052334\n",
            "\tspeed: 0.1914s/iter; left time: 913.8783s\n",
            "\titers: 1600, epoch: 5 | loss: 0.0379781\n",
            "\tspeed: 0.1910s/iter; left time: 893.1066s\n",
            "\titers: 1700, epoch: 5 | loss: 0.0020067\n",
            "\tspeed: 0.1915s/iter; left time: 876.3256s\n",
            "\titers: 1800, epoch: 5 | loss: 0.0069450\n",
            "\tspeed: 0.1910s/iter; left time: 854.6867s\n",
            "\titers: 1900, epoch: 5 | loss: 0.0359713\n",
            "\tspeed: 0.1905s/iter; left time: 833.6313s\n",
            "\titers: 2000, epoch: 5 | loss: 0.0045416\n",
            "\tspeed: 0.1912s/iter; left time: 817.2752s\n",
            "\titers: 2100, epoch: 5 | loss: 0.0102775\n",
            "\tspeed: 0.1912s/iter; left time: 798.3177s\n",
            "\titers: 2200, epoch: 5 | loss: 0.0319983\n",
            "\tspeed: 0.1919s/iter; left time: 781.8420s\n",
            "\titers: 2300, epoch: 5 | loss: 0.0095618\n",
            "\tspeed: 0.1914s/iter; left time: 760.9299s\n",
            "\titers: 2400, epoch: 5 | loss: 0.0162301\n",
            "\tspeed: 0.1914s/iter; left time: 741.8484s\n",
            "\titers: 2500, epoch: 5 | loss: 0.0243087\n",
            "\tspeed: 0.1911s/iter; left time: 721.4118s\n",
            "\titers: 2600, epoch: 5 | loss: 0.0189283\n",
            "\tspeed: 0.1909s/iter; left time: 701.4938s\n",
            "\titers: 2700, epoch: 5 | loss: 0.0277466\n",
            "\tspeed: 0.1917s/iter; left time: 685.4251s\n",
            "\titers: 2800, epoch: 5 | loss: 0.0101315\n",
            "\tspeed: 0.1914s/iter; left time: 665.0299s\n",
            "\titers: 2900, epoch: 5 | loss: 0.0077304\n",
            "\tspeed: 0.1914s/iter; left time: 645.8944s\n",
            "\titers: 3000, epoch: 5 | loss: 0.0045361\n",
            "\tspeed: 0.1912s/iter; left time: 626.2939s\n",
            "\titers: 3100, epoch: 5 | loss: 0.0009794\n",
            "\tspeed: 0.1920s/iter; left time: 609.4842s\n",
            "Epoch: 5, Steps: 3137 | Train Loss: 0.0166706 Vali Loss: 0.0057158 Test Loss: 0.0042815\n",
            "Validation loss decreased (0.005867 --> 0.005716).  Saving model ...\n",
            "Updating learning rate to 6.25e-06\n",
            "\titers: 100, epoch: 6 | loss: 0.0014868\n",
            "\tspeed: 0.9358s/iter; left time: 2842.9634s\n",
            "\titers: 200, epoch: 6 | loss: 0.0014306\n",
            "\tspeed: 0.1916s/iter; left time: 562.8573s\n",
            "\titers: 300, epoch: 6 | loss: 0.0014647\n",
            "\tspeed: 0.1921s/iter; left time: 545.2716s\n",
            "\titers: 400, epoch: 6 | loss: 0.0013589\n",
            "\tspeed: 0.1906s/iter; left time: 521.9288s\n",
            "\titers: 500, epoch: 6 | loss: 0.0015802\n",
            "\tspeed: 0.1911s/iter; left time: 504.1767s\n",
            "\titers: 600, epoch: 6 | loss: 0.0013224\n",
            "\tspeed: 0.1912s/iter; left time: 485.3243s\n",
            "\titers: 700, epoch: 6 | loss: 0.0013371\n",
            "\tspeed: 0.1898s/iter; left time: 462.6903s\n",
            "\titers: 800, epoch: 6 | loss: 0.0013896\n",
            "\tspeed: 0.1909s/iter; left time: 446.3875s\n",
            "\titers: 900, epoch: 6 | loss: 0.0014776\n",
            "\tspeed: 0.1908s/iter; left time: 426.9309s\n",
            "\titers: 1000, epoch: 6 | loss: 0.0018631\n",
            "\tspeed: 0.1909s/iter; left time: 408.0602s\n",
            "\titers: 1100, epoch: 6 | loss: 0.0014326\n",
            "\tspeed: 0.1905s/iter; left time: 388.1761s\n",
            "\titers: 1200, epoch: 6 | loss: 0.0013210\n",
            "\tspeed: 0.1909s/iter; left time: 369.9758s\n",
            "\titers: 1300, epoch: 6 | loss: 0.0015436\n",
            "\tspeed: 0.1904s/iter; left time: 350.0279s\n",
            "\titers: 1400, epoch: 6 | loss: 0.0014124\n",
            "\tspeed: 0.1912s/iter; left time: 332.3050s\n",
            "\titers: 1500, epoch: 6 | loss: 0.0014628\n",
            "\tspeed: 0.1907s/iter; left time: 312.3996s\n",
            "\titers: 1600, epoch: 6 | loss: 0.0014187\n",
            "\tspeed: 0.1906s/iter; left time: 293.1987s\n",
            "\titers: 1700, epoch: 6 | loss: 0.0013322\n",
            "\tspeed: 0.1915s/iter; left time: 275.3975s\n",
            "\titers: 1800, epoch: 6 | loss: 0.0015346\n",
            "\tspeed: 0.1904s/iter; left time: 254.7270s\n",
            "\titers: 1900, epoch: 6 | loss: 0.0014507\n",
            "\tspeed: 0.1906s/iter; left time: 235.9915s\n",
            "\titers: 2000, epoch: 6 | loss: 0.0014433\n",
            "\tspeed: 0.1899s/iter; left time: 216.0527s\n",
            "\titers: 2100, epoch: 6 | loss: 0.0012996\n",
            "\tspeed: 0.1912s/iter; left time: 198.4144s\n",
            "\titers: 2200, epoch: 6 | loss: 0.0014854\n",
            "\tspeed: 0.1903s/iter; left time: 178.4893s\n",
            "\titers: 2300, epoch: 6 | loss: 0.0013547\n",
            "\tspeed: 0.1900s/iter; left time: 159.1925s\n",
            "\titers: 2400, epoch: 6 | loss: 0.0012940\n",
            "\tspeed: 0.1908s/iter; left time: 140.8394s\n",
            "\titers: 2500, epoch: 6 | loss: 0.0016105\n",
            "\tspeed: 0.1902s/iter; left time: 121.3158s\n",
            "\titers: 2600, epoch: 6 | loss: 0.0013596\n",
            "\tspeed: 0.1905s/iter; left time: 102.4763s\n",
            "\titers: 2700, epoch: 6 | loss: 0.0014375\n",
            "\tspeed: 0.1904s/iter; left time: 83.3954s\n",
            "\titers: 2800, epoch: 6 | loss: 0.0016043\n",
            "\tspeed: 0.1902s/iter; left time: 64.2772s\n",
            "\titers: 2900, epoch: 6 | loss: 0.0014582\n",
            "\tspeed: 0.1904s/iter; left time: 45.3269s\n",
            "\titers: 3000, epoch: 6 | loss: 0.0014091\n",
            "\tspeed: 0.1907s/iter; left time: 26.3231s\n",
            "\titers: 3100, epoch: 6 | loss: 0.0013388\n",
            "\tspeed: 0.1908s/iter; left time: 7.2510s\n",
            "Epoch: 6, Steps: 3137 | Train Loss: 0.0081705 Vali Loss: 0.0056160 Test Loss: 0.0042056\n",
            "Validation loss decreased (0.005716 --> 0.005616).  Saving model ...\n",
            "Updating learning rate to 3.125e-06\n",
            ">>>>>>>testing : gta_WADI_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 156847\n",
            "test shape: (784, 200, 1, 124) (784, 200, 1, 124)\n",
            "test shape: (156800, 1, 124) (156800, 1, 124)\n",
            "mse:0.004205389078424142, mae:0.029038268403756284\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : gta_WADI_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 627567\n",
            "val 39166\n",
            "test 156847\n",
            "\titers: 100, epoch: 1 | loss: 12148.6167117\n",
            "\tspeed: 0.1903s/iter; left time: 3562.3836s\n",
            "\titers: 200, epoch: 1 | loss: 11994.8448250\n",
            "\tspeed: 0.1920s/iter; left time: 3575.3818s\n",
            "\titers: 300, epoch: 1 | loss: 11841.0797730\n",
            "\tspeed: 0.1910s/iter; left time: 3537.7398s\n",
            "\titers: 400, epoch: 1 | loss: 11687.3154117\n",
            "\tspeed: 0.1914s/iter; left time: 3526.9521s\n",
            "\titers: 500, epoch: 1 | loss: 11533.5527830\n",
            "\tspeed: 0.1912s/iter; left time: 3503.4603s\n",
            "\titers: 600, epoch: 1 | loss: 11379.7911079\n",
            "\tspeed: 0.1911s/iter; left time: 3482.9028s\n",
            "\titers: 700, epoch: 1 | loss: 11226.0291290\n",
            "\tspeed: 0.1919s/iter; left time: 3478.4176s\n",
            "\titers: 800, epoch: 1 | loss: 11072.2684261\n",
            "\tspeed: 0.1911s/iter; left time: 3444.7454s\n",
            "Traceback (most recent call last):\n",
            "  File \"main_gta_dad.py\", line 77, in <module>\n",
            "    exp.train(setting)\n",
            "  File \"/content/drive/MyDrive/Colab_Notebooks/GTA/exp/exp_gta_dad.py\", line 185, in train\n",
            "    model_optim.step()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\", line 153, in step\n",
            "    maximize=group['maximize'])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\", line 105, in adam\n",
            "    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n",
            "KeyboardInterrupt\n",
            "True\n",
            "Use GPU: cuda:0\n",
            "Traceback (most recent call last):\n",
            "  File \"main_gta_dad.py\", line 75, in <module>\n",
            "    exp = Exp(args)\n",
            "  File \"/content/drive/MyDrive/Colab_Notebooks/GTA/exp/exp_gta_dad.py\", line 29, in __init__\n",
            "    super(Exp_GTA_DAD, self).__init__(args)\n",
            "  File \"/content/drive/MyDrive/Colab_Notebooks/GTA/exp/exp_basic.py\", line 9, in __init__\n",
            "    self.model = self._build_model().to(self.device)\n",
            "  File \"/content/drive/MyDrive/Colab_Notebooks/GTA/exp/exp_gta_dad.py\", line 53, in _build_model\n",
            "    self.device\n",
            "  File \"/content/drive/MyDrive/Colab_Notebooks/GTA/models/gta.py\", line 140, in __init__\n",
            "    self.gt_embedding = GraphTemporalEmbedding(num_nodes, seq_len, num_levels, kernel_size=3, dropout=dropout, device=device)\n",
            "  File \"/content/drive/MyDrive/Colab_Notebooks/GTA/models/gta.py\", line 108, in __init__\n",
            "    self.edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long, device=self.device)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "Sod3NUbuSRQH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxCnfFl7JEEv",
        "outputId": "6ab2934f-7766-4a35-9b2e-12ebdd3837ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : gta_WADI_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 784477\n",
            "val 43140\n",
            "test 172741\n",
            "\titers: 100, epoch: 1 | loss: 12148.6167375\n",
            "\tspeed: 0.1955s/iter; left time: 4580.4969s\n",
            "\titers: 200, epoch: 1 | loss: 11994.8463578\n",
            "\tspeed: 0.1946s/iter; left time: 4541.5170s\n",
            "\titers: 300, epoch: 1 | loss: 11841.0799758\n",
            "\tspeed: 0.1943s/iter; left time: 4513.1592s\n",
            "\titers: 400, epoch: 1 | loss: 11687.3170648\n",
            "\tspeed: 0.1946s/iter; left time: 4500.6547s\n",
            "\titers: 500, epoch: 1 | loss: 11533.5549038\n",
            "\tspeed: 0.1946s/iter; left time: 4483.1998s\n",
            "\titers: 600, epoch: 1 | loss: 11379.7922513\n",
            "\tspeed: 0.1949s/iter; left time: 4468.7406s\n",
            "\titers: 700, epoch: 1 | loss: 11226.0305105\n",
            "\tspeed: 0.1941s/iter; left time: 4431.8883s\n",
            "\titers: 800, epoch: 1 | loss: 11072.2687459\n",
            "\tspeed: 0.1956s/iter; left time: 4445.7836s\n",
            "\titers: 900, epoch: 1 | loss: 10918.5081184\n",
            "\tspeed: 0.1957s/iter; left time: 4429.3453s\n",
            "\titers: 1000, epoch: 1 | loss: 10764.7475153\n",
            "\tspeed: 0.1952s/iter; left time: 4398.7779s\n",
            "\titers: 1100, epoch: 1 | loss: 10610.9862742\n",
            "\tspeed: 0.1963s/iter; left time: 4404.1298s\n",
            "\titers: 1200, epoch: 1 | loss: 10457.2261960\n",
            "\tspeed: 0.1946s/iter; left time: 4346.6077s\n",
            "\titers: 1300, epoch: 1 | loss: 10303.4650695\n",
            "\tspeed: 0.1928s/iter; left time: 4286.4351s\n",
            "\titers: 1400, epoch: 1 | loss: 10149.7051531\n",
            "\tspeed: 0.1957s/iter; left time: 4332.1165s\n",
            "\titers: 1500, epoch: 1 | loss: 9995.9443416\n",
            "\tspeed: 0.1950s/iter; left time: 4295.6408s\n",
            "\titers: 1600, epoch: 1 | loss: 9842.1839175\n",
            "\tspeed: 0.1947s/iter; left time: 4269.3624s\n",
            "\titers: 1700, epoch: 1 | loss: 9688.4234118\n",
            "\tspeed: 0.1949s/iter; left time: 4254.4332s\n",
            "\titers: 1800, epoch: 1 | loss: 9534.6635754\n",
            "\tspeed: 0.1949s/iter; left time: 4236.8407s\n",
            "\titers: 1900, epoch: 1 | loss: 9380.9032087\n",
            "\tspeed: 0.1950s/iter; left time: 4218.4313s\n",
            "\titers: 2000, epoch: 1 | loss: 9227.1426626\n",
            "\tspeed: 0.1956s/iter; left time: 4211.2850s\n",
            "\titers: 2100, epoch: 1 | loss: 9073.3824033\n",
            "\tspeed: 0.1951s/iter; left time: 4181.5118s\n",
            "\titers: 2200, epoch: 1 | loss: 8919.6223380\n",
            "\tspeed: 0.1955s/iter; left time: 4170.9280s\n",
            "\titers: 2300, epoch: 1 | loss: 8765.8618843\n",
            "\tspeed: 0.1959s/iter; left time: 4159.1400s\n",
            "\titers: 2400, epoch: 1 | loss: 8612.1020379\n",
            "\tspeed: 0.1958s/iter; left time: 4138.3035s\n",
            "\titers: 2500, epoch: 1 | loss: 8458.3410275\n",
            "\tspeed: 0.1963s/iter; left time: 4129.7651s\n",
            "\titers: 2600, epoch: 1 | loss: 8304.5811964\n",
            "\tspeed: 0.1953s/iter; left time: 4088.3292s\n",
            "\titers: 2700, epoch: 1 | loss: 8150.8209156\n",
            "\tspeed: 0.1956s/iter; left time: 4074.3251s\n",
            "\titers: 2800, epoch: 1 | loss: 7997.0608560\n",
            "\tspeed: 0.1947s/iter; left time: 4037.0150s\n",
            "\titers: 2900, epoch: 1 | loss: 7843.3008890\n",
            "\tspeed: 0.1957s/iter; left time: 4036.9452s\n",
            "\titers: 3000, epoch: 1 | loss: 7689.5408344\n",
            "\tspeed: 0.1950s/iter; left time: 4004.7784s\n",
            "\titers: 3100, epoch: 1 | loss: 7535.7804719\n",
            "\tspeed: 0.1952s/iter; left time: 3988.9997s\n",
            "\titers: 3200, epoch: 1 | loss: 7382.0203345\n",
            "\tspeed: 0.1947s/iter; left time: 3958.0273s\n",
            "\titers: 3300, epoch: 1 | loss: 7228.2602816\n",
            "\tspeed: 0.1956s/iter; left time: 3957.0001s\n",
            "\titers: 3400, epoch: 1 | loss: 7074.5001094\n",
            "\tspeed: 0.1937s/iter; left time: 3899.0915s\n",
            "\titers: 3500, epoch: 1 | loss: 6920.7398423\n",
            "\tspeed: 0.1947s/iter; left time: 3900.6298s\n",
            "\titers: 3600, epoch: 1 | loss: 6766.9799920\n",
            "\tspeed: 0.1946s/iter; left time: 3878.2477s\n",
            "\titers: 3700, epoch: 1 | loss: 6613.2203244\n",
            "\tspeed: 0.1943s/iter; left time: 3854.3518s\n",
            "\titers: 3800, epoch: 1 | loss: 6459.4599241\n",
            "\tspeed: 0.1946s/iter; left time: 3839.2949s\n",
            "\titers: 3900, epoch: 1 | loss: 6305.7001920\n",
            "\tspeed: 0.1952s/iter; left time: 3832.7216s\n",
            "Epoch: 1, Steps: 3922 | Train Loss: 9286.3448657 Vali Loss: 0.0222882 Test Loss: 0.0320856\n",
            "Validation loss decreased (inf --> 0.022288).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 6118.1122561\n",
            "\tspeed: 1.0103s/iter; left time: 19711.1878s\n",
            "\titers: 200, epoch: 2 | loss: 5964.3526261\n",
            "\tspeed: 0.1944s/iter; left time: 3772.5984s\n",
            "\titers: 300, epoch: 2 | loss: 5810.5923776\n",
            "\tspeed: 0.1938s/iter; left time: 3742.8740s\n",
            "\titers: 400, epoch: 2 | loss: 5656.8323798\n",
            "\tspeed: 0.1939s/iter; left time: 3724.5816s\n",
            "\titers: 500, epoch: 2 | loss: 5503.0722195\n",
            "\tspeed: 0.1950s/iter; left time: 3726.0944s\n",
            "\titers: 600, epoch: 2 | loss: 5349.3121380\n",
            "\tspeed: 0.1938s/iter; left time: 3683.8132s\n",
            "\titers: 700, epoch: 2 | loss: 5195.5521631\n",
            "\tspeed: 0.1942s/iter; left time: 3672.6557s\n",
            "\titers: 800, epoch: 2 | loss: 5041.7920699\n",
            "\tspeed: 0.1951s/iter; left time: 3670.7166s\n",
            "\titers: 900, epoch: 2 | loss: 4888.0320326\n",
            "\tspeed: 0.1944s/iter; left time: 3638.1852s\n",
            "\titers: 1000, epoch: 2 | loss: 4734.2721709\n",
            "\tspeed: 0.1947s/iter; left time: 3624.3031s\n",
            "\titers: 1100, epoch: 2 | loss: 4580.5118568\n",
            "\tspeed: 0.1952s/iter; left time: 3612.4371s\n",
            "\titers: 1200, epoch: 2 | loss: 4426.7524617\n",
            "\tspeed: 0.1943s/iter; left time: 3576.4015s\n",
            "\titers: 1300, epoch: 2 | loss: 4272.9918185\n",
            "\tspeed: 0.1958s/iter; left time: 3584.4287s\n",
            "\titers: 1400, epoch: 2 | loss: 4119.2321314\n",
            "\tspeed: 0.1945s/iter; left time: 3541.9517s\n",
            "\titers: 1500, epoch: 2 | loss: 3965.4723310\n",
            "\tspeed: 0.1935s/iter; left time: 3505.0698s\n",
            "\titers: 1600, epoch: 2 | loss: 3811.7119205\n",
            "\tspeed: 0.1941s/iter; left time: 3495.2152s\n",
            "\titers: 1700, epoch: 2 | loss: 3657.9518688\n",
            "\tspeed: 0.1939s/iter; left time: 3473.6991s\n",
            "\titers: 1800, epoch: 2 | loss: 3504.1918610\n",
            "\tspeed: 0.1942s/iter; left time: 3458.2645s\n",
            "\titers: 1900, epoch: 2 | loss: 3350.4319895\n",
            "\tspeed: 0.1938s/iter; left time: 3431.5624s\n",
            "\titers: 2000, epoch: 2 | loss: 3196.6716675\n",
            "\tspeed: 0.1936s/iter; left time: 3408.8518s\n",
            "\titers: 2100, epoch: 2 | loss: 3042.9119348\n",
            "\tspeed: 0.1935s/iter; left time: 3388.8550s\n",
            "\titers: 2200, epoch: 2 | loss: 2889.1520087\n",
            "\tspeed: 0.1935s/iter; left time: 3368.8611s\n",
            "\titers: 2300, epoch: 2 | loss: 2735.3920940\n",
            "\tspeed: 0.1935s/iter; left time: 3350.1474s\n",
            "\titers: 2400, epoch: 2 | loss: 2581.6318919\n",
            "\tspeed: 0.1943s/iter; left time: 3343.8623s\n",
            "\titers: 2500, epoch: 2 | loss: 2427.8717187\n",
            "\tspeed: 0.1939s/iter; left time: 3318.0741s\n",
            "\titers: 2600, epoch: 2 | loss: 2274.1117099\n",
            "\tspeed: 0.1942s/iter; left time: 3302.8247s\n",
            "\titers: 2700, epoch: 2 | loss: 2120.3515864\n",
            "\tspeed: 0.1939s/iter; left time: 3278.3523s\n",
            "\titers: 2800, epoch: 2 | loss: 1966.5917891\n",
            "\tspeed: 0.1938s/iter; left time: 3257.5248s\n",
            "\titers: 2900, epoch: 2 | loss: 1812.8315787\n",
            "\tspeed: 0.1932s/iter; left time: 3228.8311s\n",
            "\titers: 3000, epoch: 2 | loss: 1659.0717757\n",
            "\tspeed: 0.1940s/iter; left time: 3222.2854s\n",
            "\titers: 3100, epoch: 2 | loss: 1505.3116519\n",
            "\tspeed: 0.1937s/iter; left time: 3198.1703s\n",
            "\titers: 3200, epoch: 2 | loss: 1351.5516742\n",
            "\tspeed: 0.1933s/iter; left time: 3172.6360s\n",
            "\titers: 3300, epoch: 2 | loss: 1197.7916596\n",
            "\tspeed: 0.1939s/iter; left time: 3162.4146s\n",
            "\titers: 3400, epoch: 2 | loss: 1044.0316050\n",
            "\tspeed: 0.1930s/iter; left time: 3129.2440s\n",
            "\titers: 3500, epoch: 2 | loss: 890.2716569\n",
            "\tspeed: 0.1938s/iter; left time: 3121.8582s\n",
            "\titers: 3600, epoch: 2 | loss: 736.5114930\n",
            "\tspeed: 0.1940s/iter; left time: 3105.3754s\n",
            "\titers: 3700, epoch: 2 | loss: 582.7514592\n",
            "\tspeed: 0.1943s/iter; left time: 3091.5888s\n",
            "\titers: 3800, epoch: 2 | loss: 428.9916500\n",
            "\tspeed: 0.1944s/iter; left time: 3074.2103s\n",
            "\titers: 3900, epoch: 2 | loss: 275.2317633\n",
            "\tspeed: 0.1948s/iter; left time: 3060.8295s\n",
            "Epoch: 2, Steps: 3922 | Train Loss: 3255.8695200 Vali Loss: 0.0203413 Test Loss: 0.0291131\n",
            "Validation loss decreased (0.022288 --> 0.020341).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 163.7556209\n",
            "\tspeed: 1.0128s/iter; left time: 15789.1572s\n",
            "\titers: 200, epoch: 3 | loss: 86.8756405\n",
            "\tspeed: 0.1936s/iter; left time: 2998.3542s\n",
            "\titers: 300, epoch: 3 | loss: 9.9957916\n",
            "\tspeed: 0.1944s/iter; left time: 2991.6277s\n",
            "\titers: 400, epoch: 3 | loss: 0.0468457\n",
            "\tspeed: 0.1934s/iter; left time: 2957.5998s\n",
            "\titers: 500, epoch: 3 | loss: 0.3323518\n",
            "\tspeed: 0.1935s/iter; left time: 2938.9029s\n",
            "\titers: 600, epoch: 3 | loss: 0.3253867\n",
            "\tspeed: 0.1938s/iter; left time: 2923.9081s\n",
            "\titers: 700, epoch: 3 | loss: 0.0470113\n",
            "\tspeed: 0.1943s/iter; left time: 2912.1713s\n",
            "\titers: 800, epoch: 3 | loss: 0.3321626\n",
            "\tspeed: 0.1938s/iter; left time: 2885.7215s\n",
            "\titers: 900, epoch: 3 | loss: 0.3252968\n",
            "\tspeed: 0.1934s/iter; left time: 2859.6222s\n",
            "\titers: 1000, epoch: 3 | loss: 0.0468190\n",
            "\tspeed: 0.1936s/iter; left time: 2843.4708s\n",
            "\titers: 1100, epoch: 3 | loss: 0.3322023\n",
            "\tspeed: 0.1937s/iter; left time: 2826.2144s\n",
            "\titers: 1200, epoch: 3 | loss: 0.3251580\n",
            "\tspeed: 0.1935s/iter; left time: 2802.9534s\n",
            "\titers: 1300, epoch: 3 | loss: 0.0469175\n",
            "\tspeed: 0.1945s/iter; left time: 2799.0334s\n",
            "\titers: 1400, epoch: 3 | loss: 0.3322840\n",
            "\tspeed: 0.1944s/iter; left time: 2778.4334s\n",
            "\titers: 1500, epoch: 3 | loss: 0.3254057\n",
            "\tspeed: 0.1943s/iter; left time: 2757.1629s\n",
            "\titers: 1600, epoch: 3 | loss: 0.0468868\n",
            "\tspeed: 0.1937s/iter; left time: 2729.2561s\n",
            "\titers: 1700, epoch: 3 | loss: 0.3322938\n",
            "\tspeed: 0.1940s/iter; left time: 2713.9346s\n",
            "\titers: 1800, epoch: 3 | loss: 0.3252271\n",
            "\tspeed: 0.1942s/iter; left time: 2697.3719s\n",
            "\titers: 1900, epoch: 3 | loss: 0.0468440\n",
            "\tspeed: 0.1942s/iter; left time: 2678.0436s\n",
            "\titers: 2000, epoch: 3 | loss: 0.3325013\n",
            "\tspeed: 0.1936s/iter; left time: 2650.8398s\n",
            "\titers: 2100, epoch: 3 | loss: 0.3251272\n",
            "\tspeed: 0.1944s/iter; left time: 2641.0588s\n",
            "\titers: 2200, epoch: 3 | loss: 0.0467703\n",
            "\tspeed: 0.1934s/iter; left time: 2609.3971s\n",
            "\titers: 2300, epoch: 3 | loss: 0.3322666\n",
            "\tspeed: 0.1934s/iter; left time: 2588.8523s\n",
            "\titers: 2400, epoch: 3 | loss: 0.3252640\n",
            "\tspeed: 0.1938s/iter; left time: 2575.3988s\n",
            "\titers: 2500, epoch: 3 | loss: 0.0467646\n",
            "\tspeed: 0.1945s/iter; left time: 2565.5960s\n",
            "\titers: 2600, epoch: 3 | loss: 0.3325286\n",
            "\tspeed: 0.1934s/iter; left time: 2531.3232s\n",
            "\titers: 2700, epoch: 3 | loss: 0.3251705\n",
            "\tspeed: 0.1949s/iter; left time: 2531.7865s\n",
            "\titers: 2800, epoch: 3 | loss: 0.0469333\n",
            "\tspeed: 0.1938s/iter; left time: 2497.5529s\n",
            "\titers: 2900, epoch: 3 | loss: 0.3321892\n",
            "\tspeed: 0.1945s/iter; left time: 2487.7030s\n",
            "\titers: 3000, epoch: 3 | loss: 0.3252910\n",
            "\tspeed: 0.1948s/iter; left time: 2472.1780s\n",
            "\titers: 3100, epoch: 3 | loss: 0.0467327\n",
            "\tspeed: 0.1935s/iter; left time: 2435.5944s\n",
            "\titers: 3200, epoch: 3 | loss: 0.3321850\n",
            "\tspeed: 0.1950s/iter; left time: 2435.7138s\n",
            "\titers: 3300, epoch: 3 | loss: 0.3251244\n",
            "\tspeed: 0.1948s/iter; left time: 2413.7476s\n",
            "\titers: 3400, epoch: 3 | loss: 0.0469706\n",
            "\tspeed: 0.1957s/iter; left time: 2404.8254s\n",
            "\titers: 3500, epoch: 3 | loss: 0.3321939\n",
            "\tspeed: 0.1946s/iter; left time: 2372.1200s\n",
            "\titers: 3600, epoch: 3 | loss: 0.3251274\n",
            "\tspeed: 0.1927s/iter; left time: 2329.9166s\n",
            "\titers: 3700, epoch: 3 | loss: 0.0467830\n",
            "\tspeed: 0.1948s/iter; left time: 2336.0467s\n",
            "\titers: 3800, epoch: 3 | loss: 0.3322332\n",
            "\tspeed: 0.1947s/iter; left time: 2314.9199s\n",
            "\titers: 3900, epoch: 3 | loss: 0.3253625\n",
            "\tspeed: 0.1947s/iter; left time: 2294.8435s\n",
            "Epoch: 3, Steps: 3922 | Train Loss: 9.8070468 Vali Loss: 0.0197475 Test Loss: 0.0285906\n",
            "Validation loss decreased (0.020341 --> 0.019748).  Saving model ...\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 0.0800718\n",
            "\tspeed: 1.0162s/iter; left time: 11856.0964s\n",
            "\titers: 200, epoch: 4 | loss: 0.0529423\n",
            "\tspeed: 0.1959s/iter; left time: 2265.9419s\n",
            "\titers: 300, epoch: 4 | loss: 0.0018296\n",
            "\tspeed: 0.1949s/iter; left time: 2235.4209s\n",
            "\titers: 400, epoch: 4 | loss: 0.0089891\n",
            "\tspeed: 0.1950s/iter; left time: 2216.6871s\n",
            "\titers: 500, epoch: 4 | loss: 0.1480894\n",
            "\tspeed: 0.1952s/iter; left time: 2198.9708s\n",
            "\titers: 600, epoch: 4 | loss: 0.0567926\n",
            "\tspeed: 0.1950s/iter; left time: 2177.8903s\n",
            "\titers: 700, epoch: 4 | loss: 0.0615747\n",
            "\tspeed: 0.1947s/iter; left time: 2155.1500s\n",
            "\titers: 800, epoch: 4 | loss: 0.0799742\n",
            "\tspeed: 0.1951s/iter; left time: 2139.1592s\n",
            "\titers: 900, epoch: 4 | loss: 0.0530866\n",
            "\tspeed: 0.1944s/iter; left time: 2113.0057s\n",
            "\titers: 1000, epoch: 4 | loss: 0.0019035\n",
            "\tspeed: 0.1945s/iter; left time: 2093.7454s\n",
            "\titers: 1100, epoch: 4 | loss: 0.0090026\n",
            "\tspeed: 0.1949s/iter; left time: 2078.8014s\n",
            "\titers: 1200, epoch: 4 | loss: 0.1483214\n",
            "\tspeed: 0.1940s/iter; left time: 2049.7483s\n",
            "\titers: 1300, epoch: 4 | loss: 0.0570252\n",
            "\tspeed: 0.1949s/iter; left time: 2039.6376s\n",
            "\titers: 1400, epoch: 4 | loss: 0.0614057\n",
            "\tspeed: 0.1940s/iter; left time: 2010.9117s\n",
            "\titers: 1500, epoch: 4 | loss: 0.0800854\n",
            "\tspeed: 0.1944s/iter; left time: 1996.3347s\n",
            "\titers: 1600, epoch: 4 | loss: 0.0528986\n",
            "\tspeed: 0.1936s/iter; left time: 1968.3575s\n",
            "\titers: 1700, epoch: 4 | loss: 0.0018952\n",
            "\tspeed: 0.1950s/iter; left time: 1963.4815s\n",
            "\titers: 1800, epoch: 4 | loss: 0.0091265\n",
            "\tspeed: 0.1943s/iter; left time: 1936.5950s\n",
            "\titers: 1900, epoch: 4 | loss: 0.1482891\n",
            "\tspeed: 0.1936s/iter; left time: 1910.3014s\n",
            "\titers: 2000, epoch: 4 | loss: 0.0568545\n",
            "\tspeed: 0.1931s/iter; left time: 1886.0964s\n",
            "\titers: 2100, epoch: 4 | loss: 0.0615300\n",
            "\tspeed: 0.1945s/iter; left time: 1880.0405s\n",
            "\titers: 2200, epoch: 4 | loss: 0.0799540\n",
            "\tspeed: 0.1932s/iter; left time: 1848.3578s\n",
            "\titers: 2300, epoch: 4 | loss: 0.0533521\n",
            "\tspeed: 0.1939s/iter; left time: 1835.4336s\n",
            "\titers: 2400, epoch: 4 | loss: 0.0018140\n",
            "\tspeed: 0.1940s/iter; left time: 1817.3402s\n",
            "\titers: 2500, epoch: 4 | loss: 0.0089100\n",
            "\tspeed: 0.1936s/iter; left time: 1794.3149s\n",
            "\titers: 2600, epoch: 4 | loss: 0.1481006\n",
            "\tspeed: 0.1944s/iter; left time: 1781.8871s\n",
            "\titers: 2700, epoch: 4 | loss: 0.0567048\n",
            "\tspeed: 0.1942s/iter; left time: 1761.2455s\n",
            "\titers: 2800, epoch: 4 | loss: 0.0613771\n",
            "\tspeed: 0.1951s/iter; left time: 1749.8701s\n",
            "\titers: 2900, epoch: 4 | loss: 0.0801188\n",
            "\tspeed: 0.1938s/iter; left time: 1718.3749s\n",
            "\titers: 3000, epoch: 4 | loss: 0.0530884\n",
            "\tspeed: 0.1941s/iter; left time: 1701.7267s\n",
            "\titers: 3100, epoch: 4 | loss: 0.0018933\n",
            "\tspeed: 0.1937s/iter; left time: 1678.9421s\n",
            "\titers: 3200, epoch: 4 | loss: 0.0089091\n",
            "\tspeed: 0.1948s/iter; left time: 1668.4661s\n",
            "\titers: 3300, epoch: 4 | loss: 0.1479111\n",
            "\tspeed: 0.1957s/iter; left time: 1656.8739s\n",
            "\titers: 3400, epoch: 4 | loss: 0.0567485\n",
            "\tspeed: 0.1943s/iter; left time: 1625.5644s\n",
            "\titers: 3500, epoch: 4 | loss: 0.0613923\n",
            "\tspeed: 0.1941s/iter; left time: 1604.2626s\n",
            "\titers: 3600, epoch: 4 | loss: 0.0798296\n",
            "\tspeed: 0.1943s/iter; left time: 1586.8013s\n",
            "\titers: 3700, epoch: 4 | loss: 0.0531929\n",
            "\tspeed: 0.1940s/iter; left time: 1565.1364s\n",
            "\titers: 3800, epoch: 4 | loss: 0.0018169\n",
            "\tspeed: 0.1944s/iter; left time: 1548.9999s\n",
            "\titers: 3900, epoch: 4 | loss: 0.0088873\n",
            "\tspeed: 0.1944s/iter; left time: 1528.9695s\n",
            "Epoch: 4, Steps: 3922 | Train Loss: 0.0630280 Vali Loss: 0.0197002 Test Loss: 0.0286144\n",
            "Validation loss decreased (0.019748 --> 0.019700).  Saving model ...\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 5 | loss: 0.0390413\n",
            "\tspeed: 1.0100s/iter; left time: 7822.3439s\n",
            "\titers: 200, epoch: 5 | loss: 0.0129503\n",
            "\tspeed: 0.1946s/iter; left time: 1487.4191s\n",
            "\titers: 300, epoch: 5 | loss: 0.0390404\n",
            "\tspeed: 0.1942s/iter; left time: 1465.4707s\n",
            "\titers: 400, epoch: 5 | loss: 0.0127400\n",
            "\tspeed: 0.1942s/iter; left time: 1446.1110s\n",
            "\titers: 500, epoch: 5 | loss: 0.0389341\n",
            "\tspeed: 0.1961s/iter; left time: 1440.1435s\n",
            "\titers: 600, epoch: 5 | loss: 0.0127037\n",
            "\tspeed: 0.1949s/iter; left time: 1412.0709s\n",
            "\titers: 700, epoch: 5 | loss: 0.0389974\n",
            "\tspeed: 0.1942s/iter; left time: 1387.7240s\n",
            "\titers: 800, epoch: 5 | loss: 0.0126932\n",
            "\tspeed: 0.1950s/iter; left time: 1373.5980s\n",
            "\titers: 900, epoch: 5 | loss: 0.0389600\n",
            "\tspeed: 0.1946s/iter; left time: 1351.1705s\n",
            "\titers: 1000, epoch: 5 | loss: 0.0127237\n",
            "\tspeed: 0.1948s/iter; left time: 1333.3742s\n",
            "\titers: 1100, epoch: 5 | loss: 0.0391836\n",
            "\tspeed: 0.1945s/iter; left time: 1311.6221s\n",
            "\titers: 1200, epoch: 5 | loss: 0.0129041\n",
            "\tspeed: 0.1948s/iter; left time: 1294.6319s\n",
            "\titers: 1300, epoch: 5 | loss: 0.0389893\n",
            "\tspeed: 0.1952s/iter; left time: 1277.5167s\n",
            "\titers: 1400, epoch: 5 | loss: 0.0125555\n",
            "\tspeed: 0.1939s/iter; left time: 1249.8476s\n",
            "\titers: 1500, epoch: 5 | loss: 0.0390033\n",
            "\tspeed: 0.1945s/iter; left time: 1234.1303s\n",
            "\titers: 1600, epoch: 5 | loss: 0.0125877\n",
            "\tspeed: 0.1958s/iter; left time: 1222.5270s\n",
            "\titers: 1700, epoch: 5 | loss: 0.0389657\n",
            "\tspeed: 0.1956s/iter; left time: 1201.9245s\n",
            "\titers: 1800, epoch: 5 | loss: 0.0125928\n",
            "\tspeed: 0.1946s/iter; left time: 1176.5908s\n",
            "\titers: 1900, epoch: 5 | loss: 0.0389372\n",
            "\tspeed: 0.1943s/iter; left time: 1154.9448s\n",
            "\titers: 2000, epoch: 5 | loss: 0.0126335\n",
            "\tspeed: 0.1951s/iter; left time: 1140.3645s\n",
            "\titers: 2100, epoch: 5 | loss: 0.0391940\n",
            "\tspeed: 0.1941s/iter; left time: 1115.1293s\n",
            "\titers: 2200, epoch: 5 | loss: 0.0125870\n",
            "\tspeed: 0.1940s/iter; left time: 1095.3150s\n",
            "\titers: 2300, epoch: 5 | loss: 0.0390001\n",
            "\tspeed: 0.1935s/iter; left time: 1072.9679s\n",
            "\titers: 2400, epoch: 5 | loss: 0.0124951\n",
            "\tspeed: 0.1940s/iter; left time: 1056.1328s\n",
            "\titers: 2500, epoch: 5 | loss: 0.0390873\n",
            "\tspeed: 0.1938s/iter; left time: 1035.6883s\n",
            "\titers: 2600, epoch: 5 | loss: 0.0126452\n",
            "\tspeed: 0.1938s/iter; left time: 1016.2215s\n",
            "\titers: 2700, epoch: 5 | loss: 0.0390326\n",
            "\tspeed: 0.1944s/iter; left time: 999.9724s\n",
            "\titers: 2800, epoch: 5 | loss: 0.0126687\n",
            "\tspeed: 0.1948s/iter; left time: 982.7034s\n",
            "\titers: 2900, epoch: 5 | loss: 0.0391106\n",
            "\tspeed: 0.1949s/iter; left time: 963.5868s\n",
            "\titers: 3000, epoch: 5 | loss: 0.0126841\n",
            "\tspeed: 0.1952s/iter; left time: 945.5571s\n",
            "\titers: 3100, epoch: 5 | loss: 0.0389462\n",
            "\tspeed: 0.1941s/iter; left time: 920.8193s\n",
            "\titers: 3200, epoch: 5 | loss: 0.0126918\n",
            "\tspeed: 0.1940s/iter; left time: 901.1675s\n",
            "\titers: 3300, epoch: 5 | loss: 0.0391105\n",
            "\tspeed: 0.1940s/iter; left time: 881.9148s\n",
            "\titers: 3400, epoch: 5 | loss: 0.0126824\n",
            "\tspeed: 0.1949s/iter; left time: 866.2688s\n",
            "\titers: 3500, epoch: 5 | loss: 0.0389915\n",
            "\tspeed: 0.1941s/iter; left time: 843.5173s\n",
            "\titers: 3600, epoch: 5 | loss: 0.0126741\n",
            "\tspeed: 0.1952s/iter; left time: 828.8277s\n",
            "\titers: 3700, epoch: 5 | loss: 0.0389368\n",
            "\tspeed: 0.1946s/iter; left time: 806.5885s\n",
            "\titers: 3800, epoch: 5 | loss: 0.0126278\n",
            "\tspeed: 0.1940s/iter; left time: 784.5863s\n",
            "\titers: 3900, epoch: 5 | loss: 0.0390565\n",
            "\tspeed: 0.1944s/iter; left time: 766.9428s\n",
            "Epoch: 5, Steps: 3922 | Train Loss: 0.0305472 Vali Loss: 0.0196062 Test Loss: 0.0285185\n",
            "Validation loss decreased (0.019700 --> 0.019606).  Saving model ...\n",
            "Updating learning rate to 6.25e-06\n",
            "\titers: 100, epoch: 6 | loss: 0.0252002\n",
            "\tspeed: 1.0138s/iter; left time: 3875.8915s\n",
            "\titers: 200, epoch: 6 | loss: 0.0135720\n",
            "\tspeed: 0.1945s/iter; left time: 724.0670s\n",
            "\titers: 300, epoch: 6 | loss: 0.0251882\n",
            "\tspeed: 0.1943s/iter; left time: 704.0774s\n",
            "\titers: 400, epoch: 6 | loss: 0.0135766\n",
            "\tspeed: 0.1948s/iter; left time: 686.4547s\n",
            "\titers: 500, epoch: 6 | loss: 0.0254370\n",
            "\tspeed: 0.1940s/iter; left time: 664.1678s\n",
            "\titers: 600, epoch: 6 | loss: 0.0136537\n",
            "\tspeed: 0.1941s/iter; left time: 644.9975s\n",
            "\titers: 700, epoch: 6 | loss: 0.0253912\n",
            "\tspeed: 0.1936s/iter; left time: 624.0882s\n",
            "\titers: 800, epoch: 6 | loss: 0.0137136\n",
            "\tspeed: 0.1949s/iter; left time: 608.6478s\n",
            "\titers: 900, epoch: 6 | loss: 0.0251573\n",
            "\tspeed: 0.1950s/iter; left time: 589.6110s\n",
            "\titers: 1000, epoch: 6 | loss: 0.0137403\n",
            "\tspeed: 0.1952s/iter; left time: 570.6290s\n",
            "\titers: 1100, epoch: 6 | loss: 0.0254410\n",
            "\tspeed: 0.1953s/iter; left time: 551.2437s\n",
            "\titers: 1200, epoch: 6 | loss: 0.0135782\n",
            "\tspeed: 0.1931s/iter; left time: 525.8714s\n",
            "\titers: 1300, epoch: 6 | loss: 0.0253642\n",
            "\tspeed: 0.1938s/iter; left time: 508.3555s\n",
            "\titers: 1400, epoch: 6 | loss: 0.0135912\n",
            "\tspeed: 0.1949s/iter; left time: 491.7257s\n",
            "\titers: 1500, epoch: 6 | loss: 0.0253160\n",
            "\tspeed: 0.1944s/iter; left time: 470.9867s\n",
            "\titers: 1600, epoch: 6 | loss: 0.0136836\n",
            "\tspeed: 0.1956s/iter; left time: 454.4884s\n",
            "\titers: 1700, epoch: 6 | loss: 0.0254059\n",
            "\tspeed: 0.1958s/iter; left time: 435.2025s\n",
            "\titers: 1800, epoch: 6 | loss: 0.0135123\n",
            "\tspeed: 0.1953s/iter; left time: 414.5367s\n",
            "\titers: 1900, epoch: 6 | loss: 0.0253675\n",
            "\tspeed: 0.1949s/iter; left time: 394.2983s\n",
            "\titers: 2000, epoch: 6 | loss: 0.0136408\n",
            "\tspeed: 0.1952s/iter; left time: 375.3798s\n",
            "\titers: 2100, epoch: 6 | loss: 0.0252105\n",
            "\tspeed: 0.1948s/iter; left time: 355.1114s\n",
            "\titers: 2200, epoch: 6 | loss: 0.0136787\n",
            "\tspeed: 0.1958s/iter; left time: 337.4153s\n",
            "\titers: 2300, epoch: 6 | loss: 0.0252204\n",
            "\tspeed: 0.1954s/iter; left time: 317.1604s\n",
            "\titers: 2400, epoch: 6 | loss: 0.0138046\n",
            "\tspeed: 0.1953s/iter; left time: 297.4312s\n",
            "\titers: 2500, epoch: 6 | loss: 0.0252873\n",
            "\tspeed: 0.1943s/iter; left time: 276.5368s\n",
            "\titers: 2600, epoch: 6 | loss: 0.0136367\n",
            "\tspeed: 0.1942s/iter; left time: 256.8672s\n",
            "\titers: 2700, epoch: 6 | loss: 0.0253270\n",
            "\tspeed: 0.1940s/iter; left time: 237.2761s\n",
            "\titers: 2800, epoch: 6 | loss: 0.0136197\n",
            "\tspeed: 0.1943s/iter; left time: 218.2164s\n",
            "\titers: 2900, epoch: 6 | loss: 0.0252150\n",
            "\tspeed: 0.1941s/iter; left time: 198.5911s\n",
            "\titers: 3000, epoch: 6 | loss: 0.0137288\n",
            "\tspeed: 0.1932s/iter; left time: 178.3625s\n",
            "\titers: 3100, epoch: 6 | loss: 0.0252898\n",
            "\tspeed: 0.1941s/iter; left time: 159.7522s\n",
            "\titers: 3200, epoch: 6 | loss: 0.0136590\n",
            "\tspeed: 0.1941s/iter; left time: 140.3225s\n",
            "\titers: 3300, epoch: 6 | loss: 0.0252276\n",
            "\tspeed: 0.1948s/iter; left time: 121.3878s\n",
            "\titers: 3400, epoch: 6 | loss: 0.0137406\n",
            "\tspeed: 0.1937s/iter; left time: 101.2951s\n",
            "\titers: 3500, epoch: 6 | loss: 0.0253538\n",
            "\tspeed: 0.1942s/iter; left time: 82.1632s\n",
            "\titers: 3600, epoch: 6 | loss: 0.0138618\n",
            "\tspeed: 0.1937s/iter; left time: 62.5780s\n",
            "\titers: 3700, epoch: 6 | loss: 0.0253334\n",
            "\tspeed: 0.1933s/iter; left time: 43.1157s\n",
            "\titers: 3800, epoch: 6 | loss: 0.0136286\n",
            "\tspeed: 0.1933s/iter; left time: 23.7798s\n",
            "\titers: 3900, epoch: 6 | loss: 0.0252954\n",
            "\tspeed: 0.1948s/iter; left time: 4.4815s\n",
            "Epoch: 6, Steps: 3922 | Train Loss: 0.0155768 Vali Loss: 0.0195460 Test Loss: 0.0285020\n",
            "Validation loss decreased (0.019606 --> 0.019546).  Saving model ...\n",
            "Updating learning rate to 3.125e-06\n",
            ">>>>>>>testing : gta_WADI_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 172741\n",
            "test shape: (863, 200, 1, 124) (863, 200, 1, 124)\n",
            "test shape: (172600, 1, 124) (172600, 1, 124)\n",
            "mse:0.028503128684547737, mae:0.08184011533410676\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : gta_WADI_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 784477\n",
            "val 43140\n",
            "test 172741\n",
            "\titers: 100, epoch: 1 | loss: 12148.6143491\n",
            "\tspeed: 0.1939s/iter; left time: 4542.6761s\n",
            "\titers: 200, epoch: 1 | loss: 11994.8458912\n",
            "\tspeed: 0.1942s/iter; left time: 4531.1882s\n",
            "\titers: 300, epoch: 1 | loss: 11841.0804903\n",
            "\tspeed: 0.1942s/iter; left time: 4512.1913s\n",
            "\titers: 400, epoch: 1 | loss: 11687.3159938\n",
            "\tspeed: 0.1940s/iter; left time: 4487.6552s\n",
            "\titers: 500, epoch: 1 | loss: 11533.5546039\n",
            "\tspeed: 0.1943s/iter; left time: 4474.9500s\n",
            "\titers: 600, epoch: 1 | loss: 11379.7920155\n",
            "\tspeed: 0.1946s/iter; left time: 4462.6079s\n",
            "\titers: 700, epoch: 1 | loss: 11226.0302025\n",
            "\tspeed: 0.1936s/iter; left time: 4420.5028s\n",
            "\titers: 800, epoch: 1 | loss: 11072.2682179\n",
            "\tspeed: 0.1938s/iter; left time: 4404.6009s\n",
            "\titers: 900, epoch: 1 | loss: 10918.5074571\n",
            "\tspeed: 0.1939s/iter; left time: 4389.0124s\n",
            "\titers: 1000, epoch: 1 | loss: 10764.7470192\n",
            "\tspeed: 0.1941s/iter; left time: 4373.1201s\n",
            "\titers: 1100, epoch: 1 | loss: 10610.9858165\n",
            "\tspeed: 0.1941s/iter; left time: 4355.0911s\n",
            "\titers: 1200, epoch: 1 | loss: 10457.2259273\n",
            "\tspeed: 0.1940s/iter; left time: 4333.3372s\n",
            "\titers: 1300, epoch: 1 | loss: 10303.4650985\n",
            "\tspeed: 0.1950s/iter; left time: 4334.7403s\n",
            "\titers: 1400, epoch: 1 | loss: 10149.7040489\n",
            "\tspeed: 0.1946s/iter; left time: 4307.9408s\n",
            "\titers: 1500, epoch: 1 | loss: 9995.9441008\n",
            "\tspeed: 0.1946s/iter; left time: 4288.2033s\n",
            "\titers: 1600, epoch: 1 | loss: 9842.1838405\n",
            "\tspeed: 0.1941s/iter; left time: 4256.1412s\n",
            "\titers: 1700, epoch: 1 | loss: 9688.4232071\n",
            "\tspeed: 0.1946s/iter; left time: 4248.4522s\n",
            "\titers: 1800, epoch: 1 | loss: 9534.6629828\n",
            "\tspeed: 0.1935s/iter; left time: 4204.3563s\n",
            "\titers: 1900, epoch: 1 | loss: 9380.9025749\n",
            "\tspeed: 0.1943s/iter; left time: 4202.6117s\n",
            "\titers: 2000, epoch: 1 | loss: 9227.1424080\n",
            "\tspeed: 0.1941s/iter; left time: 4179.1393s\n",
            "\titers: 2100, epoch: 1 | loss: 9073.3821022\n",
            "\tspeed: 0.1950s/iter; left time: 4179.3092s\n",
            "\titers: 2200, epoch: 1 | loss: 8919.6225763\n",
            "\tspeed: 0.1940s/iter; left time: 4138.2352s\n",
            "\titers: 2300, epoch: 1 | loss: 8765.8620117\n",
            "\tspeed: 0.1942s/iter; left time: 4122.5040s\n",
            "\titers: 2400, epoch: 1 | loss: 8612.1015442\n",
            "\tspeed: 0.1943s/iter; left time: 4106.6529s\n",
            "\titers: 2500, epoch: 1 | loss: 8458.3413472\n",
            "\tspeed: 0.1944s/iter; left time: 4087.7909s\n",
            "\titers: 2600, epoch: 1 | loss: 8304.5812080\n",
            "\tspeed: 0.1943s/iter; left time: 4066.4168s\n",
            "\titers: 2700, epoch: 1 | loss: 8150.8209209\n",
            "\tspeed: 0.1953s/iter; left time: 4068.9445s\n",
            "\titers: 2800, epoch: 1 | loss: 7997.0610957\n",
            "\tspeed: 0.1940s/iter; left time: 4022.3760s\n",
            "\titers: 2900, epoch: 1 | loss: 7843.3010332\n",
            "\tspeed: 0.1940s/iter; left time: 4002.0412s\n",
            "\titers: 3000, epoch: 1 | loss: 7689.5405424\n",
            "\tspeed: 0.1947s/iter; left time: 3998.6050s\n",
            "\titers: 3100, epoch: 1 | loss: 7535.7804848\n",
            "\tspeed: 0.1951s/iter; left time: 3987.3067s\n",
            "\titers: 3200, epoch: 1 | loss: 7382.0202826\n",
            "\tspeed: 0.1943s/iter; left time: 3950.4292s\n",
            "\titers: 3300, epoch: 1 | loss: 7228.2602299\n",
            "\tspeed: 0.1945s/iter; left time: 3935.1605s\n",
            "\titers: 3400, epoch: 1 | loss: 7074.5002880\n",
            "\tspeed: 0.1951s/iter; left time: 3927.8652s\n",
            "\titers: 3500, epoch: 1 | loss: 6920.7399446\n",
            "\tspeed: 0.1962s/iter; left time: 3931.0100s\n",
            "\titers: 3600, epoch: 1 | loss: 6766.9799559\n",
            "\tspeed: 0.1950s/iter; left time: 3887.0924s\n",
            "\titers: 3700, epoch: 1 | loss: 6613.2199852\n",
            "\tspeed: 0.1951s/iter; left time: 3868.4435s\n",
            "\titers: 3800, epoch: 1 | loss: 6459.4599698\n",
            "\tspeed: 0.1948s/iter; left time: 3844.4810s\n",
            "\titers: 3900, epoch: 1 | loss: 6305.6997207\n",
            "\tspeed: 0.1946s/iter; left time: 3819.9967s\n",
            "Epoch: 1, Steps: 3922 | Train Loss: 9286.3447962 Vali Loss: 0.0242716 Test Loss: 0.0348321\n",
            "Validation loss decreased (inf --> 0.024272).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 6118.1127248\n",
            "\tspeed: 1.0082s/iter; left time: 19671.7367s\n",
            "\titers: 200, epoch: 2 | loss: 5964.3524239\n",
            "\tspeed: 0.1938s/iter; left time: 3761.7085s\n",
            "\titers: 300, epoch: 2 | loss: 5810.5922766\n",
            "\tspeed: 0.1937s/iter; left time: 3740.9033s\n",
            "\titers: 400, epoch: 2 | loss: 5656.8323324\n",
            "\tspeed: 0.1931s/iter; left time: 3710.1844s\n",
            "\titers: 500, epoch: 2 | loss: 5503.0721610\n",
            "\tspeed: 0.1940s/iter; left time: 3706.5937s\n",
            "\titers: 600, epoch: 2 | loss: 5349.3119909\n",
            "\tspeed: 0.1945s/iter; left time: 3696.9520s\n",
            "\titers: 700, epoch: 2 | loss: 5195.5521655\n",
            "\tspeed: 0.1941s/iter; left time: 3670.1638s\n",
            "\titers: 800, epoch: 2 | loss: 5041.7921976\n",
            "\tspeed: 0.1939s/iter; left time: 3647.5123s\n",
            "\titers: 900, epoch: 2 | loss: 4888.0320431\n",
            "\tspeed: 0.1947s/iter; left time: 3643.5947s\n",
            "\titers: 1000, epoch: 2 | loss: 4734.2722875\n",
            "\tspeed: 0.1939s/iter; left time: 3607.7968s\n",
            "\titers: 1100, epoch: 2 | loss: 4580.5120838\n",
            "\tspeed: 0.1938s/iter; left time: 3587.6396s\n",
            "\titers: 1200, epoch: 2 | loss: 4426.7518632\n",
            "\tspeed: 0.1936s/iter; left time: 3563.6191s\n",
            "\titers: 1300, epoch: 2 | loss: 4272.9921382\n",
            "\tspeed: 0.1940s/iter; left time: 3552.9719s\n",
            "\titers: 1400, epoch: 2 | loss: 4119.2325170\n",
            "\tspeed: 0.1937s/iter; left time: 3526.7869s\n",
            "\titers: 1500, epoch: 2 | loss: 3965.4720623\n",
            "\tspeed: 0.1941s/iter; left time: 3515.1065s\n",
            "\titers: 1600, epoch: 2 | loss: 3811.7119315\n",
            "\tspeed: 0.1937s/iter; left time: 3488.1931s\n",
            "\titers: 1700, epoch: 2 | loss: 3657.9518651\n",
            "\tspeed: 0.1939s/iter; left time: 3472.3245s\n",
            "\titers: 1800, epoch: 2 | loss: 3504.1919571\n",
            "\tspeed: 0.1943s/iter; left time: 3460.1747s\n",
            "\titers: 1900, epoch: 2 | loss: 3350.4318495\n",
            "\tspeed: 0.1940s/iter; left time: 3436.3850s\n",
            "\titers: 2000, epoch: 2 | loss: 3196.6717664\n",
            "\tspeed: 0.1937s/iter; left time: 3412.1300s\n",
            "\titers: 2100, epoch: 2 | loss: 3042.9118557\n",
            "\tspeed: 0.1938s/iter; left time: 3393.5716s\n",
            "\titers: 2200, epoch: 2 | loss: 2889.1519167\n",
            "\tspeed: 0.1933s/iter; left time: 3365.9739s\n",
            "\titers: 2300, epoch: 2 | loss: 2735.3918409\n",
            "\tspeed: 0.1948s/iter; left time: 3371.9669s\n",
            "\titers: 2400, epoch: 2 | loss: 2581.6317466\n",
            "\tspeed: 0.1951s/iter; left time: 3357.5479s\n",
            "\titers: 2500, epoch: 2 | loss: 2427.8720459\n",
            "\tspeed: 0.1947s/iter; left time: 3331.5075s\n",
            "\titers: 2600, epoch: 2 | loss: 2274.1117023\n",
            "\tspeed: 0.1919s/iter; left time: 3264.6227s\n",
            "\titers: 2700, epoch: 2 | loss: 2120.3516875\n",
            "\tspeed: 0.1948s/iter; left time: 3293.4499s\n",
            "\titers: 2800, epoch: 2 | loss: 1966.5918144\n",
            "\tspeed: 0.1944s/iter; left time: 3267.8611s\n",
            "\titers: 2900, epoch: 2 | loss: 1812.8316348\n",
            "\tspeed: 0.1946s/iter; left time: 3251.4596s\n",
            "\titers: 3000, epoch: 2 | loss: 1659.0716899\n",
            "\tspeed: 0.1951s/iter; left time: 3241.5365s\n",
            "\titers: 3100, epoch: 2 | loss: 1505.3117625\n",
            "\tspeed: 0.1957s/iter; left time: 3231.9298s\n",
            "\titers: 3200, epoch: 2 | loss: 1351.5515735\n",
            "\tspeed: 0.1957s/iter; left time: 3212.1852s\n",
            "\titers: 3300, epoch: 2 | loss: 1197.7916292\n",
            "\tspeed: 0.1953s/iter; left time: 3185.3734s\n",
            "\titers: 3400, epoch: 2 | loss: 1044.0316186\n",
            "\tspeed: 0.1942s/iter; left time: 3147.9985s\n",
            "\titers: 3500, epoch: 2 | loss: 890.2717409\n",
            "\tspeed: 0.1951s/iter; left time: 3143.7329s\n",
            "\titers: 3600, epoch: 2 | loss: 736.5116599\n",
            "\tspeed: 0.1954s/iter; left time: 3128.4617s\n",
            "\titers: 3700, epoch: 2 | loss: 582.7514529\n",
            "\tspeed: 0.1960s/iter; left time: 3118.4606s\n",
            "\titers: 3800, epoch: 2 | loss: 428.9914818\n",
            "\tspeed: 0.1958s/iter; left time: 3095.7495s\n",
            "\titers: 3900, epoch: 2 | loss: 275.2317723\n",
            "\tspeed: 0.1957s/iter; left time: 3074.0462s\n",
            "Epoch: 2, Steps: 3922 | Train Loss: 3255.8695270 Vali Loss: 0.0216591 Test Loss: 0.0321145\n",
            "Validation loss decreased (0.024272 --> 0.021659).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 163.7556007\n",
            "\tspeed: 1.0142s/iter; left time: 15810.5028s\n",
            "\titers: 200, epoch: 3 | loss: 86.8755434\n",
            "\tspeed: 0.1954s/iter; left time: 3026.9245s\n",
            "\titers: 300, epoch: 3 | loss: 9.9954660\n",
            "\tspeed: 0.1948s/iter; left time: 2997.9334s\n",
            "\titers: 400, epoch: 3 | loss: 0.0468724\n",
            "\tspeed: 0.1941s/iter; left time: 2966.9851s\n",
            "\titers: 500, epoch: 3 | loss: 0.3324684\n",
            "\tspeed: 0.1945s/iter; left time: 2954.9755s\n",
            "\titers: 600, epoch: 3 | loss: 0.3252817\n",
            "\tspeed: 0.1943s/iter; left time: 2931.2711s\n",
            "\titers: 700, epoch: 3 | loss: 0.0471273\n",
            "\tspeed: 0.1944s/iter; left time: 2913.4039s\n",
            "\titers: 800, epoch: 3 | loss: 0.3324401\n",
            "\tspeed: 0.1939s/iter; left time: 2887.1068s\n",
            "\titers: 900, epoch: 3 | loss: 0.3253830\n",
            "\tspeed: 0.1947s/iter; left time: 2878.8890s\n",
            "\titers: 1000, epoch: 3 | loss: 0.0469055\n",
            "\tspeed: 0.1943s/iter; left time: 2853.6419s\n",
            "\titers: 1100, epoch: 3 | loss: 0.3322039\n",
            "\tspeed: 0.1930s/iter; left time: 2816.3288s\n",
            "\titers: 1200, epoch: 3 | loss: 0.3253448\n",
            "\tspeed: 0.1954s/iter; left time: 2830.7693s\n",
            "\titers: 1300, epoch: 3 | loss: 0.0470086\n",
            "\tspeed: 0.1938s/iter; left time: 2788.4933s\n",
            "\titers: 1400, epoch: 3 | loss: 0.3323218\n",
            "\tspeed: 0.1943s/iter; left time: 2775.7668s\n",
            "\titers: 1500, epoch: 3 | loss: 0.3251215\n",
            "\tspeed: 0.1943s/iter; left time: 2757.1779s\n",
            "\titers: 1600, epoch: 3 | loss: 0.0468378\n",
            "\tspeed: 0.1945s/iter; left time: 2740.6637s\n",
            "\titers: 1700, epoch: 3 | loss: 0.3321722\n",
            "\tspeed: 0.1941s/iter; left time: 2715.0951s\n",
            "\titers: 1800, epoch: 3 | loss: 0.3253632\n",
            "\tspeed: 0.1947s/iter; left time: 2703.6602s\n",
            "\titers: 1900, epoch: 3 | loss: 0.0471766\n",
            "\tspeed: 0.1948s/iter; left time: 2686.2507s\n",
            "\titers: 2000, epoch: 3 | loss: 0.3322854\n",
            "\tspeed: 0.1939s/iter; left time: 2654.0329s\n",
            "\titers: 2100, epoch: 3 | loss: 0.3253617\n",
            "\tspeed: 0.1939s/iter; left time: 2635.4951s\n",
            "\titers: 2200, epoch: 3 | loss: 0.0470156\n",
            "\tspeed: 0.1941s/iter; left time: 2617.7725s\n",
            "\titers: 2300, epoch: 3 | loss: 0.3324119\n",
            "\tspeed: 0.1940s/iter; left time: 2597.3869s\n",
            "\titers: 2400, epoch: 3 | loss: 0.3253299\n",
            "\tspeed: 0.1940s/iter; left time: 2578.5288s\n",
            "\titers: 2500, epoch: 3 | loss: 0.0469036\n",
            "\tspeed: 0.1950s/iter; left time: 2572.3472s\n",
            "\titers: 2600, epoch: 3 | loss: 0.3321847\n",
            "\tspeed: 0.1945s/iter; left time: 2546.3304s\n",
            "\titers: 2700, epoch: 3 | loss: 0.3252564\n",
            "\tspeed: 0.1943s/iter; left time: 2523.5031s\n",
            "\titers: 2800, epoch: 3 | loss: 0.0468843\n",
            "\tspeed: 0.1937s/iter; left time: 2497.2399s\n",
            "\titers: 2900, epoch: 3 | loss: 0.3321825\n",
            "\tspeed: 0.1948s/iter; left time: 2491.6133s\n",
            "\titers: 3000, epoch: 3 | loss: 0.3256396\n",
            "\tspeed: 0.1940s/iter; left time: 2461.6394s\n",
            "\titers: 3100, epoch: 3 | loss: 0.0468912\n",
            "\tspeed: 0.1937s/iter; left time: 2438.5180s\n",
            "\titers: 3200, epoch: 3 | loss: 0.3325337\n",
            "\tspeed: 0.1936s/iter; left time: 2417.9755s\n",
            "\titers: 3300, epoch: 3 | loss: 0.3253243\n",
            "\tspeed: 0.1941s/iter; left time: 2404.5678s\n",
            "\titers: 3400, epoch: 3 | loss: 0.0469475\n",
            "\tspeed: 0.1944s/iter; left time: 2389.2197s\n",
            "\titers: 3500, epoch: 3 | loss: 0.3322881\n",
            "\tspeed: 0.1935s/iter; left time: 2358.0752s\n",
            "\titers: 3600, epoch: 3 | loss: 0.3252285\n",
            "\tspeed: 0.1938s/iter; left time: 2342.5264s\n",
            "\titers: 3700, epoch: 3 | loss: 0.0467558\n",
            "\tspeed: 0.1942s/iter; left time: 2328.8558s\n",
            "\titers: 3800, epoch: 3 | loss: 0.3320772\n",
            "\tspeed: 0.1939s/iter; left time: 2305.2564s\n",
            "\titers: 3900, epoch: 3 | loss: 0.3252083\n",
            "\tspeed: 0.1942s/iter; left time: 2289.4231s\n",
            "Epoch: 3, Steps: 3922 | Train Loss: 9.8070601 Vali Loss: 0.0214751 Test Loss: 0.0323151\n",
            "Validation loss decreased (0.021659 --> 0.021475).  Saving model ...\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 0.0802192\n",
            "\tspeed: 1.0103s/iter; left time: 11787.5349s\n",
            "\titers: 200, epoch: 4 | loss: 0.0530697\n",
            "\tspeed: 0.1940s/iter; left time: 2243.9953s\n",
            "\titers: 300, epoch: 4 | loss: 0.0022273\n",
            "\tspeed: 0.1948s/iter; left time: 2233.7673s\n",
            "\titers: 400, epoch: 4 | loss: 0.0091412\n",
            "\tspeed: 0.1944s/iter; left time: 2209.5144s\n",
            "\titers: 500, epoch: 4 | loss: 0.1480919\n",
            "\tspeed: 0.1944s/iter; left time: 2190.4174s\n",
            "\titers: 600, epoch: 4 | loss: 0.0568708\n",
            "\tspeed: 0.1949s/iter; left time: 2176.0822s\n",
            "\titers: 700, epoch: 4 | loss: 0.0614035\n",
            "\tspeed: 0.1938s/iter; left time: 2144.6820s\n",
            "\titers: 800, epoch: 4 | loss: 0.0799559\n",
            "\tspeed: 0.1946s/iter; left time: 2133.6701s\n",
            "\titers: 900, epoch: 4 | loss: 0.0530728\n",
            "\tspeed: 0.1945s/iter; left time: 2113.4883s\n",
            "\titers: 1000, epoch: 4 | loss: 0.0019925\n",
            "\tspeed: 0.1951s/iter; left time: 2100.7249s\n",
            "\titers: 1100, epoch: 4 | loss: 0.0087912\n",
            "\tspeed: 0.1937s/iter; left time: 2066.5494s\n",
            "\titers: 1200, epoch: 4 | loss: 0.1480873\n",
            "\tspeed: 0.1951s/iter; left time: 2061.5601s\n",
            "\titers: 1300, epoch: 4 | loss: 0.0573380\n",
            "\tspeed: 0.1947s/iter; left time: 2038.2940s\n",
            "\titers: 1400, epoch: 4 | loss: 0.0614806\n",
            "\tspeed: 0.1943s/iter; left time: 2014.1288s\n",
            "\titers: 1500, epoch: 4 | loss: 0.0798358\n",
            "\tspeed: 0.1955s/iter; left time: 2007.5812s\n",
            "\titers: 1600, epoch: 4 | loss: 0.0529898\n",
            "\tspeed: 0.1944s/iter; left time: 1976.7501s\n",
            "\titers: 1700, epoch: 4 | loss: 0.0018506\n",
            "\tspeed: 0.1942s/iter; left time: 1955.3889s\n",
            "\titers: 1800, epoch: 4 | loss: 0.0090786\n",
            "\tspeed: 0.1942s/iter; left time: 1935.8627s\n",
            "\titers: 1900, epoch: 4 | loss: 0.1482404\n",
            "\tspeed: 0.1943s/iter; left time: 1916.7760s\n",
            "\titers: 2000, epoch: 4 | loss: 0.0570864\n",
            "\tspeed: 0.1947s/iter; left time: 1901.7535s\n",
            "\titers: 2100, epoch: 4 | loss: 0.0615457\n",
            "\tspeed: 0.1939s/iter; left time: 1874.4730s\n",
            "\titers: 2200, epoch: 4 | loss: 0.0800168\n",
            "\tspeed: 0.1942s/iter; left time: 1857.4606s\n",
            "\titers: 2300, epoch: 4 | loss: 0.0531773\n",
            "\tspeed: 0.1938s/iter; left time: 1834.8732s\n",
            "\titers: 2400, epoch: 4 | loss: 0.0018459\n",
            "\tspeed: 0.1946s/iter; left time: 1822.8887s\n",
            "\titers: 2500, epoch: 4 | loss: 0.0089110\n",
            "\tspeed: 0.1952s/iter; left time: 1808.5532s\n",
            "\titers: 2600, epoch: 4 | loss: 0.1480325\n",
            "\tspeed: 0.1946s/iter; left time: 1784.0468s\n",
            "\titers: 2700, epoch: 4 | loss: 0.0568406\n",
            "\tspeed: 0.1948s/iter; left time: 1766.2489s\n",
            "\titers: 2800, epoch: 4 | loss: 0.0616187\n",
            "\tspeed: 0.1949s/iter; left time: 1747.8808s\n",
            "\titers: 2900, epoch: 4 | loss: 0.0801478\n",
            "\tspeed: 0.1946s/iter; left time: 1725.5648s\n",
            "\titers: 3000, epoch: 4 | loss: 0.0531151\n",
            "\tspeed: 0.1948s/iter; left time: 1707.7256s\n",
            "\titers: 3100, epoch: 4 | loss: 0.0018684\n",
            "\tspeed: 0.1954s/iter; left time: 1693.1594s\n",
            "\titers: 3200, epoch: 4 | loss: 0.0089711\n",
            "\tspeed: 0.1945s/iter; left time: 1666.0526s\n",
            "\titers: 3300, epoch: 4 | loss: 0.1481337\n",
            "\tspeed: 0.1943s/iter; left time: 1645.4298s\n",
            "\titers: 3400, epoch: 4 | loss: 0.0569254\n",
            "\tspeed: 0.1941s/iter; left time: 1624.1378s\n",
            "\titers: 3500, epoch: 4 | loss: 0.0614839\n",
            "\tspeed: 0.1945s/iter; left time: 1607.7090s\n",
            "\titers: 3600, epoch: 4 | loss: 0.0799174\n",
            "\tspeed: 0.1944s/iter; left time: 1587.6926s\n",
            "\titers: 3700, epoch: 4 | loss: 0.0528479\n",
            "\tspeed: 0.1946s/iter; left time: 1569.5290s\n",
            "\titers: 3800, epoch: 4 | loss: 0.0020534\n",
            "\tspeed: 0.1942s/iter; left time: 1547.3896s\n",
            "\titers: 3900, epoch: 4 | loss: 0.0089490\n",
            "\tspeed: 0.1938s/iter; left time: 1524.9315s\n",
            "Epoch: 4, Steps: 3922 | Train Loss: 0.0630401 Vali Loss: 0.0214345 Test Loss: 0.0323223\n",
            "Validation loss decreased (0.021475 --> 0.021434).  Saving model ...\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 5 | loss: 0.0391607\n",
            "\tspeed: 1.0139s/iter; left time: 7852.5475s\n",
            "\titers: 200, epoch: 5 | loss: 0.0127395\n",
            "\tspeed: 0.1941s/iter; left time: 1483.6189s\n",
            "\titers: 300, epoch: 5 | loss: 0.0389134\n",
            "\tspeed: 0.1961s/iter; left time: 1479.2431s\n",
            "\titers: 400, epoch: 5 | loss: 0.0126561\n",
            "\tspeed: 0.1947s/iter; left time: 1449.4836s\n",
            "\titers: 500, epoch: 5 | loss: 0.0389466\n",
            "\tspeed: 0.1943s/iter; left time: 1427.2009s\n",
            "\titers: 600, epoch: 5 | loss: 0.0126989\n",
            "\tspeed: 0.1950s/iter; left time: 1412.7648s\n",
            "\titers: 700, epoch: 5 | loss: 0.0389461\n",
            "\tspeed: 0.1950s/iter; left time: 1393.2810s\n",
            "\titers: 800, epoch: 5 | loss: 0.0126531\n",
            "\tspeed: 0.1948s/iter; left time: 1372.1739s\n",
            "\titers: 900, epoch: 5 | loss: 0.0390941\n",
            "\tspeed: 0.1955s/iter; left time: 1357.7449s\n",
            "\titers: 1000, epoch: 5 | loss: 0.0127477\n",
            "\tspeed: 0.1945s/iter; left time: 1331.0618s\n",
            "\titers: 1100, epoch: 5 | loss: 0.0390693\n",
            "\tspeed: 0.1950s/iter; left time: 1315.5729s\n",
            "\titers: 1200, epoch: 5 | loss: 0.0126358\n",
            "\tspeed: 0.1953s/iter; left time: 1297.4643s\n",
            "\titers: 1300, epoch: 5 | loss: 0.0392166\n",
            "\tspeed: 0.1949s/iter; left time: 1275.7440s\n",
            "\titers: 1400, epoch: 5 | loss: 0.0127762\n",
            "\tspeed: 0.1946s/iter; left time: 1253.9330s\n",
            "\titers: 1500, epoch: 5 | loss: 0.0390043\n",
            "\tspeed: 0.1954s/iter; left time: 1239.8469s\n",
            "\titers: 1600, epoch: 5 | loss: 0.0125309\n",
            "\tspeed: 0.1950s/iter; left time: 1217.9676s\n",
            "\titers: 1700, epoch: 5 | loss: 0.0389722\n",
            "\tspeed: 0.1949s/iter; left time: 1197.4772s\n",
            "\titers: 1800, epoch: 5 | loss: 0.0127326\n",
            "\tspeed: 0.1949s/iter; left time: 1178.1583s\n",
            "\titers: 1900, epoch: 5 | loss: 0.0388880\n",
            "\tspeed: 0.1944s/iter; left time: 1155.7932s\n",
            "\titers: 2000, epoch: 5 | loss: 0.0126852\n",
            "\tspeed: 0.1948s/iter; left time: 1138.7295s\n",
            "\titers: 2100, epoch: 5 | loss: 0.0391105\n",
            "\tspeed: 0.1940s/iter; left time: 1114.3332s\n",
            "\titers: 2200, epoch: 5 | loss: 0.0126172\n",
            "\tspeed: 0.1944s/iter; left time: 1097.4924s\n",
            "\titers: 2300, epoch: 5 | loss: 0.0390397\n",
            "\tspeed: 0.1953s/iter; left time: 1082.9416s\n",
            "\titers: 2400, epoch: 5 | loss: 0.0127304\n",
            "\tspeed: 0.1947s/iter; left time: 1059.9579s\n",
            "\titers: 2500, epoch: 5 | loss: 0.0389914\n",
            "\tspeed: 0.1945s/iter; left time: 1039.8642s\n",
            "\titers: 2600, epoch: 5 | loss: 0.0128197\n",
            "\tspeed: 0.1941s/iter; left time: 1018.1486s\n",
            "\titers: 2700, epoch: 5 | loss: 0.0388964\n",
            "\tspeed: 0.1945s/iter; left time: 1000.7697s\n",
            "\titers: 2800, epoch: 5 | loss: 0.0126262\n",
            "\tspeed: 0.1941s/iter; left time: 979.2796s\n",
            "\titers: 2900, epoch: 5 | loss: 0.0389834\n",
            "\tspeed: 0.1936s/iter; left time: 957.3291s\n",
            "\titers: 3000, epoch: 5 | loss: 0.0127910\n",
            "\tspeed: 0.1942s/iter; left time: 940.7819s\n",
            "\titers: 3100, epoch: 5 | loss: 0.0389165\n",
            "\tspeed: 0.1941s/iter; left time: 921.2056s\n",
            "\titers: 3200, epoch: 5 | loss: 0.0127759\n",
            "\tspeed: 0.1941s/iter; left time: 901.4842s\n",
            "\titers: 3300, epoch: 5 | loss: 0.0391307\n",
            "\tspeed: 0.1945s/iter; left time: 884.1953s\n",
            "\titers: 3400, epoch: 5 | loss: 0.0126054\n",
            "\tspeed: 0.1947s/iter; left time: 865.4785s\n",
            "\titers: 3500, epoch: 5 | loss: 0.0389760\n",
            "\tspeed: 0.1945s/iter; left time: 845.1070s\n",
            "\titers: 3600, epoch: 5 | loss: 0.0125789\n",
            "\tspeed: 0.1945s/iter; left time: 825.5806s\n",
            "\titers: 3700, epoch: 5 | loss: 0.0389434\n",
            "\tspeed: 0.1948s/iter; left time: 807.2488s\n",
            "\titers: 3800, epoch: 5 | loss: 0.0127500\n",
            "\tspeed: 0.1944s/iter; left time: 786.3415s\n",
            "\titers: 3900, epoch: 5 | loss: 0.0389153\n",
            "\tspeed: 0.1940s/iter; left time: 765.5040s\n",
            "Epoch: 5, Steps: 3922 | Train Loss: 0.0305599 Vali Loss: 0.0214708 Test Loss: 0.0324396\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 6.25e-06\n",
            "\titers: 100, epoch: 6 | loss: 0.0252319\n",
            "\tspeed: 1.0111s/iter; left time: 3865.2593s\n",
            "\titers: 200, epoch: 6 | loss: 0.0137921\n",
            "\tspeed: 0.1946s/iter; left time: 724.5901s\n",
            "\titers: 300, epoch: 6 | loss: 0.0253712\n",
            "\tspeed: 0.1938s/iter; left time: 702.2474s\n",
            "\titers: 400, epoch: 6 | loss: 0.0137506\n",
            "\tspeed: 0.1945s/iter; left time: 685.3943s\n",
            "\titers: 500, epoch: 6 | loss: 0.0251538\n",
            "\tspeed: 0.1948s/iter; left time: 666.8478s\n",
            "\titers: 600, epoch: 6 | loss: 0.0139314\n",
            "\tspeed: 0.1942s/iter; left time: 645.4534s\n",
            "\titers: 700, epoch: 6 | loss: 0.0253449\n",
            "\tspeed: 0.1948s/iter; left time: 627.9831s\n",
            "\titers: 800, epoch: 6 | loss: 0.0135779\n",
            "\tspeed: 0.1946s/iter; left time: 607.6280s\n",
            "\titers: 900, epoch: 6 | loss: 0.0252673\n",
            "\tspeed: 0.1944s/iter; left time: 587.6074s\n",
            "\titers: 1000, epoch: 6 | loss: 0.0136540\n",
            "\tspeed: 0.1944s/iter; left time: 568.1415s\n",
            "\titers: 1100, epoch: 6 | loss: 0.0252453\n",
            "\tspeed: 0.1943s/iter; left time: 548.5629s\n",
            "\titers: 1200, epoch: 6 | loss: 0.0136559\n",
            "\tspeed: 0.1942s/iter; left time: 528.6807s\n",
            "\titers: 1300, epoch: 6 | loss: 0.0253674\n",
            "\tspeed: 0.1945s/iter; left time: 510.0498s\n",
            "\titers: 1400, epoch: 6 | loss: 0.0135974\n",
            "\tspeed: 0.1932s/iter; left time: 487.5073s\n",
            "\titers: 1500, epoch: 6 | loss: 0.0253050\n",
            "\tspeed: 0.1943s/iter; left time: 470.6786s\n",
            "\titers: 1600, epoch: 6 | loss: 0.0136552\n",
            "\tspeed: 0.1938s/iter; left time: 450.2738s\n",
            "\titers: 1700, epoch: 6 | loss: 0.0252007\n",
            "\tspeed: 0.1944s/iter; left time: 432.1315s\n",
            "\titers: 1800, epoch: 6 | loss: 0.0136449\n",
            "\tspeed: 0.1943s/iter; left time: 412.5798s\n",
            "\titers: 1900, epoch: 6 | loss: 0.0254062\n",
            "\tspeed: 0.1942s/iter; left time: 392.8170s\n",
            "\titers: 2000, epoch: 6 | loss: 0.0136116\n",
            "\tspeed: 0.1938s/iter; left time: 372.5910s\n",
            "\titers: 2100, epoch: 6 | loss: 0.0254714\n",
            "\tspeed: 0.1948s/iter; left time: 355.1021s\n",
            "\titers: 2200, epoch: 6 | loss: 0.0136512\n",
            "\tspeed: 0.1944s/iter; left time: 334.8740s\n",
            "\titers: 2300, epoch: 6 | loss: 0.0254978\n",
            "\tspeed: 0.1939s/iter; left time: 314.7779s\n",
            "\titers: 2400, epoch: 6 | loss: 0.0138677\n",
            "\tspeed: 0.1942s/iter; left time: 295.8353s\n",
            "\titers: 2500, epoch: 6 | loss: 0.0252916\n",
            "\tspeed: 0.1944s/iter; left time: 276.5718s\n",
            "\titers: 2600, epoch: 6 | loss: 0.0136084\n",
            "\tspeed: 0.1936s/iter; left time: 256.0926s\n",
            "\titers: 2700, epoch: 6 | loss: 0.0252421\n",
            "\tspeed: 0.1942s/iter; left time: 237.4794s\n",
            "\titers: 2800, epoch: 6 | loss: 0.0138351\n",
            "\tspeed: 0.1942s/iter; left time: 218.0733s\n",
            "\titers: 2900, epoch: 6 | loss: 0.0251881\n",
            "\tspeed: 0.1948s/iter; left time: 199.2991s\n",
            "\titers: 3000, epoch: 6 | loss: 0.0138677\n",
            "\tspeed: 0.1938s/iter; left time: 178.8795s\n",
            "\titers: 3100, epoch: 6 | loss: 0.0252790\n",
            "\tspeed: 0.1947s/iter; left time: 160.1972s\n",
            "\titers: 3200, epoch: 6 | loss: 0.0136074\n",
            "\tspeed: 0.1942s/iter; left time: 140.3804s\n",
            "\titers: 3300, epoch: 6 | loss: 0.0255321\n",
            "\tspeed: 0.1933s/iter; left time: 120.4196s\n",
            "\titers: 3400, epoch: 6 | loss: 0.0136510\n",
            "\tspeed: 0.1940s/iter; left time: 101.4845s\n",
            "\titers: 3500, epoch: 6 | loss: 0.0253245\n",
            "\tspeed: 0.1938s/iter; left time: 81.9954s\n",
            "\titers: 3600, epoch: 6 | loss: 0.0136914\n",
            "\tspeed: 0.1940s/iter; left time: 62.6732s\n",
            "\titers: 3700, epoch: 6 | loss: 0.0251867\n",
            "\tspeed: 0.1949s/iter; left time: 43.4601s\n",
            "\titers: 3800, epoch: 6 | loss: 0.0136240\n",
            "\tspeed: 0.1937s/iter; left time: 23.8277s\n",
            "\titers: 3900, epoch: 6 | loss: 0.0255379\n",
            "\tspeed: 0.1941s/iter; left time: 4.4650s\n",
            "Epoch: 6, Steps: 3922 | Train Loss: 0.0155900 Vali Loss: 0.0213946 Test Loss: 0.0324008\n",
            "Validation loss decreased (0.021434 --> 0.021395).  Saving model ...\n",
            "Updating learning rate to 3.125e-06\n",
            ">>>>>>>testing : gta_WADI_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 172741\n",
            "test shape: (863, 200, 1, 124) (863, 200, 1, 124)\n",
            "test shape: (172600, 1, 124) (172600, 1, 124)\n",
            "mse:0.032400298231432575, mae:0.0970916305975514\n"
          ]
        }
      ],
      "source": [
        "!python -u main_gta_dad.py --model gta --data WADI --root_path '/content/drive/MyDrive/Colab_Notebooks/GTA/data/rename' --data_path '/data/rename/WADI_14days_colab.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUlF6U7H0YyV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "label = np.load('/content/drive/MyDrive/Colab_Notebooks/GTA/results/gta_WADI_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_0/label.npy')\n",
        "metrics = np.load('/content/drive/MyDrive/Colab_Notebooks/GTA/results/gta_WADI_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_0/metrics.npy')\n",
        "pred =  np.load('/content/drive/MyDrive/Colab_Notebooks/GTA/results/gta_WADI_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_0/pred.npy')\n",
        "true =  np.load('/content/drive/MyDrive/Colab_Notebooks/GTA/results/gta_WADI_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_0/true.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqfMRQzZaszm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "def prep(pred, true, col):\n",
        "  data_f = np.zeros((pred.shape))\n",
        "  for i in range(len(pred)):\n",
        "    data_f[i] = ((pred[i] - true[i])**2).sum()\n",
        "  f1 = torch.from_numpy(data_f)\n",
        "  mp1 = nn.MaxPool1d(col)\n",
        "  f1 = f1.squeeze()\n",
        "  f1 = mp1(f1)\n",
        "  f1 = f1.squeeze()\n",
        "  result = f1.numpy()\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMR7xbb_1iVP"
      },
      "outputs": [],
      "source": [
        "wadi_se = prep(pred, true, 124)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wWq_9da8iE_",
        "outputId": "d9ea412c-f2e0-4232-d503-095c7f3cc42f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2.32394676, 2.3226587 , 2.42238943, ..., 4.09478585, 4.11913612,\n",
              "       4.05235223])"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wadi_se"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMxMvb3L81aQ",
        "outputId": "40170ed9-3df9-42a0-8e0b-e15b07052987"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[ 9.72544066e-02,  7.00671307e-01,  2.95526656e-01, ...,\n",
              "          1.35485365e-01, -4.59831659e-05,  2.17889961e-01]],\n",
              "\n",
              "       [[ 9.77314013e-02,  7.00973408e-01,  2.95530453e-01, ...,\n",
              "          1.35301521e-01, -1.13622454e-04,  2.18053812e-01]],\n",
              "\n",
              "       [[ 9.87413161e-02,  7.01254013e-01,  2.95448006e-01, ...,\n",
              "          1.35312555e-01, -1.24024113e-04,  2.18050153e-01]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 1.06589248e+00,  8.67606370e-01,  2.94716517e-01, ...,\n",
              "          9.90140822e-02,  3.71662823e-05,  1.62161476e-01]],\n",
              "\n",
              "       [[ 1.06709488e+00,  8.67462197e-01,  2.94533768e-01, ...,\n",
              "          9.88223192e-02, -3.94788678e-05,  1.61348883e-01]],\n",
              "\n",
              "       [[ 1.06686945e+00,  8.66886651e-01,  2.98389733e-01, ...,\n",
              "          9.61232626e-02,  9.62386040e-04,  1.53406554e-01]]])"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Pu1d33E5DiU"
      },
      "outputs": [],
      "source": [
        "f1 = np.where(wadi_se > 4.3, -1 , 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzEVwWbD7I_y"
      },
      "outputs": [],
      "source": [
        "f2 = np.append(f1, np.ones(201))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRstPzdvEhqF",
        "outputId": "1c77e8ec-3c8e-4312-f15c-248a12d72f1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              " 1.0    122271\n",
              "-1.0     50530\n",
              "dtype: int64"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(f2).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNA7nYv2iL-n",
        "outputId": "c65f7c18-5f43-4fd2-da7d-4ab4be62ee12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              " 1    162824\n",
              "-1      9977\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attack_data['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J65sSL_0DdIS",
        "outputId": "6e09174b-1aa6-4970-ee19-d19a5b586b4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8108034164050579\n",
            "0.7098339311158061\n",
            "[[  3284   6693]\n",
            " [ 47246 115578]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
        "print(f1_score(attack_data['label'], f2))\n",
        "print(recall_score(attack_data['label'], f2))\n",
        "print(confusion_matrix(attack_data['label'], f2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCUgnAFz7F1m"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(f2).to_csv( '/content/drive/MyDrive/Colab_Notebooks/GTA/results/wadi_gta_se_81_70.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9pPOCmz9F3a"
      },
      "source": [
        "----\n",
        "### SWAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f8J2Vbx9H-y",
        "outputId": "459ab0bb-7834-47f1-b018-41f0fa3029e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "my_path = '/content/notebooks'\n",
        "sys.path.append('/content/drive/MyDrive/Colab_Notebooks/GTA/myenv')\n",
        "sys.path.append('/content/drive/MyDrive/Colab_Notebooks/GTA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hUyrptm_RnJ"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# train = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/SWAT/SWaT_Dataset_Normal_v1_0.csv')\n",
        "# attack_data = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/SWAT/SWaT_Dataset_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izCXQ3pNG8P8",
        "outputId": "64fa50b0-c3d6-4382-8bcf-4382b99b653d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n"
          ]
        }
      ],
      "source": [
        "# from datetime import datetime\n",
        "# import time\n",
        "# train[' Timestamp'] = pd.to_datetime(train[' Timestamp'])\n",
        "# attack_data[' Timestamp'] = pd.to_datetime(attack_data[' Timestamp'])\n",
        "# for i in range(len(train[' Timestamp'])):\n",
        "#   train[' Timestamp'].iloc[i] = time.mktime(train[' Timestamp'].iloc[i].timetuple())\n",
        "# for i in range(len(attack_data[' Timestamp'])):\n",
        "#   attack_data[' Timestamp'].iloc[i] = time.mktime(attack_data[' Timestamp'].iloc[i].timetuple())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDgkzMxSIEY_"
      },
      "outputs": [],
      "source": [
        "# train.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/SWAT//ts_modi/SWaT_Dataset_Normal_v1_0.csv')\n",
        "# attack_data.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/SWAT/ts_modi/SWaT_Dataset_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkDby0zUNQT2"
      },
      "outputs": [],
      "source": [
        "# train.drop('label', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayuyACwKNWm9"
      },
      "outputs": [],
      "source": [
        "# train1 = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/SWAT/SWaT_Dataset_Normal_v1_0.csv', index_col=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNLGn6l-N0Iy",
        "outputId": "8353ee0e-d55f-4b0e-a6a5-fe7ec69af43b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab_Notebooks/GTA\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab_Notebooks/GTA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/SWAT/ts_modi/SWaT_Dataset_Normal_v1_0.csv', index_col=[0])"
      ],
      "metadata": {
        "id": "aSTlxmYmHhU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DipS2Kt-MhtD"
      },
      "outputs": [],
      "source": [
        "# train.drop('label', axis=1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHw9EZkNIYNp",
        "outputId": "f43a6449-8184-4dad-caf2-4fe7706f4417"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : gta_SWaT_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 322228\n",
            "val 112419\n",
            "test 449859\n",
            "\titers: 100, epoch: 1 | loss: 2136.4624244\n",
            "\tspeed: 0.0812s/iter; left time: 776.7683s\n",
            "\titers: 200, epoch: 1 | loss: 2109.4077902\n",
            "\tspeed: 0.0802s/iter; left time: 759.1403s\n",
            "\titers: 300, epoch: 1 | loss: 2082.3625570\n",
            "\tspeed: 0.0797s/iter; left time: 746.3424s\n",
            "\titers: 400, epoch: 1 | loss: 2055.3211870\n",
            "\tspeed: 0.0797s/iter; left time: 738.4226s\n",
            "\titers: 500, epoch: 1 | loss: 2028.2795093\n",
            "\tspeed: 0.0791s/iter; left time: 724.7304s\n",
            "\titers: 600, epoch: 1 | loss: 2001.2392093\n",
            "\tspeed: 0.0789s/iter; left time: 715.7889s\n",
            "\titers: 700, epoch: 1 | loss: 1974.1978655\n",
            "\tspeed: 0.0793s/iter; left time: 710.8260s\n",
            "\titers: 800, epoch: 1 | loss: 1947.1572752\n",
            "\tspeed: 0.0798s/iter; left time: 707.8202s\n",
            "\titers: 900, epoch: 1 | loss: 1920.1165919\n",
            "\tspeed: 0.0797s/iter; left time: 699.0502s\n",
            "\titers: 1000, epoch: 1 | loss: 1893.0761445\n",
            "\tspeed: 0.0794s/iter; left time: 688.0753s\n",
            "\titers: 1100, epoch: 1 | loss: 1866.0358566\n",
            "\tspeed: 0.0809s/iter; left time: 692.9686s\n",
            "\titers: 1200, epoch: 1 | loss: 1838.9959830\n",
            "\tspeed: 0.0797s/iter; left time: 674.7134s\n",
            "\titers: 1300, epoch: 1 | loss: 1811.9558255\n",
            "\tspeed: 0.0799s/iter; left time: 668.6942s\n",
            "\titers: 1400, epoch: 1 | loss: 1784.9151654\n",
            "\tspeed: 0.0792s/iter; left time: 655.1255s\n",
            "\titers: 1500, epoch: 1 | loss: 1757.8743586\n",
            "\tspeed: 0.0801s/iter; left time: 654.1167s\n",
            "\titers: 1600, epoch: 1 | loss: 1730.8347004\n",
            "\tspeed: 0.0797s/iter; left time: 643.1889s\n",
            "Epoch: 1, Steps: 1611 | Train Loss: 1945.5409494 Vali Loss: 0.1164382 Test Loss: 0.1133114\n",
            "Validation loss decreased (inf --> 0.116438).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 1700.8194877\n",
            "\tspeed: 1.0049s/iter; left time: 7995.2612s\n",
            "\titers: 200, epoch: 2 | loss: 1673.7794770\n",
            "\tspeed: 0.0800s/iter; left time: 628.8677s\n",
            "\titers: 300, epoch: 2 | loss: 1646.7397081\n",
            "\tspeed: 0.0795s/iter; left time: 616.8224s\n",
            "\titers: 400, epoch: 2 | loss: 1619.6997950\n",
            "\tspeed: 0.0794s/iter; left time: 607.9077s\n",
            "\titers: 500, epoch: 2 | loss: 1592.6590430\n",
            "\tspeed: 0.0791s/iter; left time: 597.9913s\n",
            "\titers: 600, epoch: 2 | loss: 1565.6190490\n",
            "\tspeed: 0.0795s/iter; left time: 593.0210s\n",
            "\titers: 700, epoch: 2 | loss: 1538.5789167\n",
            "\tspeed: 0.0797s/iter; left time: 586.0484s\n",
            "\titers: 800, epoch: 2 | loss: 1511.5384664\n",
            "\tspeed: 0.0809s/iter; left time: 587.1220s\n",
            "\titers: 900, epoch: 2 | loss: 1484.4985656\n",
            "\tspeed: 0.0804s/iter; left time: 575.4524s\n",
            "\titers: 1000, epoch: 2 | loss: 1457.4585901\n",
            "\tspeed: 0.0798s/iter; left time: 563.1843s\n",
            "\titers: 1100, epoch: 2 | loss: 1430.4181438\n",
            "\tspeed: 0.0798s/iter; left time: 555.4125s\n",
            "\titers: 1200, epoch: 2 | loss: 1403.3784640\n",
            "\tspeed: 0.0799s/iter; left time: 547.9038s\n",
            "\titers: 1300, epoch: 2 | loss: 1376.3385140\n",
            "\tspeed: 0.0794s/iter; left time: 536.3024s\n",
            "\titers: 1400, epoch: 2 | loss: 1349.2981148\n",
            "\tspeed: 0.0797s/iter; left time: 530.4317s\n",
            "\titers: 1500, epoch: 2 | loss: 1322.2581294\n",
            "\tspeed: 0.0794s/iter; left time: 520.7451s\n",
            "\titers: 1600, epoch: 2 | loss: 1295.2182539\n",
            "\tspeed: 0.0793s/iter; left time: 511.8866s\n",
            "Epoch: 2, Steps: 1611 | Train Loss: 1509.9164410 Vali Loss: 0.1114069 Test Loss: 0.1084728\n",
            "Validation loss decreased (0.116438 --> 0.111407).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 1278.5886768\n",
            "\tspeed: 0.9970s/iter; left time: 6326.2438s\n",
            "\titers: 200, epoch: 3 | loss: 1265.0684867\n",
            "\tspeed: 0.0794s/iter; left time: 495.9566s\n",
            "\titers: 300, epoch: 3 | loss: 1251.5481917\n",
            "\tspeed: 0.0804s/iter; left time: 493.7670s\n",
            "\titers: 400, epoch: 3 | loss: 1238.0286298\n",
            "\tspeed: 0.0811s/iter; left time: 490.3678s\n",
            "\titers: 500, epoch: 3 | loss: 1224.5082729\n",
            "\tspeed: 0.0796s/iter; left time: 473.0409s\n",
            "\titers: 600, epoch: 3 | loss: 1210.9882992\n",
            "\tspeed: 0.0793s/iter; left time: 463.3767s\n",
            "\titers: 700, epoch: 3 | loss: 1197.4681743\n",
            "\tspeed: 0.0797s/iter; left time: 457.7706s\n",
            "\titers: 800, epoch: 3 | loss: 1183.9483942\n",
            "\tspeed: 0.0795s/iter; left time: 448.7069s\n",
            "\titers: 900, epoch: 3 | loss: 1170.4281488\n",
            "\tspeed: 0.0796s/iter; left time: 441.4288s\n",
            "\titers: 1000, epoch: 3 | loss: 1156.9079220\n",
            "\tspeed: 0.0796s/iter; left time: 433.6569s\n",
            "\titers: 1100, epoch: 3 | loss: 1143.3879307\n",
            "\tspeed: 0.0793s/iter; left time: 423.7398s\n",
            "\titers: 1200, epoch: 3 | loss: 1129.8677700\n",
            "\tspeed: 0.0797s/iter; left time: 418.2295s\n",
            "\titers: 1300, epoch: 3 | loss: 1116.3479471\n",
            "\tspeed: 0.0789s/iter; left time: 405.8280s\n",
            "\titers: 1400, epoch: 3 | loss: 1102.8280218\n",
            "\tspeed: 0.0789s/iter; left time: 397.8793s\n",
            "\titers: 1500, epoch: 3 | loss: 1089.3079652\n",
            "\tspeed: 0.0794s/iter; left time: 392.6294s\n",
            "\titers: 1600, epoch: 3 | loss: 1075.7877357\n",
            "\tspeed: 0.0807s/iter; left time: 391.2202s\n",
            "Epoch: 3, Steps: 1611 | Train Loss: 1183.1369474 Vali Loss: 0.1077630 Test Loss: 0.1052347\n",
            "Validation loss decreased (0.111407 --> 0.107763).  Saving model ...\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 1067.4730872\n",
            "\tspeed: 1.0026s/iter; left time: 4746.4526s\n",
            "\titers: 200, epoch: 4 | loss: 1060.7132324\n",
            "\tspeed: 0.0792s/iter; left time: 366.8334s\n",
            "\titers: 300, epoch: 4 | loss: 1053.9532648\n",
            "\tspeed: 0.0799s/iter; left time: 362.2445s\n",
            "\titers: 400, epoch: 4 | loss: 1047.1929172\n",
            "\tspeed: 0.0792s/iter; left time: 351.3212s\n",
            "\titers: 500, epoch: 4 | loss: 1040.4331010\n",
            "\tspeed: 0.0792s/iter; left time: 343.4117s\n",
            "\titers: 600, epoch: 4 | loss: 1033.6730033\n",
            "\tspeed: 0.0793s/iter; left time: 335.8448s\n",
            "\titers: 700, epoch: 4 | loss: 1026.9129602\n",
            "\tspeed: 0.0791s/iter; left time: 326.9226s\n",
            "\titers: 800, epoch: 4 | loss: 1020.1531060\n",
            "\tspeed: 0.0798s/iter; left time: 321.9823s\n",
            "\titers: 900, epoch: 4 | loss: 1013.3929982\n",
            "\tspeed: 0.0795s/iter; left time: 312.7110s\n",
            "\titers: 1000, epoch: 4 | loss: 1006.6328292\n",
            "\tspeed: 0.0797s/iter; left time: 305.5969s\n",
            "\titers: 1100, epoch: 4 | loss: 999.8728169\n",
            "\tspeed: 0.0794s/iter; left time: 296.3886s\n",
            "\titers: 1200, epoch: 4 | loss: 993.1130475\n",
            "\tspeed: 0.0802s/iter; left time: 291.4120s\n",
            "\titers: 1300, epoch: 4 | loss: 986.3532373\n",
            "\tspeed: 0.0801s/iter; left time: 283.0591s\n",
            "\titers: 1400, epoch: 4 | loss: 979.5930642\n",
            "\tspeed: 0.0795s/iter; left time: 273.1434s\n",
            "\titers: 1500, epoch: 4 | loss: 972.8327750\n",
            "\tspeed: 0.0797s/iter; left time: 265.5817s\n",
            "\titers: 1600, epoch: 4 | loss: 966.0729375\n",
            "\tspeed: 0.0790s/iter; left time: 255.4517s\n",
            "Epoch: 4, Steps: 1611 | Train Loss: 1019.7474299 Vali Loss: 0.1056020 Test Loss: 0.1034738\n",
            "Validation loss decreased (0.107763 --> 0.105602).  Saving model ...\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 5 | loss: 961.9154284\n",
            "\tspeed: 1.0021s/iter; left time: 3129.5556s\n",
            "\titers: 200, epoch: 5 | loss: 958.5356243\n",
            "\tspeed: 0.0792s/iter; left time: 239.3352s\n",
            "\titers: 300, epoch: 5 | loss: 955.1555146\n",
            "\tspeed: 0.0789s/iter; left time: 230.5632s\n",
            "\titers: 400, epoch: 5 | loss: 951.7753395\n",
            "\tspeed: 0.0789s/iter; left time: 222.7857s\n",
            "\titers: 500, epoch: 5 | loss: 948.3955568\n",
            "\tspeed: 0.0788s/iter; left time: 214.4487s\n",
            "\titers: 600, epoch: 5 | loss: 945.0154156\n",
            "\tspeed: 0.0794s/iter; left time: 208.2906s\n",
            "\titers: 700, epoch: 5 | loss: 941.6352157\n",
            "\tspeed: 0.0794s/iter; left time: 200.3111s\n",
            "\titers: 800, epoch: 5 | loss: 938.2552861\n",
            "\tspeed: 0.0795s/iter; left time: 192.7398s\n",
            "\titers: 900, epoch: 5 | loss: 934.8752796\n",
            "\tspeed: 0.0804s/iter; left time: 186.7896s\n",
            "\titers: 1000, epoch: 5 | loss: 931.4956636\n",
            "\tspeed: 0.0791s/iter; left time: 175.8908s\n",
            "\titers: 1100, epoch: 5 | loss: 928.1155746\n",
            "\tspeed: 0.0793s/iter; left time: 168.3742s\n",
            "\titers: 1200, epoch: 5 | loss: 924.7354914\n",
            "\tspeed: 0.0798s/iter; left time: 161.3642s\n",
            "\titers: 1300, epoch: 5 | loss: 921.3555489\n",
            "\tspeed: 0.0788s/iter; left time: 151.5309s\n",
            "\titers: 1400, epoch: 5 | loss: 917.9753148\n",
            "\tspeed: 0.0793s/iter; left time: 144.5883s\n",
            "\titers: 1500, epoch: 5 | loss: 914.5955119\n",
            "\tspeed: 0.0790s/iter; left time: 136.0468s\n",
            "\titers: 1600, epoch: 5 | loss: 911.2156287\n",
            "\tspeed: 0.0794s/iter; left time: 128.8795s\n",
            "Epoch: 5, Steps: 1611 | Train Loss: 938.0526796 Vali Loss: 0.1045082 Test Loss: 0.1023061\n",
            "Validation loss decreased (0.105602 --> 0.104508).  Saving model ...\n",
            "Updating learning rate to 6.25e-06\n",
            "\titers: 100, epoch: 6 | loss: 909.1365875\n",
            "\tspeed: 1.0072s/iter; left time: 1522.9208s\n",
            "\titers: 200, epoch: 6 | loss: 907.4466109\n",
            "\tspeed: 0.0792s/iter; left time: 111.8818s\n",
            "\titers: 300, epoch: 6 | loss: 905.7568879\n",
            "\tspeed: 0.0794s/iter; left time: 104.1964s\n",
            "\titers: 400, epoch: 6 | loss: 904.0666201\n",
            "\tspeed: 0.0789s/iter; left time: 95.6340s\n",
            "\titers: 500, epoch: 6 | loss: 902.3767353\n",
            "\tspeed: 0.0805s/iter; left time: 89.5162s\n",
            "\titers: 600, epoch: 6 | loss: 900.6868376\n",
            "\tspeed: 0.0795s/iter; left time: 80.4785s\n",
            "\titers: 700, epoch: 6 | loss: 898.9967384\n",
            "\tspeed: 0.0799s/iter; left time: 72.8399s\n",
            "\titers: 800, epoch: 6 | loss: 897.3065569\n",
            "\tspeed: 0.0793s/iter; left time: 64.4236s\n",
            "\titers: 900, epoch: 6 | loss: 895.6167992\n",
            "\tspeed: 0.0788s/iter; left time: 56.0923s\n",
            "\titers: 1000, epoch: 6 | loss: 893.9266591\n",
            "\tspeed: 0.0788s/iter; left time: 48.2261s\n",
            "\titers: 1100, epoch: 6 | loss: 892.2364991\n",
            "\tspeed: 0.0792s/iter; left time: 40.5678s\n",
            "\titers: 1200, epoch: 6 | loss: 890.5467156\n",
            "\tspeed: 0.0791s/iter; left time: 32.5717s\n",
            "\titers: 1300, epoch: 6 | loss: 888.8566260\n",
            "\tspeed: 0.0789s/iter; left time: 24.6117s\n",
            "\titers: 1400, epoch: 6 | loss: 887.1666961\n",
            "\tspeed: 0.0789s/iter; left time: 16.7257s\n",
            "\titers: 1500, epoch: 6 | loss: 885.4766973\n",
            "\tspeed: 0.0788s/iter; left time: 8.8244s\n",
            "\titers: 1600, epoch: 6 | loss: 883.7866350\n",
            "\tspeed: 0.0791s/iter; left time: 0.9494s\n",
            "Epoch: 6, Steps: 1611 | Train Loss: 897.2052997 Vali Loss: 0.1038509 Test Loss: 0.1016525\n",
            "Validation loss decreased (0.104508 --> 0.103851).  Saving model ...\n",
            "Updating learning rate to 3.125e-06\n",
            ">>>>>>>testing : gta_SWaT_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 449859\n",
            "test shape: (2249, 200, 1, 52) (2249, 200, 1, 52)\n",
            "test shape: (449800, 1, 52) (449800, 1, 52)\n",
            "mse:0.10164295367341226, mae:0.1989830251316841\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : gta_SWaT_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 322228\n",
            "val 112419\n",
            "test 449859\n",
            "\titers: 100, epoch: 1 | loss: 2136.4611599\n",
            "\tspeed: 0.0801s/iter; left time: 766.3224s\n",
            "\titers: 200, epoch: 1 | loss: 2109.4073045\n",
            "\tspeed: 0.0797s/iter; left time: 754.1775s\n",
            "\titers: 300, epoch: 1 | loss: 2082.3634648\n",
            "\tspeed: 0.0795s/iter; left time: 745.0753s\n",
            "\titers: 400, epoch: 1 | loss: 2055.3204277\n",
            "\tspeed: 0.0800s/iter; left time: 741.1312s\n",
            "\titers: 500, epoch: 1 | loss: 2028.2793982\n",
            "\tspeed: 0.0795s/iter; left time: 728.8457s\n",
            "\titers: 600, epoch: 1 | loss: 2001.2385582\n",
            "\tspeed: 0.0794s/iter; left time: 719.9815s\n",
            "\titers: 700, epoch: 1 | loss: 1974.1980345\n",
            "\tspeed: 0.0796s/iter; left time: 713.5361s\n",
            "\titers: 800, epoch: 1 | loss: 1947.1580889\n",
            "\tspeed: 0.0798s/iter; left time: 707.2075s\n",
            "\titers: 900, epoch: 1 | loss: 1920.1171734\n",
            "\tspeed: 0.0798s/iter; left time: 699.2239s\n",
            "\titers: 1000, epoch: 1 | loss: 1893.0767440\n",
            "\tspeed: 0.0794s/iter; left time: 688.2240s\n",
            "\titers: 1100, epoch: 1 | loss: 1866.0358087\n",
            "\tspeed: 0.0795s/iter; left time: 681.4790s\n",
            "\titers: 1200, epoch: 1 | loss: 1838.9954218\n",
            "\tspeed: 0.0809s/iter; left time: 685.3857s\n",
            "\titers: 1300, epoch: 1 | loss: 1811.9552481\n",
            "\tspeed: 0.0802s/iter; left time: 670.8853s\n",
            "\titers: 1400, epoch: 1 | loss: 1784.9150819\n",
            "\tspeed: 0.0794s/iter; left time: 656.5697s\n",
            "\titers: 1500, epoch: 1 | loss: 1757.8747005\n",
            "\tspeed: 0.0796s/iter; left time: 649.8532s\n",
            "\titers: 1600, epoch: 1 | loss: 1730.8346507\n",
            "\tspeed: 0.0801s/iter; left time: 646.3881s\n",
            "Epoch: 1, Steps: 1611 | Train Loss: 1945.5413651 Vali Loss: 0.1122369 Test Loss: 0.1109600\n",
            "Validation loss decreased (inf --> 0.112237).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 1700.8197815\n",
            "\tspeed: 1.0127s/iter; left time: 8056.7790s\n",
            "\titers: 200, epoch: 2 | loss: 1673.7797035\n",
            "\tspeed: 0.0795s/iter; left time: 624.3674s\n",
            "\titers: 300, epoch: 2 | loss: 1646.7395024\n",
            "\tspeed: 0.0795s/iter; left time: 616.9427s\n",
            "\titers: 400, epoch: 2 | loss: 1619.6993157\n",
            "\tspeed: 0.0794s/iter; left time: 607.8587s\n",
            "\titers: 500, epoch: 2 | loss: 1592.6591547\n",
            "\tspeed: 0.0795s/iter; left time: 600.7896s\n",
            "\titers: 600, epoch: 2 | loss: 1565.6189647\n",
            "\tspeed: 0.0790s/iter; left time: 588.6812s\n",
            "\titers: 700, epoch: 2 | loss: 1538.5788720\n",
            "\tspeed: 0.0791s/iter; left time: 581.8728s\n",
            "\titers: 800, epoch: 2 | loss: 1511.5388194\n",
            "\tspeed: 0.0802s/iter; left time: 581.9341s\n",
            "\titers: 900, epoch: 2 | loss: 1484.4985783\n",
            "\tspeed: 0.0812s/iter; left time: 581.3345s\n",
            "\titers: 1000, epoch: 2 | loss: 1457.4587323\n",
            "\tspeed: 0.0791s/iter; left time: 558.3806s\n",
            "\titers: 1100, epoch: 2 | loss: 1430.4183651\n",
            "\tspeed: 0.0788s/iter; left time: 548.4763s\n",
            "\titers: 1200, epoch: 2 | loss: 1403.3782967\n",
            "\tspeed: 0.0791s/iter; left time: 542.4575s\n",
            "\titers: 1300, epoch: 2 | loss: 1376.3381756\n",
            "\tspeed: 0.0790s/iter; left time: 533.9141s\n",
            "\titers: 1400, epoch: 2 | loss: 1349.2977757\n",
            "\tspeed: 0.0793s/iter; left time: 527.8202s\n",
            "\titers: 1500, epoch: 2 | loss: 1322.2580857\n",
            "\tspeed: 0.0787s/iter; left time: 516.0204s\n",
            "\titers: 1600, epoch: 2 | loss: 1295.2178629\n",
            "\tspeed: 0.0788s/iter; left time: 509.0309s\n",
            "Epoch: 2, Steps: 1611 | Train Loss: 1509.9164253 Vali Loss: 0.1067306 Test Loss: 0.1049109\n",
            "Validation loss decreased (0.112237 --> 0.106731).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 1278.5880871\n",
            "\tspeed: 0.9958s/iter; left time: 6318.4545s\n",
            "\titers: 200, epoch: 3 | loss: 1265.0682481\n",
            "\tspeed: 0.0794s/iter; left time: 495.8541s\n",
            "\titers: 300, epoch: 3 | loss: 1251.5482145\n",
            "\tspeed: 0.0790s/iter; left time: 485.3713s\n",
            "\titers: 400, epoch: 3 | loss: 1238.0282769\n",
            "\tspeed: 0.0788s/iter; left time: 476.4396s\n",
            "\titers: 500, epoch: 3 | loss: 1224.5078612\n",
            "\tspeed: 0.0798s/iter; left time: 474.5826s\n",
            "\titers: 600, epoch: 3 | loss: 1210.9881603\n",
            "\tspeed: 0.0796s/iter; left time: 465.0238s\n",
            "\titers: 700, epoch: 3 | loss: 1197.4681768\n",
            "\tspeed: 0.0793s/iter; left time: 455.3584s\n",
            "\titers: 800, epoch: 3 | loss: 1183.9479704\n",
            "\tspeed: 0.0791s/iter; left time: 446.7543s\n",
            "\titers: 900, epoch: 3 | loss: 1170.4281540\n",
            "\tspeed: 0.0788s/iter; left time: 437.1047s\n",
            "\titers: 1000, epoch: 3 | loss: 1156.9083371\n",
            "\tspeed: 0.0789s/iter; left time: 429.8811s\n",
            "\titers: 1100, epoch: 3 | loss: 1143.3880587\n",
            "\tspeed: 0.0793s/iter; left time: 424.0794s\n",
            "\titers: 1200, epoch: 3 | loss: 1129.8678377\n",
            "\tspeed: 0.0789s/iter; left time: 413.8244s\n",
            "\titers: 1300, epoch: 3 | loss: 1116.3477908\n",
            "\tspeed: 0.0789s/iter; left time: 405.6929s\n",
            "\titers: 1400, epoch: 3 | loss: 1102.8278855\n",
            "\tspeed: 0.0791s/iter; left time: 399.1981s\n",
            "\titers: 1500, epoch: 3 | loss: 1089.3081042\n",
            "\tspeed: 0.0795s/iter; left time: 393.2312s\n",
            "\titers: 1600, epoch: 3 | loss: 1075.7879055\n",
            "\tspeed: 0.0789s/iter; left time: 382.4739s\n",
            "Epoch: 3, Steps: 1611 | Train Loss: 1183.1368954 Vali Loss: 0.1051318 Test Loss: 0.1033539\n",
            "Validation loss decreased (0.106731 --> 0.105132).  Saving model ...\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 1067.4729871\n",
            "\tspeed: 0.9922s/iter; left time: 4697.2945s\n",
            "\titers: 200, epoch: 4 | loss: 1060.7130218\n",
            "\tspeed: 0.0805s/iter; left time: 373.0181s\n",
            "\titers: 300, epoch: 4 | loss: 1053.9530995\n",
            "\tspeed: 0.0799s/iter; left time: 362.0581s\n",
            "\titers: 400, epoch: 4 | loss: 1047.1929407\n",
            "\tspeed: 0.0791s/iter; left time: 350.8911s\n",
            "\titers: 500, epoch: 4 | loss: 1040.4330490\n",
            "\tspeed: 0.0791s/iter; left time: 342.6929s\n",
            "\titers: 600, epoch: 4 | loss: 1033.6728954\n",
            "\tspeed: 0.0791s/iter; left time: 335.0291s\n",
            "\titers: 700, epoch: 4 | loss: 1026.9127042\n",
            "\tspeed: 0.0792s/iter; left time: 327.4747s\n",
            "\titers: 800, epoch: 4 | loss: 1020.1528978\n",
            "\tspeed: 0.0798s/iter; left time: 321.7716s\n",
            "\titers: 900, epoch: 4 | loss: 1013.3930767\n",
            "\tspeed: 0.0793s/iter; left time: 312.0796s\n",
            "\titers: 1000, epoch: 4 | loss: 1006.6329530\n",
            "\tspeed: 0.0791s/iter; left time: 303.2659s\n",
            "\titers: 1100, epoch: 4 | loss: 999.8730038\n",
            "\tspeed: 0.0793s/iter; left time: 296.0585s\n",
            "\titers: 1200, epoch: 4 | loss: 993.1129162\n",
            "\tspeed: 0.0798s/iter; left time: 290.1492s\n",
            "\titers: 1300, epoch: 4 | loss: 986.3528388\n",
            "\tspeed: 0.0796s/iter; left time: 281.4243s\n",
            "\titers: 1400, epoch: 4 | loss: 979.5928011\n",
            "\tspeed: 0.0801s/iter; left time: 274.9002s\n",
            "\titers: 1500, epoch: 4 | loss: 972.8328531\n",
            "\tspeed: 0.0797s/iter; left time: 265.6929s\n",
            "\titers: 1600, epoch: 4 | loss: 966.0728255\n",
            "\tspeed: 0.0791s/iter; left time: 255.6551s\n",
            "Epoch: 4, Steps: 1611 | Train Loss: 1019.7473827 Vali Loss: 0.1038181 Test Loss: 0.1021672\n",
            "Validation loss decreased (0.105132 --> 0.103818).  Saving model ...\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 5 | loss: 961.9155094\n",
            "\tspeed: 0.9969s/iter; left time: 3113.2072s\n",
            "\titers: 200, epoch: 5 | loss: 958.5354570\n",
            "\tspeed: 0.0801s/iter; left time: 242.1486s\n",
            "\titers: 300, epoch: 5 | loss: 955.1553779\n",
            "\tspeed: 0.0795s/iter; left time: 232.2519s\n",
            "\titers: 400, epoch: 5 | loss: 951.7754674\n",
            "\tspeed: 0.0792s/iter; left time: 223.6948s\n",
            "\titers: 500, epoch: 5 | loss: 948.3954918\n",
            "\tspeed: 0.0794s/iter; left time: 216.1323s\n",
            "\titers: 600, epoch: 5 | loss: 945.0154051\n",
            "\tspeed: 0.0793s/iter; left time: 208.0057s\n",
            "\titers: 700, epoch: 5 | loss: 941.6353805\n",
            "\tspeed: 0.0792s/iter; left time: 199.8131s\n",
            "\titers: 800, epoch: 5 | loss: 938.2551867\n",
            "\tspeed: 0.0790s/iter; left time: 191.3491s\n",
            "\titers: 900, epoch: 5 | loss: 934.8753381\n",
            "\tspeed: 0.0792s/iter; left time: 183.9757s\n",
            "\titers: 1000, epoch: 5 | loss: 931.4954095\n",
            "\tspeed: 0.0798s/iter; left time: 177.3779s\n",
            "\titers: 1100, epoch: 5 | loss: 928.1153655\n",
            "\tspeed: 0.0809s/iter; left time: 171.8129s\n",
            "\titers: 1200, epoch: 5 | loss: 924.7354356\n",
            "\tspeed: 0.0790s/iter; left time: 159.9127s\n",
            "\titers: 1300, epoch: 5 | loss: 921.3552276\n",
            "\tspeed: 0.0794s/iter; left time: 152.6654s\n",
            "\titers: 1400, epoch: 5 | loss: 917.9754259\n",
            "\tspeed: 0.0796s/iter; left time: 145.1344s\n",
            "\titers: 1500, epoch: 5 | loss: 914.5954624\n",
            "\tspeed: 0.0794s/iter; left time: 136.7518s\n",
            "\titers: 1600, epoch: 5 | loss: 911.2154414\n",
            "\tspeed: 0.0796s/iter; left time: 129.2274s\n",
            "Epoch: 5, Steps: 1611 | Train Loss: 938.0526334 Vali Loss: 0.1031659 Test Loss: 0.1015935\n",
            "Validation loss decreased (0.103818 --> 0.103166).  Saving model ...\n",
            "Updating learning rate to 6.25e-06\n",
            "\titers: 100, epoch: 6 | loss: 909.1367141\n",
            "\tspeed: 0.9979s/iter; left time: 1508.8560s\n",
            "\titers: 200, epoch: 6 | loss: 907.4467633\n",
            "\tspeed: 0.0791s/iter; left time: 111.7212s\n",
            "\titers: 300, epoch: 6 | loss: 905.7565461\n",
            "\tspeed: 0.0794s/iter; left time: 104.1189s\n",
            "\titers: 400, epoch: 6 | loss: 904.0667044\n",
            "\tspeed: 0.0794s/iter; left time: 96.2054s\n",
            "\titers: 500, epoch: 6 | loss: 902.3766307\n",
            "\tspeed: 0.0793s/iter; left time: 88.1495s\n",
            "\titers: 600, epoch: 6 | loss: 900.6867747\n",
            "\tspeed: 0.0793s/iter; left time: 80.2278s\n",
            "\titers: 700, epoch: 6 | loss: 898.9965302\n",
            "\tspeed: 0.0805s/iter; left time: 73.4495s\n",
            "\titers: 800, epoch: 6 | loss: 897.3068634\n",
            "\tspeed: 0.0810s/iter; left time: 65.7978s\n",
            "\titers: 900, epoch: 6 | loss: 895.6165650\n",
            "\tspeed: 0.0790s/iter; left time: 56.2485s\n",
            "\titers: 1000, epoch: 6 | loss: 893.9265413\n",
            "\tspeed: 0.0790s/iter; left time: 48.3269s\n",
            "\titers: 1100, epoch: 6 | loss: 892.2365942\n",
            "\tspeed: 0.0793s/iter; left time: 40.5810s\n",
            "\titers: 1200, epoch: 6 | loss: 890.5464249\n",
            "\tspeed: 0.0800s/iter; left time: 32.9624s\n",
            "\titers: 1300, epoch: 6 | loss: 888.8564762\n",
            "\tspeed: 0.0791s/iter; left time: 24.6725s\n",
            "\titers: 1400, epoch: 6 | loss: 887.1667814\n",
            "\tspeed: 0.0791s/iter; left time: 16.7658s\n",
            "\titers: 1500, epoch: 6 | loss: 885.4767212\n",
            "\tspeed: 0.0796s/iter; left time: 8.9157s\n",
            "\titers: 1600, epoch: 6 | loss: 883.7865584\n",
            "\tspeed: 0.0792s/iter; left time: 0.9505s\n",
            "Epoch: 6, Steps: 1611 | Train Loss: 897.2052540 Vali Loss: 0.1022888 Test Loss: 0.1008724\n",
            "Validation loss decreased (0.103166 --> 0.102289).  Saving model ...\n",
            "Updating learning rate to 3.125e-06\n",
            ">>>>>>>testing : gta_SWaT_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 449859\n",
            "test shape: (2249, 200, 1, 52) (2249, 200, 1, 52)\n",
            "test shape: (449800, 1, 52) (449800, 1, 52)\n",
            "mse:0.10086688865096384, mae:0.19129404915556847\n"
          ]
        }
      ],
      "source": [
        "!python -u main_gta_dad.py --model gta --data SWaT --root_path '/content/drive/MyDrive/Colab_Notebooks/GTA/data/SWAT/ts_modi' --data_path 'SWaT_Dataset_Normal_v1_0.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XLqsyrTONzW"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(attack_data['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuvbGtm4Zxau"
      },
      "outputs": [],
      "source": [
        "swat_label = np.load('/content/drive/MyDrive/Colab_Notebooks/GTA/results/gta_SWaT_ftM_sl60_ll30_pl1_nl3_dm124_nh8_el3_dl2_df124_atprob_ebfixed_test_1/label.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY4qrprwaLEn",
        "outputId": "587ddf0d-b17c-412c-ded8-8bf160f0026a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(449919,)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "swat_label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUpeYeFaafQI"
      },
      "outputs": [],
      "source": [
        "swat_label = np.append(swat_label, np.zeros(119))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smYdr_EJG7G0"
      },
      "outputs": [],
      "source": [
        "swat_pred = np.load('/content/drive/MyDrive/Colab_Notebooks/GTA/results/gta_SWaT_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_1/pred.npy')\n",
        "swat_true = np.load('/content/drive/MyDrive/Colab_Notebooks/GTA/results/gta_SWaT_ftM_sl60_ll30_pl1_nl3_dm128_nh8_el3_dl2_df128_atprob_ebfixed_test_1/true.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xv9svF0-Hgpn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "f = np.zeros((swat_pred.shape))\n",
        "for i in range(len(f)):\n",
        "  f[i] = ((swat_pred[i] - swat_true[i])**2).sum()\n",
        "f1 = torch.from_numpy(f)\n",
        "mp1 = nn.MaxPool1d(52)\n",
        "f1 = mp1(f1)\n",
        "f1 = f1.squeeze()\n",
        "f2 = f1.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2oSmN1FIK2T",
        "outputId": "11f90044-3bcb-47a3-bff9-22da0a6a7438"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.35144492, 5.35061942, 5.35288508, ..., 6.25730888, 6.26092237,\n",
              "       6.25888077])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "f2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZvkOF4rHglh"
      },
      "outputs": [],
      "source": [
        "f3 = np.where(f2 > 4.3, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIGHgYeMHgjM",
        "outputId": "380a11bd-8ba3-4554-9112-1abfd8134512"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    415988\n",
              "1     33812\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "pd.DataFrame(f3).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqaBArZvIRbh",
        "outputId": "e906eb08-786c-4dba-d525-c4eea1fd5ecc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    395298\n",
              "1     54621\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "attack_data['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoLrdF1wIjdG"
      },
      "outputs": [],
      "source": [
        "f3 = np.append(f3, np.zeros(119))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXayH5bKaERr",
        "outputId": "1d220a50-f414-4783-b714-fa0c30ead737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7619327626564742\n",
            "0.6167957379030043\n",
            "[[395176    122]\n",
            " [ 20931  33690]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
        "print(f1_score(attack_data['label'], f3))\n",
        "print(recall_score(attack_data['label'], f3))\n",
        "print(confusion_matrix(attack_data['label'], f3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htUOdBrLJQ7E"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(f3).to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/results/swat_gta_se_76_61.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgmDcwwMJbDf"
      },
      "source": [
        "---\n",
        "### HAI21.03"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "my_path = '/content/notebooks'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52BLcbs70fwY",
        "outputId": "1bfd245a-d4fc-4fd4-cd99-ace74ea12cae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X7uJz1k0MR1y"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from datetime import *\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def dataframe_from_csv(target):\n",
        "    return pd.read_csv(target).rename(columns=lambda x: x.strip())\n",
        "\n",
        "def dataframe_from_csvs(targets):\n",
        "    return pd.concat([dataframe_from_csv(x) for x in targets])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mP6d0IYsJabb"
      },
      "outputs": [],
      "source": [
        "hai_valid_dataset = sorted([x for x in Path(\"/content/drive/MyDrive/Colab_Notebooks/HAI/data/New folder4/validation/\").glob(\"*.csv\")])\n",
        "hai_valid = dataframe_from_csvs(hai_valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hai_valid"
      ],
      "metadata": {
        "id": "sF0U3kXx1WNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1I--KEOM89u"
      },
      "outputs": [],
      "source": [
        "# hai_test_dataset = sorted([x for x in Path(\"/content/drive/MyDrive/Colab_Notebooks/HAI/data/New folder4/testing\").glob(\"*.csv\")])\n",
        "# hai_test = dataframe_from_csvs(hai_test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZsS8hc7M733",
        "outputId": "25336154-a3fb-419a-c78a-f48ccd9d12ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "hai_valid[' Timestamp'] = pd.to_datetime(hai_valid['time'])\n",
        "for i in range(len(hai_valid[' Timestamp'])):\n",
        "  hai_valid[' Timestamp'].iloc[i] = time.mktime(hai_valid[' Timestamp'].iloc[i].timetuple())\n",
        "\n",
        "# hai_test[' Timestamp'] = pd.to_datetime(hai_test['time'])\n",
        "# for i in range(len(hai_test[' Timestamp'])):\n",
        "  # hai_test[' Timestamp'].iloc[i] = time.mktime(hai_test[' Timestamp'].iloc[i].timetuple())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "svHpxHUtMXDN"
      },
      "outputs": [],
      "source": [
        "# hai_train.drop(['time','attack'],axis=1, inplace = True)\n",
        "# hai_test.drop('time',axis=1, inplace = True)\n",
        "hai_valid.drop('time',axis=1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hai_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "gySv1vLD5ROw",
        "outputId": "8cd73127-61b6-48d9-f680-d4de2e742c5f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             C01   C02  C03       C04     C05      C06        C07       C08  \\\n",
              "0      402.70947  12.0   10  51.95007 -1.0189 -1.86768  789.76508  28.03162   \n",
              "1      402.81174  12.0   10  51.96533 -1.2637 -1.86768  789.13147  28.02301   \n",
              "2      402.76062  12.0   10  51.96533 -1.5398 -1.86768  785.81653  28.02993   \n",
              "3      402.81174  12.0   10  51.98822 -1.6212 -1.86768  785.42438  28.02993   \n",
              "4      402.91394  12.0   10  51.90429 -1.5631 -1.86768  782.99249  28.02990   \n",
              "...          ...   ...  ...       ...     ...      ...        ...       ...   \n",
              "43196  397.08661  12.0   10  66.58325 -1.2052 -1.83716  786.93738  28.03250   \n",
              "43197  397.18887  12.0   10  66.58325 -0.9256 -1.83716  783.44989  28.02304   \n",
              "43198  397.13776  12.0   10  66.58325 -0.7843 -1.83716  784.86780  28.02814   \n",
              "43199  397.34222  12.0   10  66.58325 -0.7646 -1.83716  785.51416  28.02294   \n",
              "43200  397.49557  12.0   10  66.58325 -0.9083 -1.83716  786.98297  28.02990   \n",
              "\n",
              "       C09     C10  ...      C72       C73       C74       C75        C76  \\\n",
              "0      688 -2.8687  ...  1.34293  10.89290  34.88770  12.26196  380.31683   \n",
              "1      648 -2.9842  ...  1.34216  10.80512  34.88770  12.26196  380.02747   \n",
              "2      616 -3.4939  ...  1.34369  10.80029  34.88770  12.26196  381.52850   \n",
              "3      584 -3.8188  ...  1.34445  10.80579  34.88770  12.26196  382.08911   \n",
              "4      552 -3.9858  ...  1.34293  10.81415  34.90295  12.26196  383.44543   \n",
              "...    ...     ...  ...      ...       ...       ...       ...        ...   \n",
              "43196    0 -3.9067  ...  1.35971  16.19496  35.22338  12.01019  390.13672   \n",
              "43197    0 -3.5679  ...  1.35971  16.23927  35.23864  12.01019  390.24518   \n",
              "43198    0 -3.2297  ...  1.35818  16.20675  35.23864  12.01019  390.46222   \n",
              "43199    0 -2.8769  ...  1.35818  16.17168  35.25391  12.01019  391.78241   \n",
              "43200    0 -2.8633  ...  1.35895  16.10412  35.22338  12.01019  391.31219   \n",
              "\n",
              "             C77       C78     C79  attack     Timestamp  \n",
              "0      386.26666  32.59527  5.6330       0  1594134000.0  \n",
              "1      386.30286  32.59527  5.4158       0  1594134001.0  \n",
              "2      389.73883  32.59527  5.5532       0  1594134002.0  \n",
              "3      388.94311  32.59527  5.7833       0  1594134003.0  \n",
              "4      389.72082  32.59527  6.0309       0  1594134004.0  \n",
              "...          ...       ...     ...     ...           ...  \n",
              "43196  394.91107  31.81634  5.2977       0  1594177196.0  \n",
              "43197  397.35248  31.81634  5.3188       0  1594177197.0  \n",
              "43198  396.70142  31.81634  5.1800       0  1594177198.0  \n",
              "43199  397.73218  31.81634  4.8763       0  1594177199.0  \n",
              "43200  397.24390  31.81634  4.5790       0  1594177200.0  \n",
              "\n",
              "[43201 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c72079ae-5d4e-4955-b4c5-c54c66ae20bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C01</th>\n",
              "      <th>C02</th>\n",
              "      <th>C03</th>\n",
              "      <th>C04</th>\n",
              "      <th>C05</th>\n",
              "      <th>C06</th>\n",
              "      <th>C07</th>\n",
              "      <th>C08</th>\n",
              "      <th>C09</th>\n",
              "      <th>C10</th>\n",
              "      <th>...</th>\n",
              "      <th>C72</th>\n",
              "      <th>C73</th>\n",
              "      <th>C74</th>\n",
              "      <th>C75</th>\n",
              "      <th>C76</th>\n",
              "      <th>C77</th>\n",
              "      <th>C78</th>\n",
              "      <th>C79</th>\n",
              "      <th>attack</th>\n",
              "      <th>Timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>402.70947</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10</td>\n",
              "      <td>51.95007</td>\n",
              "      <td>-1.0189</td>\n",
              "      <td>-1.86768</td>\n",
              "      <td>789.76508</td>\n",
              "      <td>28.03162</td>\n",
              "      <td>688</td>\n",
              "      <td>-2.8687</td>\n",
              "      <td>...</td>\n",
              "      <td>1.34293</td>\n",
              "      <td>10.89290</td>\n",
              "      <td>34.88770</td>\n",
              "      <td>12.26196</td>\n",
              "      <td>380.31683</td>\n",
              "      <td>386.26666</td>\n",
              "      <td>32.59527</td>\n",
              "      <td>5.6330</td>\n",
              "      <td>0</td>\n",
              "      <td>1594134000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>402.81174</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10</td>\n",
              "      <td>51.96533</td>\n",
              "      <td>-1.2637</td>\n",
              "      <td>-1.86768</td>\n",
              "      <td>789.13147</td>\n",
              "      <td>28.02301</td>\n",
              "      <td>648</td>\n",
              "      <td>-2.9842</td>\n",
              "      <td>...</td>\n",
              "      <td>1.34216</td>\n",
              "      <td>10.80512</td>\n",
              "      <td>34.88770</td>\n",
              "      <td>12.26196</td>\n",
              "      <td>380.02747</td>\n",
              "      <td>386.30286</td>\n",
              "      <td>32.59527</td>\n",
              "      <td>5.4158</td>\n",
              "      <td>0</td>\n",
              "      <td>1594134001.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>402.76062</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10</td>\n",
              "      <td>51.96533</td>\n",
              "      <td>-1.5398</td>\n",
              "      <td>-1.86768</td>\n",
              "      <td>785.81653</td>\n",
              "      <td>28.02993</td>\n",
              "      <td>616</td>\n",
              "      <td>-3.4939</td>\n",
              "      <td>...</td>\n",
              "      <td>1.34369</td>\n",
              "      <td>10.80029</td>\n",
              "      <td>34.88770</td>\n",
              "      <td>12.26196</td>\n",
              "      <td>381.52850</td>\n",
              "      <td>389.73883</td>\n",
              "      <td>32.59527</td>\n",
              "      <td>5.5532</td>\n",
              "      <td>0</td>\n",
              "      <td>1594134002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>402.81174</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10</td>\n",
              "      <td>51.98822</td>\n",
              "      <td>-1.6212</td>\n",
              "      <td>-1.86768</td>\n",
              "      <td>785.42438</td>\n",
              "      <td>28.02993</td>\n",
              "      <td>584</td>\n",
              "      <td>-3.8188</td>\n",
              "      <td>...</td>\n",
              "      <td>1.34445</td>\n",
              "      <td>10.80579</td>\n",
              "      <td>34.88770</td>\n",
              "      <td>12.26196</td>\n",
              "      <td>382.08911</td>\n",
              "      <td>388.94311</td>\n",
              "      <td>32.59527</td>\n",
              "      <td>5.7833</td>\n",
              "      <td>0</td>\n",
              "      <td>1594134003.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>402.91394</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10</td>\n",
              "      <td>51.90429</td>\n",
              "      <td>-1.5631</td>\n",
              "      <td>-1.86768</td>\n",
              "      <td>782.99249</td>\n",
              "      <td>28.02990</td>\n",
              "      <td>552</td>\n",
              "      <td>-3.9858</td>\n",
              "      <td>...</td>\n",
              "      <td>1.34293</td>\n",
              "      <td>10.81415</td>\n",
              "      <td>34.90295</td>\n",
              "      <td>12.26196</td>\n",
              "      <td>383.44543</td>\n",
              "      <td>389.72082</td>\n",
              "      <td>32.59527</td>\n",
              "      <td>6.0309</td>\n",
              "      <td>0</td>\n",
              "      <td>1594134004.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43196</th>\n",
              "      <td>397.08661</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10</td>\n",
              "      <td>66.58325</td>\n",
              "      <td>-1.2052</td>\n",
              "      <td>-1.83716</td>\n",
              "      <td>786.93738</td>\n",
              "      <td>28.03250</td>\n",
              "      <td>0</td>\n",
              "      <td>-3.9067</td>\n",
              "      <td>...</td>\n",
              "      <td>1.35971</td>\n",
              "      <td>16.19496</td>\n",
              "      <td>35.22338</td>\n",
              "      <td>12.01019</td>\n",
              "      <td>390.13672</td>\n",
              "      <td>394.91107</td>\n",
              "      <td>31.81634</td>\n",
              "      <td>5.2977</td>\n",
              "      <td>0</td>\n",
              "      <td>1594177196.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43197</th>\n",
              "      <td>397.18887</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10</td>\n",
              "      <td>66.58325</td>\n",
              "      <td>-0.9256</td>\n",
              "      <td>-1.83716</td>\n",
              "      <td>783.44989</td>\n",
              "      <td>28.02304</td>\n",
              "      <td>0</td>\n",
              "      <td>-3.5679</td>\n",
              "      <td>...</td>\n",
              "      <td>1.35971</td>\n",
              "      <td>16.23927</td>\n",
              "      <td>35.23864</td>\n",
              "      <td>12.01019</td>\n",
              "      <td>390.24518</td>\n",
              "      <td>397.35248</td>\n",
              "      <td>31.81634</td>\n",
              "      <td>5.3188</td>\n",
              "      <td>0</td>\n",
              "      <td>1594177197.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43198</th>\n",
              "      <td>397.13776</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10</td>\n",
              "      <td>66.58325</td>\n",
              "      <td>-0.7843</td>\n",
              "      <td>-1.83716</td>\n",
              "      <td>784.86780</td>\n",
              "      <td>28.02814</td>\n",
              "      <td>0</td>\n",
              "      <td>-3.2297</td>\n",
              "      <td>...</td>\n",
              "      <td>1.35818</td>\n",
              "      <td>16.20675</td>\n",
              "      <td>35.23864</td>\n",
              "      <td>12.01019</td>\n",
              "      <td>390.46222</td>\n",
              "      <td>396.70142</td>\n",
              "      <td>31.81634</td>\n",
              "      <td>5.1800</td>\n",
              "      <td>0</td>\n",
              "      <td>1594177198.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43199</th>\n",
              "      <td>397.34222</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10</td>\n",
              "      <td>66.58325</td>\n",
              "      <td>-0.7646</td>\n",
              "      <td>-1.83716</td>\n",
              "      <td>785.51416</td>\n",
              "      <td>28.02294</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.8769</td>\n",
              "      <td>...</td>\n",
              "      <td>1.35818</td>\n",
              "      <td>16.17168</td>\n",
              "      <td>35.25391</td>\n",
              "      <td>12.01019</td>\n",
              "      <td>391.78241</td>\n",
              "      <td>397.73218</td>\n",
              "      <td>31.81634</td>\n",
              "      <td>4.8763</td>\n",
              "      <td>0</td>\n",
              "      <td>1594177199.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43200</th>\n",
              "      <td>397.49557</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10</td>\n",
              "      <td>66.58325</td>\n",
              "      <td>-0.9083</td>\n",
              "      <td>-1.83716</td>\n",
              "      <td>786.98297</td>\n",
              "      <td>28.02990</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.8633</td>\n",
              "      <td>...</td>\n",
              "      <td>1.35895</td>\n",
              "      <td>16.10412</td>\n",
              "      <td>35.22338</td>\n",
              "      <td>12.01019</td>\n",
              "      <td>391.31219</td>\n",
              "      <td>397.24390</td>\n",
              "      <td>31.81634</td>\n",
              "      <td>4.5790</td>\n",
              "      <td>0</td>\n",
              "      <td>1594177200.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43201 rows × 81 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c72079ae-5d4e-4955-b4c5-c54c66ae20bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c72079ae-5d4e-4955-b4c5-c54c66ae20bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c72079ae-5d4e-4955-b4c5-c54c66ae20bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hai_test = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/HAI/HAI_test_total.csv', index_col=[0])"
      ],
      "metadata": {
        "id": "3cnzHIin5quP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hai_test_val = pd.concat([hai_test, hai_valid])"
      ],
      "metadata": {
        "id": "I2L_W4-454r5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(hai_test_val.columns[:-2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia3-gTLo6BNR",
        "outputId": "311bd7c5-7504-4456-d7f4-d0755e4bc39a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hai_test_val.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/HAI/HAI_test_val.csv')"
      ],
      "metadata": {
        "id": "1SkXo51E6UKB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgCyHjReNzh2"
      },
      "outputs": [],
      "source": [
        "hai_train.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/HAI/HAI_train_total_+valid.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieW_aDkQN1l-"
      },
      "outputs": [],
      "source": [
        "hai_test.to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/HAI/HAI_test_total.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riNhgVd2wB5d",
        "outputId": "d2899ceb-7a7d-4267-d90b-fd227f091960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Notebooks/GTA\n",
            "True\n",
            "Use GPU: cuda:0\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab_Notebooks/GTA\n",
        "!python -u main_gta_dad.py --model gta --data HAI --root_path '/content/drive/MyDrive/Colab_Notebooks/GTA/data/HAI' --data_path 'HAI_train_total.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zu5wSlHgonU5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I92mv_OQuTwS"
      },
      "outputs": [],
      "source": [
        "hai_test = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/HAI/HAI_test_total.csv', index_col=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1ql7EL8wrhQ"
      },
      "outputs": [],
      "source": [
        "hai_pred = np.load('/content/drive/MyDrive/Colab_Notebooks/GTA/results/gta_HAI_ftM_sl60_ll30_pl1_nl3_dm124_nh8_el3_dl2_df124_atprob_ebfixed_test_1/pred.npy')\n",
        "hai_true = np.load('/content/drive/MyDrive/Colab_Notebooks/GTA/results/gta_HAI_ftM_sl60_ll30_pl1_nl3_dm124_nh8_el3_dl2_df124_atprob_ebfixed_test_1/true.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mvwu2pHQ-Zi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "hai_f = np.zeros((hai_pred.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDPD2NJwRBmg"
      },
      "outputs": [],
      "source": [
        "for i in range(len(hai_true)):\n",
        "  hai_f[i] = ((hai_pred[i] - hai_true[i])**2).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_UcbILqx1Dn"
      },
      "outputs": [],
      "source": [
        "f1 = torch.from_numpy(hai_f)\n",
        "mp1 = nn.MaxPool1d(80)\n",
        "f1 = f1.squeeze()\n",
        "f1 = mp1(f1)\n",
        "f1 = f1.squeeze()\n",
        "f2 = f1.numpy()\n",
        "f3 = np.where(f2 > 1.965, 1, 0)\n",
        "# f3 = np.where(f2 > 4.3, 1, 0)\n",
        "f3 = np.append(f3, np.zeros(148))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go2_HpqfQJBh",
        "outputId": "45e077ed-9970-4282-c16b-d8b2130e9692"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    352370\n",
              "1.0      6434\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "pd.DataFrame(f3).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y6pdo89QFKW",
        "outputId": "559b92d5-2fa8-424c-c1d8-f4c2835be276"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    350486\n",
              "1      8318\n",
              "Name: attack, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "hai_test['attack'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D1L0F3gy1Uu",
        "outputId": "220f91ce-fd90-4c34-e633-25104938efaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.24877982646420824\n",
            "0.22060591488338543\n",
            "[[345887   4599]\n",
            " [  6483   1835]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
        "print(f1_score(hai_test['attack'], f3))\n",
        "print(recall_score(hai_test['attack'], f3))\n",
        "print(confusion_matrix(hai_test['attack'], f3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue-lM6BYQC-e"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(f3).to_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/results/hai_gta_se_24_22_th1.965.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFHAnW-MROe6"
      },
      "outputs": [],
      "source": [
        "#dspot\n",
        "from utils.spot import dSPOT\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def prep(pred, true, col):\n",
        "  data_f = pred\n",
        "  for i in range(len(pred)):\n",
        "    data_f[i] = ((pred[i] - true[i])**2).sum()\n",
        "  f1 = torch.from_numpy(data_f)\n",
        "  mp1 = nn.MaxPool1d(col)\n",
        "  f1 = f1.squeeze()\n",
        "  f1 = mp1(f1)\n",
        "  f1 = f1.squeeze()\n",
        "  result = f1.numpy()\n",
        "  return result\n",
        "\n",
        "def CORR(pred, true):\n",
        "    u = ((true-true.mean(0))*(pred-pred.mean(0))).sum(0) \n",
        "    d = np.sqrt(((true-true.mean(0))**2*(pred-pred.mean(0))**2).sum(0))\n",
        "    return (u/d).mean(-1)\n",
        "\n",
        "n_init = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7knfHYexUL7W"
      },
      "outputs": [],
      "source": [
        "wadi_pred = np.load('/content/drive/MyDrive/Colab_Notebooks/GTA/results/gta_WADI_ftM_sl60_ll30_pl1_nl3_dm124_nh8_el3_dl2_df124_atprob_ebfixed_test_0/pred.npy')\n",
        "wadi_true = np.load('/content/drive/MyDrive/Colab_Notebooks/GTA/results/gta_WADI_ftM_sl60_ll30_pl1_nl3_dm124_nh8_el3_dl2_df124_atprob_ebfixed_test_0/true.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAdhjY6cYO6e"
      },
      "outputs": [],
      "source": [
        "wadi_attack = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/rename/WADI_attackdata_colab.csv', index_col = [0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4UbpwbUYulk"
      },
      "outputs": [],
      "source": [
        "wadi_train = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/GTA/data/rename/WADI_14days_colab.csv', index_col = [0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDFW4-XSUBfc",
        "outputId": "1baf50bd-e563-4852-aee8-d7ec838533e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        }
      ],
      "source": [
        "res = CORR(wadi_pred, wadi_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "BH-2FJ0rS4tD",
        "outputId": "57c311e6-0b7d-4a32-997b-3db1578012b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial threshold : 398147754.1259863\n",
            "Number of peaks : 17\n",
            "Grimshaw maximum log-likelihood estimation ... [done]\n",
            "\tγ = 0\n",
            "\tσ = 176083132.63630325\n",
            "\tL = 339.7699353621244\n",
            "Extreme quantile (probability = 0.0001): 1321027441.1636326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 172600/172600 [00:11<00:00, 15564.89it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff385f35cd0>,\n",
              " <matplotlib.lines.Line2D at 0x7ff385f41310>]"
            ]
          },
          "execution_count": 617,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wadi_se = prep(wadi_pred, wadi_true, 124)\n",
        "wadi_dspot = dSPOT(1e-4, 100)\n",
        "wadi_dspot.fit(wadi_se[-n_init:], wadi_se)\n",
        "wadi_dspot.initialize()\n",
        "results = wadi_dspot.run()\n",
        "wadi_dspot.plot(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "VgR64LYJWj6R",
        "outputId": "b2f445c3-ba99-41f2-a970-dd80b200ef91"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4feb83de-581c-41e6-ada5-a25a272932a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.726000e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.610517e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.770635e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.817233e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.588564e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.969460e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.702327e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.343104e+10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4feb83de-581c-41e6-ada5-a25a272932a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4feb83de-581c-41e6-ada5-a25a272932a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4feb83de-581c-41e6-ada5-a25a272932a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  0\n",
              "count  1.726000e+05\n",
              "mean   3.610517e+08\n",
              "std    3.770635e+08\n",
              "min    8.817233e+06\n",
              "25%    4.588564e+07\n",
              "50%    3.969460e+08\n",
              "75%    5.702327e+08\n",
              "max    2.343104e+10"
            ]
          },
          "execution_count": 618,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(wadi_se).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YsoyhejXswL"
      },
      "outputs": [],
      "source": [
        "lab = np.where(wadi_se > results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9UOmxLZTw-6"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2GDptYNV8J2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "kHm5ne5z-wvA"
      ],
      "machine_shape": "hm",
      "name": "GTA_wadi.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNb64V4RUlb1KAFCmF7YQrJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}